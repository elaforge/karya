UNSORTED
  * experiment with Data.Conduit.Audio and Data.Conduit.Audio.SampleRate
    . Write with libsndfile / hsndfile: Sound.File.Sndfile
      or conduit-audio-sndfile: Data.Conduit.Audio.Sndfile
    . To do variable sample rate I have to break up the conduit by the
      ratio signal and resample for each rate.  How to do this?
    . I'd like to do each sample in its own thread, and then merge them
      together.  All of the processing should be interleaved.

    with conduit:
      . For each Sample, open its sample and stream chunks.  Divide each chunk
        by X positions of the ratio signal, interpolating the ratio if the
        chunk is larger.  Apply resample.  Then do the same for the envelope
        control, lpf control, etc.  If envelope goes to 0 and the signal ends,
        I can chop off the rest of the samples.
      . Then I need to mix them together at the right times.  I could do this
        with Conduit.Audio.padStart, but that generates silence, which seems
        inefficient.  I would rather have a way to have mix take offsets, e.g.
        mix [(start1, audio1), (start2, audio2), ..].
    manually:
      Chunk time starting from 0.  For each chunk, if new Samples have
      started, open their files.  Read a chunk from each open sample, possibly
      offset with silence for a just-opened one.  Apply controls to each chunk
      in turn, then mix them all together.  Close files of any samples that
      have run out of samples, or whose envelope ended at 0.
    . The advantage of the conduits way is that it handles the opening, chunks,
      and closing for me.  I can implement each control separately instead of
      fusing into a "process a chunk" function.
    . I think I need to write my own resample and mix.

  * Signal should be (Time, Val)
  basic implementation
    * load [Note] from a file, convert to [Sample]
    * Calculate ratio from the pitch.  This means I need the sample pitch,
      which means a DB for sample info, or to put metadata in the sample
      itself.  I think wav supports that at least, try writing with
      libsndfile.
      . On the other hand, I need an instrument db anyway, and it seems
        better to keep it all in code where it's convenient instead of having
        a random bit stored in the file.
    * Then load samples, resample, place, and mix into one output file.
  * implement Attribute
  * Verify tuning is correct.
  ? Why does a ratio of 0.5 go up by an octave?
  - karya support for offline instruments
    . I think I'll need some kind of resolution for the Signal "linear or
      constant" problem.
      . Not yet though since I'm just using percussion.
    - Data.Binary support for Note, which needs to go in a shared library.
      . How to share?  The easiest way is to just directly import it.  But
        then I wind up with a dependency on a file from a different repo.
        Maybe it's not so bad this way, that way I can reuse libraries and
        build etc.  But I need a more robust way to link different packages,
        because the sampler will have separate dependencies.
    - Integration with the instrument db.  This means I also share
      InstrumentDb, or at least the interesting parts of it.
    - Perform.Synth.Instrument
    - Perform.Synth.Convert converts to Notes and serializes them
    - Perform.Synth.Perform invokes the sampler
    - Cmd.Play sends start and stop MIDI msgs

  - divide score by instrument and time range, and render separate chunks
  - cache invalidate and rerender protocol
  - realtime support: receive realtime Notes and send audio directly to
    PlayCache.

instrument script Convert:
  - Sample zones, velocity zones.
  - Stop groups.
  - Randomization, round robin.
  - Amp envelope, e.g. ADHSR etc.

Sample:
  - Avoid zero padding.  I think I need to write a new 'mix' for this.
  - support pitch signal
    . I think I have to rewrite resample for this.
    . Since I use just percussion, I don't actually need this yet.
  - support envelope signal
    * Since I use just percussion, just initial level will do for now.
    - But I'll also need a fade out for stop groups.
  - filters, e.g. lpf control
    . Have to integrate another library for this, e.g. freeverb has filters.
    . The advantage over a separate vst is easier configuration and per-note
      controls.
  - as long as I'm integrating freeverb, I can add other effects like reverb

performance
  - Profiling for time and space.  It should take constant space.
  - SincBestQuality actually does have quite a large impact on the run time.
    Perhaps I should have lower quality for realtime use or even for
    incremental rerenders?  Perhaps the protocol can have a "final mix" flag
    to turn quality to max.
  - fast serialize / deserialize
    If I'm going to serialize Notes, then serialize / deserialize should be
    fast.  But Data.Binary is not fast, at least according to dons CBOR talk.
    . I'd like to be able to directly write and read control signals, e.g.
      send the pointer to the OS write() call with no intermediate steps.
    . Or I can map directly with vector-mmap.  For that I need to record the
      offsets in the file.

Reuse karya code:
  / TimeVector?  Specifically at_linear, bsearch functions
  * Logging.
  * Testing.
  * Pitch.nnToHz
  * Seq.minimumOn
  * Util.Debug
  * Util.Pretty
  * Util.Num
  * Util.ApproxEq
