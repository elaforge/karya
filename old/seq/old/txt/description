The concept is basically to create a tracker-style IDE for a musical
programming language similar to nyquist (or actually is nyquist).  The goal is
to make sequencing / creating instruments fast and easy, but keep the
flexibility and generality offered by the nyquist language.  It ought to be
flexible enough to use instruments from any number of music programming
languages seamlessly, although you will of course be constrained by the
fundamental differences between the languages.  For example, csound has a
orchestra / score concept, so you'd have to write the instrument in csound
code, and then when put in a track it simply spits out the appropriate csound
score instead of a sound object.  This score knows how to transpose, time
warp, etc. just like a sound object, and renders itself when needed.

It will be written mostly in python, with time sensitive stuff in C.  Since
python is a high-level dynamic language, much of the UI and sequencing
functionality can be altered or extended by writing python code (for example,
search/replace can simply be a python function which is mapped to the current
track).  You can do this from a python listener which has access to the
relevant data structures.

The interface will borrow the concept of an insert mode and a command mode
from vi.  The python listener (in a seperate window) will take the role of
vi's : mode.

Under the nyquist model, there is no difference between sequencing and
designing instruments, and q will reflect that.  A "track" is a way of
visuallizing a function which returns a sound object.  The track commands are
functions which modify the sound object produced by the track to their left.

Perhaps I should make a distinction between "generators" and "filters".



The sound object concept is sort of object-oriented, because the logic for
doing things is in the functions.  Say you have a sound generating function:

(osc c4)

if you say:

(loud .4 (osc c4))

The (osc) function knows how to be .4 as loud.  Now say you do the same to a
csound instrument:

(loud .4 (csound-inst c4))

The (loud) function just asks (csound-inst) to be .4 as loud, and doesn't need
to know that (csound-inst) will be scaling down parameter values.  If you say:

(play (seq (loud .4 (csound-inst c4)) (osc c4) (trumpet c4)))

(play) asks (seq) to play itself, so (seq) asks (loud) (osc) and
(trumpet) to play themselves, except with (osc) and (trumpet) shifted back in
time.  (loud) plays itself by asking (osc) to play itself .4 as loud.  (osc)
plays itself by consulting a wavetable and returning a sample stream,
(csound-inst) plays itself by generating a score, invoking csound, and
returning a sample stream, and (trumpet) plays itself by sending a midi
message.  Actually, they return a sound-object which knows how to turn itself
into a sample stream on demand (lazy evaluated).  Getting midi timing correct
for this sort of thing is something I'll have to think about.

So it's this weird functional / object-oriented cross.  Lazy evaluation,
closures, objects: they all deal with the same sort of thing, just in
different ways.

A more oo way of expressing it is:

seq(csound_inst(c4).loud(.4), osc(c4), trumpet(c4)).play()

which looks uglier (reads right -> left), but clearly shows that seq() is
different from loud(), transpose(), etc., it's a constructor, not a
method.  I'm not sure as to whether that "clearness" is a good thing or not.

** question:  in nyquist, if you do (seq (osc c4) (osc c5)), who knows about
(osc c4)'s ending time: (seq) or (osc) ?


