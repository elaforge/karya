LEGEND
  - todo; + in progress; * done; / obsolete, do not want, or can't repro
  ? open question; . note or observation

UNSORTED
  * positive events at the end of the ruler should have text above
  * merged track text doesn't render on negative events
    It's because the text has to be below the prev_offset, and the prev_offset
    is the same due to a concident rank 0 event.
  * Often windows are too narrow to see the name, and besides the title goes
    away if I don't use window decorations.  Can I squeeze the block title in
    skeleton display?
  * point select is really hard to see, it should be more obvious
    I could just make it bigger.  Or make the triangle bright red?
  - If thru did eval on "", I wouldn't need pasang thru.  But it might be
    slower.
  deriving seems really slow
    . viola-sonata took 14s in opt, 1.89s in verify_performance
    . kendang-telek takes 44s in debug, 10s in opt, and 1.5s in
      verify_performance.  Now it's 85s in debug, 12 in opt.
    . Lots of time in Signal.map_x, is it due to getting track signals?
      Derive.Control.derive_control.deriver
      Derive.Control.stash_if_wanted -> Derive.Control.get_block_track ->
      Derive.Control.stash_if_wanted -> put_unwarped_signal
        Derive.Control 165571 300 0.0 0.0 12.1 24.3
      Then Derive.Control.unwarp -> warp_to_signal -> map_x has 12.4%
      Also Derive.Control.unwarp -> Signal.unwarp -> invert -> modify_vec

      line 23793:
      Derive.Control.stash_if_wanted has 1178 entries
      Only 300 calls to Block.track_flags, so looks like the majority have
        TrackTree.tevents_block_track_id track -> Nothing

      Then put_unwarped_signal, and time is split between
      Score.warp_to_signal and Signal.unwarp

    . Remember tempo tracks have a constant sampling rate, so the tempo
      track may actually have a lot of samples in it.  And presumably
      warp_to_signal has to be repeated for each realization.
    . I could memoize by making a warp have both the triple and a lazy
      signal.
    . Or, maybe I don't need to flatten the Warp at all to unwarp with it.
    ? First find out why viola-sonata needs 300 track signals rendered.
      It's the dyn track, every single invert it has to unwarp the signal by
      the entire tempo track.
      Unwarping shouldn't be bad if I don't have to flatten the warp each
      time.
    . data/viola-sonata by opt/seq @score takes 11.49 without fusion, 10.72s
      with

    . I think profile does this because testing now wants signals for all
      tracks.  That would explain why verify_performance is so much faster.
      But if that's true, derivation in seq should become fast if I disable
      all track signals.  Try it out.
    . Also, for viola-sonata, shouldn't it be able to reuse the track signal
      for all the blocks except the top one, which is the only one with
      tempo?  Still, it has to concatenate the chunks, but that should be
      faster than rederiving, unless it's concetenating inefficiently.
    . Collect stats, kinds of track renders:
      1. Control track emitted directly: Control.stash_if_wanted
        1a. Linear tempo, can be reused.
        1b. Nonlinear tempo, must be unwarped: Signal.unwarp
      2. Sliced track is pieced together.  Note.stash_signal_if_wanted

    * Add unwarp_fused, even though it doesn't seem to help seq, but it
      does help the profile.
    ? Why don't these changes seem to help seq?
      Profiling says they do, seq is still lots slower than
      verify_performance.  Why?
    . Laziness doesn't save me from all the unwarp calls, probably because of
      Collect's Monoid instance, which has Map.unionWith Track.merge_signals
    * Get rid of Track.ts_is_pitch.
    - Move Monoid NoteDeriver instance from Deriver.Lib to Deriver.Monad
      so it's not an orphan.
    - Debug.trace implies track events are evaluated back to front, presumably
      something is insufficiently strict, and would be more efficient front to
      back.
    - It seems like inverted tracks wind up with Nothing block_id but a set
      track_id, is that ok?
    - Can I implement a more efficient TimeVector.merge when I know there will
      be lots of overlaps, as when merging track signal fragments?  I could
      first go through and count the samples that will be emitted, and then
      give that to unfoldrN.  Or I could avoid the duplicate work by first
      clipping all the fragments, and then do a big mconcat, which should be
      able to allocate the whole array in one go.  In fact, this might be
      better for all merges.
    - Make Call.TrackInfo just include a TrackEvents, since it has almost all
      the fields.  Or make a LCD if it means I can put it in CallInfo too.
    - The Control.put_signal_fragment work is done on a second call to
      a track, even though the output is never used.  Can I fix that?
    * Track.merge_signals no longer used?
    * If a block is called multiple times, it stashes signals multiple times.
      I should either ensure that laziness prevents extra work from being
      done, or figure out how to skip it if it's already there.
      . To skip it I have to thread the collect along so the next call can
        see there is already a tsig.  This makes a data dependency so it's not
        great.
      . To use laziness, I have to combine tsigs with Map.union, not
        Map.unionWith.  But then how do I combine sliced fragments, or
        orphan tracks?
      . I think I need a two step process.  If I'm in a sliced track, then
        put fragments keyed by (block_id, track_id) into a new Collect field.
        After a non-sliced track has derived, it extracts, merges, and unwarps
        the tsigs from that field, unless one already exists.  The merging
        into the field should be strict, but the field itself should be lazy,
        so when a track is evaluated the second time, none of the fragment
        stashing happens.
      * Note track track signal fails with the orphans.
        The problem is that the track fragments each get their own fragment,
        but in track_signals, so they don't combine.
        . I'm asking for the signal of the track under the transformer track,
          but that track is evaluated as orphans in the caller and all the
          events are only available it the parent track.
    * I still do lots of redundant unwarping since each control fragment has
      extra samples.  I should concatenate them first, then unwarp.
      That would mean Control.put_unwarped_signal puts the signal directly.
      Now Call.derive_track unwarps the Derive.collect_track_signals for
      the appropriate (block_id, track_id).  This seems a bit sketchy since
      I'm modifying an existing track warp, I can't do it twice.  And it would
      happen twice, since I get a derive_track on every single slice.  So
      I have to check that it's not sliced.

  / If I specialized ValCall to PitchCall, then I could make scales generate
    those, and convert to both ValCall and pitch generators.
    . Seems not worth it, since scales are generally going to use ScaleDegree
      anyway.
  - give ModifyEvents.Track the ability to change the track title?
    Cmd.Repl.LPitch.change_scale and to_relative could use this.
  - Implement 'sequence'.  It sequences its notes, paying attention only to
    their order, not time and duration.  The tricky part is getting the tempo
    right so playback looks right, and controls line up right.
    . Figure out tempo from sum of durations of called blocks.  Then set the
      tempo accordingly.  Then evaluate the block normally.  So actually this
      is a kind of tempo track.
    - Does that mean I need this to be a track call?  Or could I do with
      a note transformer?
    . For track calls:
      type TrackCall d = Call (TrackFunc d)
      type TrackFunc d = PassedArgs (Elem d) -> LogsDeriver d
      type TrackFunc = BlockId -> TrackId -> [TrackLang.Val] -> LogsDeriver d
        passed_vals :: [TrackLang.Val]
        passed_call_name :: !Text
        block_id
        track_id :: !TrackId
      - Can I use Derive.Sig?
      . Can I turn normal tracks into track calls?  I suppose they would have
        to be lookup calls.  Would that mess up TrackInfo?

      . The general problem I need to solve is notation where time is
        abstract.  If I don't mix it with concrete time (e.g. wanting
        a playback cursor, and to be able to mix with "normal" notation)
        then all is fine, but if I do want to mix then I need to get a tempo
        out of it.
  - Play position doesn't work right for 'loop' and 'tile' calls, it only
    understands the first loop, and doesn't know that 'tile' cuts off the
    beginning.
  - use tr^ and tr_ starting high and low, instead of tr1 and tr2, starting
    unison and neighbor?  Or just rename the calls and assume the neighbor is
    always higher.
  - I want to use a library of basic patterns in multiple scores.  Rather than
    just hardcoding a bunch of global calls, I should be able to load
    a namespace, and have block calls dispatch to it.  This is different
    from just loading a copy: it loads it anew each time, and doesn't save
    it with the score.  This is like the 'import' idea, except the library is
    in score, not code.
  india
    - nkam doesn't seem to interact correctly with 'h'
    - semi-tone dip.  This is like 1 cycle kam.
    - It would be possible to implement a general purpose initial-hold
      transformer by mapping the samples, to e.g. lengthen the first one and
      compress the rest to compensate.
    - Can I have ornaments that affect the tempo?  This would be another way
      to control kam ending.  But it would require a separate pass to extract
      tempo modifications.
    - janta.  Isn't this just Lift?  It's fingered, right?
    - overshoot "curve" for 'smooth': over2 over3, depending how far over
    - ornaments can use more controls than just 'dyn', e.g. bow pressure
    . instead of hardcoding specific times, I should say short, medium, long,
      which can vary and have some randomization:
      . short, medium, long: -s = '(rnd low high) | -m = .. | -l = ..
    . Think about a way to sequence ornaments:
      . seq x; y; z to sequence ornaments, does this make sense?  Or I could
        see each note has having attack, middle, and release "slots".
        I might need something more sophisticated than just overwriting
        parts of the signal.  Also I want more natural transitions.
      . Many ornaments also depend on the previous pitch, or at least start
        there.
      . The note call is for ornaments that decide their own scope.  The
        control calls are for when you want to place them directly.

  more scales
    - wendy carlos' alpha, beta, gamma
    - overtone series
    - add ratio transpose signal, that multiplies hz
  - After a rederive, it still takes a Cmd to free up the memory.  Who is
    holding on to it?
  - add edit and windows menu to all apps
    There must be special OS X support for these
    Apparently not?  iTerms is defined in English.lproj/MainMenu.xib
    https://developer.apple.com/library/mac/#documentation/Cocoa/Conceptual/WinPanel/Tasks/UsingWindowsMenu.html
    But it doesn't say how to add the Window menu.

  - %sus-abs=-.x is not quite right for detached, because it should scale
    a bit for shorter notes.  E.g. it's absolute but scales down to 0 below
    a certain threshold.
  calls:
    - Sometimes tick makes more sense as at attribute of the previous note, or
      perhaps a freestanding ornament, since it can happen or not on a repeat.
    - 'u' and 'd' have a problem with long notes because pitches can only be
      transposed so far.
      . If I knew how far a pitch could be transposed, I could clip the end
        time to the bottom pitch.  But I don't.  Maybe pitches should be
        transposable infinitely far, but emit a -1 NN signal when they cross
        the boundary?  Or would this hurt error reporting?
  vsl
    . Legato attack scale control affects the crossfade level of interval
      samples, experiment with that.
    . figure out how perf reps work, and how I should handle them
    - make sure perf_upbeat_repetitions are consistent
    - make sure grace vs. grace.updown is correct
    attribute groups:
      . bass clarinet has nv without vib
    - should be able to select the most appropriate sec# dyn given
      +cresc or +dim on a note.
    - Figure out how to map continuous controls, and crossfade.

  - network midi doesn't seem to handle abort?
    playing the second time doesn't happen
  - I have a feeling like FM8 doesn't obey ResetAllControls
    Maybe I should extend Midi.Interface.note_tracker to keep track of
    used CCs to issue resets for them.  Some reset to 1, e.g. cc2 and cc7,
    the rest reset to 0.
  - Pretty on a lot of events causes a stack overflow
    Need a reproduction.
    I should extend Util.Format so I can use it for Util.Pretty.
  - if I added the cmd name before running the cmd, I could put it in the
    error msg when an exception is caught.
  - There are still some cmds without names, who are they?
    Do some logging to track them down.

MILESTONES
  0.1
    * support diatonics, enharmonics, and symbolic transposition for church
      modes, modes of limited transposition, and exotic scales
      (e.g. octatonic a-h)
    * record chords
    + integration
    + just scales, and other ratio-oriented scales that use letters and
      accidentals
    - complete Idiom.Wind, experiment with the Idiom postprocs
    + bring back negative duration / arrival beats
    * scales and keyswitches
    / efficient thru
    * tracklang complete with set of basic calls
    * better REPL situation
    / midi record
    / dense / efficient control signals
    * derive cache
    * symbolic score
    + save undo history / incremental save - more extensive testing
    + solution for audio, plugins, track bouncing, etc.  ardour / reaper + MTC
    + jack support on linux
    / simple csound backend
    * lilypond backend: good enough to render viola-sonata
    * documentation
  1.0
    - stable api
    - solution for local data / code
  future
    - non-realtime synthesizer: doc/dev_notes/synthesizer
    - horizontal layout
    - mouse oriented signal editing
    - Unify environ, controls, and pitch signals by making signals of
      arbitrary type.
    - print scores
    - include audio inline, so I can write signal transforms like event
      transforms

----------------------------------------------------------------------

documentation
  - update screenshots: doc/img/ly-example.png
  - Publish haddock with http://documentup.com/feuerbach/standalone-haddock
  call doc:
    - I could go look through arg docs for controls and list all the controls
      that have someone listening to them in a certain scope.

incremental save / git:
  + try saving individual events for incremental save
    Seems to be just as slow as full save, probably most of the time is in
    the call to git.  Test again with larger tracks.
  - wrap operations in a lock file
  - make sure things are ok if it fails at any step
  - I don't think Ui.State needs to emit CmdTrackAllEvents for cases where
    diff will catch it.
  - See if git's delta compression understands binary and can compress
    tracks.  Otherwise, would it be worth helping it by e.g. separating
    each event with a newline?  But then it makes serializing events more of
    a hassle.
  Git docs: http://progit.org/book/ch9-2.html

integrate / integration:
  score integrate
    * Why do I need the bogus <! call at all?  I could just have a cmd call
      that adds a TrackDestination.
    / if there were a Cmd.create_fitted which took screen dimensions, then
      Integrate.score_integrate_block could make a fitted view
    - cascading score integrates
      Is there really a use for this, other than consistency?
  derive integrate
    - attrs that the instrument understands can turn into +attr calls, if
      they're not in the CallMap, e.g. save/test/wayang
    - adding a +soft stroke means it gets both less dyn and +soft again, so
      it's extra soft
    - bug: can't delete a derived track, it just gets regenerated
    - bug: can't undo past a integrate create, it just creates a new one
      Maybe I could not record the integrate step?
    - bug: create tracks, remove <, re-add <, does it work?
      Removing < should break the integrate links.
    - Ensure cascading track integration works.
    - If integrate is committing changes to a track, can that bite me if
      a "canceled" derivation comes through?  Think about this later.
    - What if an integrate wants to produce a note transformer track?  I
      think that's currently impossible.
    - quantization

lilypond:
  - warning if ly-prepend or ly-append is being omitted due to a chord
  - Maybe code events with a voice should go in the voice requested rather
    than mixed into the first one.  E.g. would have fixed grace notes.
  - one track has voice, the other doesn't, causes a "can't advance time
    backward" error
  - Support ly-append-first and ly-append-last for zero-dur notes.
    . First come up with uses for them?  Or do it just for orthogonality?
  - code events in >ly-global can be distributed to all staves
    Otherwise I have to remember to add e.g. ly-key to all staves manually.
    . But ly-key is no good, I really do need to set the key.  I think I have
      to break up the block.  Why can't I do assignment more easily?
    . Well, I have to grab a deriver to dynamically scope the new value around.
      Unless I let a deriver mutate the environ, then it has to be nested.  If
      a deriver can mutate, then events have to be evaluated in order.  Of
      course, they already do for controls because of the previous sample.
      And since it's unset at the end of the block, block caching still works,
      the same way as for previous sample.
    . On the other hand, I think I want to encourage nestedness and it should
      be easy to split.  The only reason viola-sonata has huge blocks is that
      it's a midi import.
  - Derive.Call.Lily needs a naming refactor since there are too many vaguely
    named flavours.
  - I need some way to hide rests.
    Add magic bit of code that turns its rest r4 into s4.
  - If I can figure out the meter from just the name, then I can get rid
    of the awkward map with hardcoded meters.
    I could have parse generate the Meter and memoize it.
  - optionally emit the lilypond to display a compound meter
  - use Util.Format in ly output

negative duration / arrival beats:
  represent arrival notes differently
    . Instead of representing arrival notes as the sounding time plus
      a negative duration, I could represent them as a start time plus a flag.
      If the flag is set, it's considered an arrival note and the trigger line
      is drawn at the bottom instead of the top.
    pros:
      1 Cmds work the same for negative and positive durations, I don't have
        to do any special checks for overlapping with a following negative
        event.
      2 I can have a note arrive and another depart from the same point, e.g.
        trill up to a note.
    cons:
      3 The encoding seems not as elegant.  I can still do it with negative
        durations, but now the negative is just a flag, rather than
        representing the actual extent of the duration.
    4 This means that cmds work spatially rather than logically,
      i.e. I'll need a separate "set beginning" cmd since it becomes set
      duration for negative events.  I don't know if that's a pro or con, but
      it feels like a con since I need more cmds.
    #1 might not be compelling if I've already done the work to get them to
    work, but if it's buggy or turns into continual for for every cmd then it
    becomes a big deal.

  - ensure inversion works (it should slice >start <=end)
  - ensure redraw works
    I have to make SymbolTable wrap text above too.

external
  parsing "1r" instead of "1s" gives a "unexpected eof" error msg, it should
    say 'r' was an unknown suffix
    Can't get attoparsec to consistently report an error.  Kind of hard when
    it always backtracks.
    - Need to add <||> to attoparsec.
  chorded keys are not getting the proper pitch bend
    It's a pianoteq problem.
    + Reported to pianoteq, said they'd fix it in the next release.
  - problem with pianoteq: if the same note occurs on two channels, one
    will be dropped.  Report to pianoteq.  I could work around, but it won't
    occur with real multitimbral instruments anyway.
  + send a patch to improve Random.Shuffle?
  - patch for hsc2hs for #alignment
  srcloc_annotate pragma
    I think a ghc pragma is needed.
    - read up on how jhc does it
    - ask ghc-users if it's a good idea
    - figure out how to implement pragmas in ghc

local: plugins:
  . ghc can now unload code: http://ghc.haskell.org/trac/ghc/ticket/8039
  . might be relevant: http://hackage.haskell.org/package/dynamic-loader
    http://codeutopia.net/blog/2011/08/20/adventures-in-haskell-dynamic-loading-and-compiling-of-modules/
  - to do per-score code, I can put it in Local.Score.<namespace>
    Convert to module name by replacing -x with (upper x) and capitalizing the
    first letter.
    Then when you load a score, incorporate the static config from that
    module.  Shakefile can link in the local modules under the right name.
    . If it gets to be too much overhead to link on every single build, then
      I can load dynamically at runtime.
  - Either dynamically load local inst definitions and local StaticConfig, or
    auto-generate the link file Local/Instrument.hs.
  - come up with plan for reloading inst config and static config
    Really what I want to be able to do is recompile the static config
    incrementally, relink it with the main binary *quickly*, and restart the
    app with exactly the same state.  This should be a lightweight operation,
    so it's feasible to edit some code, press play, edit code, and play
    again.  That means a full-on serialize restart is out, because the cache
    could be quite large.

    Of course, you want this stuff in a library so it can be reused across
    projects, so you can put it all in Local/.  Then the song state would
    have a (hopefully minimal) linkage from hs namespaces to the tracklang
    namespaces.

    So with hs-plugins: The static config is considered a plugin.  You edit
    Local/Config.hs, or edit other files in Local/.  It detects the change,
    regenerates Local/Config.hs, recompiles and reloads it.  Then the
    responder is called again with the new static config.

    So I need to be able to re-initialize the responder with a new static
    config.  Actually, the bits I care about are the call map and the cmd
    map.

cleanup:
  - Maybe I should use Score.PControl instead of Score.Control for pitch
    control names.  Or PitchControl and think of better names for the existing
    PitchControl and ValControl.
    . (Control, Signal, Y), (PControl, PSignal, Pitch)
      SignalRef, PSignalRef
  - clean up Pitch.Semi, Pitch.PitchClass, Pitch.Step, and Theory.Step
  - update shakefile to use new system calls and logging levels
  - if I add an Alternative instance to Sig.Parser I can write arg parsers
    like 'Sig.many xs <|> Sig.many ys'.  I think.  If I wind up with something
    else like Derive.Call.Val.num_or_pitch it would be worth trying out.
  Format3
    . Converting Pretty to Text is blocked on this.
    . Rethink how indent breaking happens.
      Maybe indent should be a flag on SoftBreak
      If pre is null, then maybe I should indent to the next level, e.g.
      [(0, ("", "a")), (2, ("", "b"))]
    . The problem is that 'text <+/> indent 2 (...)' behaves unintuitively:
      the indent happens after the newline.  But if I put indent around
      the whole expression, then because indent is also break priority, the
      breaking is wrong.  So I want to say break + indent in one word.
  convert to Text:
    - Log.debug etc.
    - Pretty.pretty
      For this I need to extend Util.Format to be a simplified prettyprinter:
      - monoidal interface, not monadic
      - write text, set indent for expression, insert soft break
    - Derive.throw
    - Ui.Id
  - I could make the fltk interface clearer by putting c_interface.cc into
    fltk, and then putting all the types it depends on in one header.
  - There's a lot of duplication between State.TrackEvents, Call.TrackInfo,
    and Derive.CallInfo.  Can I factor out the common bits?
  - Update.BlockSkeleton sets Block.Status, and so does Update.BlockTrack.  If
    I merge status update into skeleton updates I can take Status out of
    Block.DisplayTrack.
  / move src into src subdir.  Then I don't have to do hacks in the shakefile
    where I only recurse into [A-Z]* dirs.  That's not exactly a big deal
    though.
  / split Ui.State into separate modules for views, blocks, tracks, etc.
    put into Ui.State.* and re-export from Ui.State
    . Actually the giant module isn't so bad and it's stopped growing.
  - split up CallInfo depending on type
    I got started but was discouraged when it came time to write
    GetLastSample, maybe I should make another go.
    Note tracks can't get a GetLastSample at all.
  - It would be more efficient to move events around if their controls were
    normalized to start from their beginning, so that you never have to modify
    the signals.  Of course, it's only worth it if events tend to get moved
    more than once.
    . noltol moves events with Score.move, which is really inefficient.  Think
      more about making event signals relative.  It also means I don't have to
      move signals that are never used.
    . However, this is bad for global controls, currently they can just be
      directly put in the event.  It seems a shame to have to copy a slice for
      every event.
    . Perhaps just store a control offset which the performer and signal
      lookup functions then have to take into account.
    . Maybe generalize to have a TransformedSignal !Control !Shift !Stretch
      Don't I already do that in TrackWarp or something?
  - Think about some way to formalize the identifier restrictions, currently
    it's only enforced in the tracklang parser.

    p_ident applies to: Attributes, Control, PitchControl, ScaleId
    Maybe it's enough that the parser restricts them?  That means no one
    will bother creating e.g. a bogus control name because it could't be used.
    Call names are explicitly anything-goes.  BlockIds should support at
    least some of it if they are supposed to be interchangeable with other
    calls.

    On the other hand, I don't think I care much if idents can have wacky
    names, they just won't be nameable from the tracklang.
  - storing TrackEvents without duration would make maintaining the
    no-overlap invariant easier.  E.g. have explicit 'off' events, otherwise
    each event extends to the next one.  It means after merging I have to
    clear redundant offs, but that's easier right?

performance:
  - Do profiles again with Event.event_text :: Data.Text instead of ByteString.
  scrolling through giant blocks is slow
    - drawing is stil slow, I'll have to look at the fltk layer
      It happens when the block is wide.  Use test_block to see if it's just
      fltk.
      . It's fltk.  Not alpha draw though.
      Scrolling is weirdly chunky near the top when fl_scroll() is on.
      Curiously it doesn't seem to help at all.
    - Would it be faster to call fl_scroll once for all the tracks?  I could
      also theoretically call find_events all at once too, though that
      shows up low on the profile, so maybe it's not a big deal.
    . The thing is, it seems like fl_scroll doesn't actually help scrolling
      speed at all.  Maybe all the time is spent elsewhere?
  - look into Debug.Trace.traceEventIO to see how long various things take as
    in http://www.yesodweb.com/blog/2012/10/future-work-warp
  - Store signal chunks in the Ui.Track so they can be directly emitted.
    This is only useful for large chunks of 'set' calls, probably recorded
    from MIDI.  So it's probably not pressing until that feature exists.
    . make Ui.Events into 'Map ScoreTime (Event | Chunk Signal)'
    . collapse chunks of adjacent 'set' calls into a Chunk
    . track_derive on a Chunk just returns the contents
    . fltk event render should detect too dense events and omit them, rely
      on the signal render
    . UI edits should see the Chunk expanded out as Events.  Inserting an
      event should modify the chunk or split it depending on if the inserted
      event is a set call or not.
  Cmd
    - If a msg aborts or doesn't run any cmds, don't bother to run diff.
      Except that hardly ever happens if I do shortcut thru.
    - cache track cmds for each track, update when the track title or skeleton
      changes
  Derive
    - parallelize derivation
    AppendList / MergeList for Derive.Stream
      - switch to AppendList and try to get garbage down
        Avoid copying sublists returned by block calls and cache hits
      - play from cursor is a linear scan on all events from the beginning,
        seems like this would be faster if I could skip chunks.
      - see if a Merge constructor can reduce copying
      - can I cache length and range in AppendList?  does it matter?
      - insert parallelism?  maybe the evaluator can do that when it sees
        Merge?
    - lazy signals
      - check out 'at' and 'bsearch' occurrances and see if they can use tails
      - There are lots of lookups in the tempo map
    - see if making a version of Derive.local that's non-monadic in the
      modifier has any effect on performance
    derive cache
      - can I cache long blocks by slicing them if they're >n?
      - c_block should only cache if the block has > a certain number of
        events.
      - I won't rederive cached generators if they have control damage outside
        of the event range.  But there's nothing stopping a generator from
        reading ahead or behind... come up with some kind of solution for this.
    - fair amount of garbage generated by SignalBase.bsearch_above, I think
      this is because it has to box the values when it pulls them out.  But
      it's really just comparing to a Double, so I should be able to do the
      operation unboxed.  But decide about lazy signals before going nuts on
      this.  If I revert to linear search then none of this is necessary.
    - at_linear is called a lot by compose, by compose_warp, by d_warp
      can I make this more efficient?
  Perform
    / packed midi, encode to storable vector
      last step of performer is to compact into vector
      but I'm not sure this will much help
      The main thing is how to encode the device.  I think I can hash it.  Or
      use OS X persistent device ID?
      how many msgs in e.g. the ptrio?
        127130, [pno 9205, flute 63748, clarinet 54177]
        5367 for bloom
        peak for 246114 msgs: 46mb for int, 38.7 for int, 38.7 for w64

symbolic score
  some way to get symbol feedback instantly to make it easier to compose them
    . But it calls SymbolC and I ran into a problem where linux ghci can't
      link FFI-using functions.  Ask on glasgow-haskell-users.
    - I can either have a separate app, or use the special Status trick.
  - namespacing?  don't worry about it for now, if I need it later it can be
    entirely at the haskell level, I can use the per-song config to import
    namespaces
  - feta's tr symbol looks bad especially when small, is there a better one?
  - find or make a font with jian ti symbols?
  - find or make a font with gong che pu

fltk:
  - If I want to draw multiple signals together, I need a line or polygon
    + gradient function.  Maybe I can get ahold of the OS X graphics context
    and directly call cocoa functions.  For that to work on linux, I think I'd
    have to do the same for cairo.
    . Or perhaps I should just switch to OpenGL?
  drawing artifacts on retina:
    . Some of this may be fltk bugs.
    - tops of tracks and the tops of track text boxes still get gunk, visible
      when scrolling horizontally
  - Should fltk collapse adjacent dividers?
  track titles
    - Grow the window when the title grows past it.
    - Grow text past edge of window, when I resize the window the text keeps
      growing with it.  But it doesn't expect that size, and doesn't clear
      when deselected.
    - Type into track text on the right side, then expand the window so it can
      be visible.  It doesn't redraw the newly-revealed bit correctly.
    - If I wrapped track titles I could see the entire thing, but at the cost
      of using more vertical space.
  - There's a focus bug, but I'm not sure how to reproduce it.
  + can I get fltk to omit the jellybean buttons on the window?
    . Yes, but requires hacking fltk.
    . Completely disables resizing.  Apparently this is hardcoded.
  - some way to scroll that's not the scroll wheel
  - I could set certain Symbols to stretch to the length of their event, this
    would yield a nicer looking score.  But it would mess up the bounds
    detection.
    + gmail: subject:(scaling text)
      But it's OSX only.
  / rethrow c++ exceptions as FltkError
  - factor scroll redrawing into a single class
  / draw arrows in SkeletonDisplay.cc properly?  Meh, they look ok.
  - figure out how to have a minimal title bar in os x (win.border(0) removes
    it altogether)
    I can set something like kUtilityWindowClass in Fl_mac.cxx:Fl_X::make, but
    it doesn't get any kbd input
  - can I get the windows into an os x windows menu?
  incremental redraw / scrolling
    I don't like the current situation of incremental redraw and scrolling.
    It's also buggy, i.e. one pixel difference between scroll and redraw.
    Get rid of damage and redraw everything every time.  Then I have to make
    it fast to fetch the data for one screenful.  What makes that slow
    currently?
  Track
    / dividers can have separate color for upper part, for collapsable tracks
  + Why does seq sometimes leave a app menubar on quit?  Do other fltk apps
    do that?  Yes.
    . It has to do with starting from the cmdline, starting with 'open' doesn't
      have this problem.
  + Disable application persistence for fltk apps:
    http://oleb.net/blog/2011/07/whats-new-for-developers-in-lion-part-1/
    http://developer.apple.com/library/mac/#documentation/General/Conceptual/MOSXAppProgrammingGuide/CoreAppDesign/CoreAppDesign.html#//apple_ref/doc/uid/TP40010543-CH3-SW26
    Can then re-enable ~/Library/Saved Application State.

  control track, render signal
    - render option: solid with color gradient
    - combine multiple signals, e.g. one controls xpos, one controls color
      I could combine pitch and dyn.  This is appropriate for the note track.
      . I'm pretty sure OS X can do this, as can cairo, so I would need to
        figure out how to get direct access to that API.  I could get rid of
        the awful alpha_draw.cc hack while I'm at it.

logview:
  - Logview: adding new log msgs causes the status bar to shrink back to one
    line, even though it should be wrapped to two.
  - Logview got some kind of file locked error, presumably trying to track
    a rotated log.
    . It happens if the write handle is still open, for some reason
      Posix.getFileStatus then gets openFile: resource busy (file is locked)
    . Maybe it's when reopen tries to open the file and it's already open.
  - can I get the standard edit menu and copy/paste?
  - haskell and c++ use the same machine readable format
  - tabs are not lining up properly
  - option to wrap lines or not?
  - hide or display various attrs: date, file, function, ...

Ui:
  Track
    - benchmark large TrackEvents
    more compact implemnetation than Data.Map?  profile first!
      - priorities: memory efficiency, persistent, merge speed (insert many)
        shallow tree of dense chunks?
        can I take advantage of non-overlap?  [(pos0, data), (pos1, end), ...]
        data Event = Event String StyleId | End | ControlVal Double
      - I think memory efficiency is more important than modification speed
    dense sampled signals
      - efficient storage, preferably as a Signal so no conversion is necessary
      - display dense signals: omit text and trigger lines when zoomed out

test:
  - try writing criterion tests for midi performance and derivation
  complete quickcheck derive testing
    I switched back to Double for RealTime, but this means the roundoff errors
    are back.  Use quickcheck to repro them.
    + make a simple deriver that creates event and midi output skeletons
    - integrate quickcheck with generate_run_tests.py
    - assert that the reduced deriver output equals the simple deriver output
    - basic pitches: If the score was created with notes aligned to note
      starts, then every NoteOn should have the appropriate key, there should
      be no pitch bends, and "same note" should be the only reason for
      a channel split
    - basic controls: Given randomly placed control events, notes have the
      correct control curves.  Don't worry about times or midi.
    - slicing: Given some simple note transformers (tuple, place, ...),
      pitches and controls are still associated with the right notes as above.
      Don't worry about times, just that the right notes and the right
      controls.
    - block call property: a couple levels of nesting for block calls, notes
      still have the expected pitches and controls as above
    - inversion: as 'basic pitches' and 'basic controls', but controls are
      below the note tracks, results should be the same
    - stack: generate nested events, check that stack is as expected
  - count number of tests in addition to checks within each test
  - use generics or Foldable or something to write a generic StructEqual

midi record:
  - implement
  . Ideas for editing recorded MIDI:
    . control: realign attacks, smooth or sharpen attacks.
    . pitch: retune intervals, fix wrong note or add notes, change portamento
      speed.  Add, widen, or narrow vibrato.

REPL: repl:
  - repl should understand --
  - only write history when the cmd succeeded
  - command to open the haddock for a module
  - haskeline sucks for long lines, add multiple line editing?
    really I'd prefer plan9 style esc then edit
  - is Cmd.Lang.Fast now obsolete?
  - can I get local variable bindings (let x = ...; y <- ...) to work in the
    REPL?
  - tab completion for symbols like in ghci
    I'll need a list symbols cmd which the repl automatically sends on tab
    completion.
  - :compile cmd that turns on compilation for everything except Environ
  - :browse to look in modules... can I use GHC.getBindings for this?
  - :module cmd to move evaluation context to a certain module, maybe I
    could also get rid of the need for Cmd.Lang.Environ to import everything.
  - new ghc api lets log_action catch ghci msgs, e.g. "Compiling xyz", added
    in f81e14bb14e459cdd59ea232f7c711827be85dd6

tempo:
  - Create tempo by "stretching", i.e. select start and end, and create tempo
    mark that will cause the start point to be played where the end point used
    to be played.

Cmd:
  - remove RawEdit?
  meter / timestep
    - timestep 64*2 skips two 's', because 's' is the minimum match
      skip should be ignored when the match is a larger rank than exists, or
      maybe step should fail.
  - Can I give Cmds their own state without putting it in Cmd.State every time?
    At worst I can have 'Map.Map String Dynamic'.

    Use existentials:
      data forall a. Cmd = Cmd {
        cmd_func :: a -> CmdT (Status, Cmd)
        , cmd_state = a
      }
    This means that such cmds have to be able to be updated after they are run,
    so the cmd lists have to be kept in responder state.  If I'm going to do
    that, why not have cmds optionally return a continuation and handle state
    that way?

      cmd msg = do
        state <- stuff
        return $ continue $ \msg -> do
          more stuff

    Or if I can put it in the monad:
      cmd msg = do
        state <- stuff
        msg2 <- yield Cmd.Done
        more stuff

    For module level, each module of cmds would have to export a bunch of Cmds
    and the responder retrieves the state and passes in another layer of
    StateT, or directly.  I supposed Dynamic wouldn't be so bad for that.  What
    happens when the module is reloaded?

  ruler:
    - LRuler.inject, opposite of extract, replaces sub-block rulers
    * LRuler.strip which strips out lower rank marks.  This can make rulers
      for large blocks smaller.
  Cmd.Edit
    - alternate finale-like note entry: hold down step key to set step and
      turn on edit mode, but only while the key is down
      (merge will clip them to the next event)
  Cmd.Repl
    - functions to load string serialized tracks for event cut and paste
    - an aux data input for the lang socket might be useful, to paste in data
      without having to quote it
  Cmd.Play
    - Playback should have multiple lines when a block is derived multiple
      times. Have a set of playback selnums?
  copy / paste / Clip
    - clip block should use the ruler, just to make it easier to look at
    - clip could also copy over the skeleton
      It could use it to make sure the paste is compatible, but that might
      be more of an annoyance than a convenience.

  Undo / UNDO
    - shift [ and ] undo and redo zooms.  or one key to toggle last zoom?
    - Suppressed undo for val edit is surprising since I tend to do a lot of
      edits without leaving val edit.  Maybe don't do it for pitch val edit.
      Try going back to using the name to suppress, but ignore cmds with no
      name.
    - Add a "revert within selection" that searches backward for the last
      change within the selection.
    - Along those lines, should each block have its own independent history?
      This is supported naturally by the git layout since each block has its own
      file.  Wait, actually it's track, and that would be awkward if I undo one
      block and it changes tracks on another.  How do a say what position
      a block is in the history in that case?
      . One appealing thing is that I don't necessarily want things like config
        changes to be included in undo.
    - Visual display of undo history, because stepping back one-by-one is
      a bit of a hassle.
    - record view changes, at least zoom / scroll so it can be undone / redone
      separately

Derive:
  - namespaces for calls
    As there gets to be more calls, I may need to have a 'import x' which
    brings the namespace into scope.  Namespace could use tags, but perhaps
    tags should instead be derived from the namespace, e.g. prelude, bali,
    india.
  tracklang:
    - there should be a character that triggers a parse failure, which is used
      by invalid ShowVal instances like ShowVal Pitch
    - it's confusing how some calls expect env vals like 'x = 1' and some
      expect controls like '%x = 1'.
      . The obvious way to solve this would be to merge env vals and controls,
        but that's a big change.
    - Track caching is too fragile, if I add a track with scope over everything
      then I get no caching.  Instead I should cache the bottom note track, or
      perhaps every note track.  But that doesn't work because they're all
      sliced up.
  postproc
    - retune a note depending on the previous interval (e.g. sloppy pitches
      when playing quickly)
    - overblow emulation: a set of overblow ranges are defined, along with
      possible pitches for each one (fundamental and overblow harmonics).
      When a note moves from one to another, start a new note at the
      destination pitch and bend the decay of the old one to the fundamental
      or closer harmonic from the previous mode.
    - rambat damping emulation: notes ring on by default until they can be
      damped.  Damp at the first opportunity, where opportunity is defined
      as a break with no notes for a certain amount of time.  Can only damp
      two neighboring notes at a time.

  - consider track calls and block calls:
    note_track :: TrackTree.EventsNode -> Derive.EventDeriver
    derive_tree :: ScoreTime -> TrackTree.EventsTree -> Derive.EventDeriver
    I could use this to implement is-ly and no-ly, and also totally custom
    track types and block types.

  note calls:
    + chord calls, with automatic dyns for the notes.
      Originally I intended each note to go in its own track, with the idea
      that it takes about the same space but is more powerful and flexible.
      But it's not quite true, because the extra track is there for the whole
      block, though perhaps that's a side-effect of having blocks which are
      too large.  More compellingly, chords can automatically fiddle with dyn
      and start time, and can also interpret chord symbols.
    bali:
      kotekan ornaments
        - control for norot +mute
        - gender norot: control for polos 234- vs. 434-
        - an optional special pattern which switching between kotekan and back,
          e.g. 112-2-2-
        kotekan:
          - verify realization with integration
          - Some patterns do play on the beat, they should be able to do that
            and suppress the previous note.  I could do this by emitting the
            note with a +weak attr, which will be cancelled out in postproc by
            a coincident note.
          - phase: this can make the last note no longer align to the pitch
      wayang in octaves
        . I could do it with >wayang-both that emits >wayang-p and >wayang-k. Or
          just call the score twice, once with transpose +1 oct.
        . Or I could create the kantilan as a integration of the pemade, so it
          can still be modified. I think this would want a "score integration"
          which just copies and merges the events directly, and doesn't do
          the intermediate derivation.
      trompong / reyong:
        - postproc for damping which omits damping if the other hand is busy,
          or if it will be busy (e.g. 23-32)
        - trompong ngoret, actually I can use rambat tick
          But damping on reyong is different, you can just forget some notes.
        - split to ngembat, e.g.  λ 人 hmm, is there a reverse lambda?  Can
          I draw symbols reversed? 入 兩
        - various numpuk
        kilitan
          . What is the "core" of what kilitan is?
            Take a melody, and split it into multiple parts.  Each part has
            a limited pitch range, and when the melody is out of range, play
            harmonizing intervals, or move in contrary motion.
            Also, the melody is at a slow tempo, and kilitan elaborates at some
            integral multiple, using norot style patterns.
          . So I decide on how many parts, and steady state patterns for each
            part.  The patterns may have alternatives, or internal variations.
          . Patterns also have transitions to a new melody note, which occur
            before the melody note arrives.  The transitions may vary depending
            on the source and destination melody notes.
          . There are also cross-part variations, where neighbors must pick
            cooperating variations.
          . Also there may be ornaments that affect all the parts, e.g.
            232321612.  These are similar to cross-part variations, except that
            they should be signalled explicitly in the notation rather than
            being random.

          . Eval transformed deriver in flat time, to get events in ScoreTime.
          . Simplify notes to 'Melody Theory.Pitch | Ornament (Byong | DownUp)'
          . Ornaments become set patterns at the given time, different for each
            part.
          . Start with part 1 and for each note:
            . If it's an Ornament, emit the relevant notes verbatim relative to
              the current time, e.g.
                Ornament -> Part -> Time -> [(RelativeTime, Note)]
              Clip anything that would overlap the previous event, or the next
              note.
            . If it's Melody, generate harmonic points until the next
              non-Melody.  They are relative to the start of the call.
            . Start assembling notes from fragments.  Get the transition
              fragments based on the Part and the next Melody note, and if any
              line up to now, pick and emit one.  Otherwise, pick a continuation
              fragment based on the current Melody.  If it's a coordinated one,
              emit that separately.
            . Do the same for each part, except that the fragments that are
              chosen can be influenced by previous coordinated fragments.
          . Just emit open notes.  Damping is done with a separate postproc.

          . type RelativeTime = Int -- at harmonic rhythm
          . type RelativePitch = (Diatonic, Chromatic)
          . type Fragment = [(RelativeTime, RelativePitch)]
          . type Coordination = Char -- anything, just a key
          . type Fragments = [(Maybe Coordination, Probability, Fragment)]
          . type Part = Part
            { transition :: Pitch -> Fragments, continuation :: Fragments }

          . Or, do this the same way I do kotekan.  But instead of sangsih and
            polos patterns, I have a set of N patterns indexed by pitch.

          - extend to work other scales
          - more graceful transitions between pitches
          - variant patterns
          - coordination across parts
          - damping, depending on speed
          - support kilitan/beat speed more exotic than 4/1

  control calls:
    - signal transformations: +, *, max, min
    - saturation limit, e.g. flatten sine wave but without clipping
    - continuous tempo warping for signals
      tempo: "2" -> "1", "2", cont: "2" -> "i, 1", should emit a bent line

  control functions:
    - Could use rank to modify dyn and emphasize or deemphasize notes on
      important beats.
    . With 'real' and 'score' and the signal conversion functions, I gradually
      rewrite more and more functions from Deriver to functions with a
      TrackLang.Dynamic argument.  Also they're going to start to want an
      exception, and why not logging too, and I'm right back to Deriver.
    . Why can't I make ControlFunction into a Deriver?
      ControlFunction moves to Deriver.Monad, so Val must also.
      Now control function stuff must be exported from Deriver, not TrackLang
      and Score.  But also Val can't be exported from TrackLang, and there are
      tons of users for TrackLang.Val.  Maybe I can split TrackLang into a low
      level version.  In fact I already have, everything Deriver uses
      TrackLang for can come from BaseTypes, except Typecheck.  Monad.val_call
      must move to Lib.
    . Environ, Pitch, and Val all move into Derive.  And Score.Event.
      This is getting to be pretty much everything.
    . Another option is to make Derivers polymorphic.  I can put the
      fields in TrackLang.Dynamic in a typeclass.
    - Abstract 'state' and 'err' to a DeriveM, and implement
      type ControlFunctionM a = DeriveM.Deriver Dynamic Text a
      . I can't reuse Deriver, but at least I get logging and errors.

pitch: scales: scale:
  scales / Derive.Scale:
    just intonation
      - interpolate between just scales in different keys
    - meantone
    - Interpolate between two scales.  The main thing is to establish a note
      to note correspondance.
    bohlen-pierce
      - Make relative scale.
    - retune a note depending on the previous interval (e.g. sloppy pitches
      when playing quickly)
      I think this has to be postproc.
    support scales that are different ascending vs. descending
      . Scales have two versions of each degree.
      - scale_input_to_note takes a previous Note arg, which it can use to
        guess the appropriate variant.
      - Variants have to have unambiguous names though, maybe 4n^ and 4n.
      - Use scale_alternate to switch a note between alternates, bind to the
        same key as enharmonic.  If there are no enharmonics, then fall back
        on alternate.
    Raga
      - Support arohana and avarohana by treating them as enharmonics
        Is this really a good idea, since they aren't anything like
        enharmonics?  Maybe I should just use the flip-enharmonic key, but
        keep the concept separate.
        . I could keep it at the Cmd level by remembering the last entered
          pitch and defaulting this one based on it, or I could try to put it
          at the Derive level too by having the pitch itself be based on the
          previous one.
        . Putting it at the derive level seems really hard and unreliable, so
          I should have separate symbols, e.g. 4r^ and 4r_ for up and down
          variants.  For western modes this isn't necessary since the notation
          is already absolute.

    - letter and jianpu but with implicit accidentals based on the key
  + It's a bit unpleasant how I have TwelveUtils for accidental and key using
    scales, then Scale.Util for simple scales, and then Just is its own thing.
    Can I unify things into one framework?
  intonation: think about how to do e.g. meantone melody, with just harmony
    . Do a postproc to analyze simultaneous notes.  If I use an attr to
      tag the melody, I can tune everyone else to it.  But how do I retune
      notes with non-trivial pitch curves?  Well, I could use a transpose
      signal to tell the pitch calls what's going on.  I think I might just
      need the frequency of the melody note.
    . Do an analysis pass, and insert environment that says what the harmony
      is.  Then pitch calls use that to tune.  Doing the analysis might be
      tricky since I have to extract a "principle pitch" from each event,
      but it might be useful in general to have an analysis framework.

Perform:
  - I can work around the pianoteq tuning bug by not stripping redundant
    conrol changes.  This also means that recorded MIDI can be played from any
    point.  If bandwidth isn't a concern then why not?
  - damper pedal causes all notes to extend until the pedal comes up, should
    the performer know about that?  Is there anything that this breaks?
    I don't think so, it affects channel allotment so notes could be
    improperly joined, but mixing pedal and multiplexing seems rare enough.
  - Perform.Midi.Perform: should be possible to lead keyswitches as long as
    they don't precede the previous NoteOn, since I think samplers will only
    switch on the next NoteOn
  Instrument
    - some basic midi instrument defs for generic midi (dev, patch)

Instrument DB / browser:
  - browser has lots of empty space on the bottom
  - z1/virus-bass has UnknownMessage for initialization?
  - patch files could go in the Local/Instrument dir with the source?
    at least it should go in source control
  - colorize the info_pane so tags are easier to read
  - search lang supports quotes
  sysex
    z1
      - convert patches to larger pitch bend and send them back
      - I need control over which program and bank the patches go when they
        are initialized.  I can use the card as scratch space.
      - I also need to initialize a new multiset, and give the score
        a multiset config, or derive one from the midi config.
    vl1
      - test sending sysexes back
      - move patches to new format
      - figure out how to set category for builtin patches
        *word shorthand for category=word?
        but I want to use the inst name, not the score name...

OSC backend
  in doc/dev_notes/sythesizer
  - Write a simple supercollider instrument and try controlling that with OSC.
  - Even if reaktor and supercollider don't understand bundles, I could write
    a scheduler server that takes bundles and emits their msgs at the correct
    time.

jack: JACK: linux midi:
  bugs
    - something is still wrong, I get "no space in output port" and then
      corrupted output
    ? jack1 doesn't work at all: other clients don't see writes, until I quit,
      and then they get continuously spammed.  Apparently the jack_port_t*
      from the registration and the lookup are different.
      - Try stashing port from port_by_name port instead of jack_register_port.
  - does jack not support sysex at all?  Maybe I can't use it at all then.
  - Ensure that shutdown stuff is being called correctly.  I don't care but
    maybe JACK does?
  use jack transport
    I don't think I need to be the master.
    - When starting a play, call jack_transport_locate,
      then jack_transport_start().  The play then blocks on a lock which is
      released by JackSyncCallback when it gets a JackRolling state.
    - Register with jack_set_sync_callback.  JackSyncCallback sets a syncing
      flag, emits a Msg that forces the needed bits of performance, then that
      cmd must call back and reset the flag, at which point the sync function
      can return true.
    Then the next step is to test, and then figure out a way to get ardour to
    automatically set up a bunch of instruments and make MIDI in ports for
    them.

misc ideas:
  . Import or trace curve from a pitch tracker into the pitch track.
  - Staff notation represents chords well, but tracks don't.  Think of a more
    compact notation.
  - Why can't I write a 'tr' that generates pitch signal in some cases, and
    adds an attribute in others?  It would be redesigning control tracks so
    they are just note tracks that slice their children and apply
    a transformer to them.  I'm not sure that will coexist with the curve
    description language that control tracks currently implement.
    It would be interesting to get rid of track types entirely though.
  darcs to git:
    . https://github.com/purcell/darcs-to-git
    . http://darcs.net/DarcsBridgeUsage

planning / research
  cmj:
    - bezier-spline-modeling-of-pitch-continuous-melodic-expression.pdf
      Contact Bret Battey about PICACS: http://www.mti.dmu.ac.uk/~bbattey/
    - Wendy Carlos' tuning article: "Tuning at the crossroads", CMJ 11/1
  things for expressive music
    There needs to be some way for notes to affect surrounding notes.  For
    example
      . A trill might want to push the next note back a bit so it can complete
        its cycle.
      . Portamento might want to put controls points on a curve, so the speed
        a distance between pitches affects how quickly they approach, and
        quick notes will have less accurate pitch.
      . Gender tick affects the damping of the previous note.
      . If I control uses bezier curves, the curve is determined by the last
        control point of the previous and the first point of the current call.
    Other ideas:
      . Switch samples when played quickly.
      . Drum thing where successive strokes lose some energy.
    . Randomization is a first step, but true variation in playing is not
      random.  Things to study:
      . Tempo variation.  This is related to intentional tempo variation, but
        there should be slight tempo variations all the time.  This also has
        to do with higher level controls like rushing or lagging, and slight
        amounts of swing.
        E.g. some instruments may tend to rush when they want to be more
        prominent, or get louder.
      . Start / duration variation.  Related to tempo but at a lower level and
        less systematic.  Interpretation of staccato depends on surrounding
        tempo.
      . Dynamic variation.  Many instruments tend to get louder at higher
        pitches.  Tempo speed up tends to increase volume.
      . Pitch variation.  Some instruments tend to attack inaccurately and
        then correct.  Higher dynamics and tempo could make pitch less
        accurate.
    Modelling notation as a set of constraints:
      Notation specifies parameters along with how "fixed" they are.  For
      example, specified pitches are usually immovable, but onset time might
      be variable, depending on how important the beat is.  Higher level
      notation then assembles components and combines the constraints, and
      results in either conflicts, or a set of more specific constraints.

      . Example: janta attacks from below, normally one diatonic step, but
        avoids repeating the previous note.  A trill can end on either low
        or high, but if followed by janta, will change to avoid making janta
        repeat a note.  If trill speed is unfixed, it can change that,
        otherwise change attack time of the following note.  If the trill end
        is fixed, then the grace note must adapt by picking another higher
        note.
      . Carnatic ornaments change when time is reduced.

  think about grammar for ornaments
    . Notes have a syntax: there are ornaments or articulations only valid at
      the attack time, ones that apply to the sustain, and ones that serve as
      transitions to the next note.  Also, the shapes of ornaments vary based on
      the note or absence of a note preceding and following, in addition to the
      speed.  It makes me think of cursive Arabic, where letters change shape
      and placement based on the previous letter, along with rules about which
      letters go where in the word (I'm sure linguists have a name for this,
      e.g. English has "ng", but won't start a word with it).  I've noticed
      there's a tension between specifying exact times via a timeline or
      whatever, and the kind of higher level flexibility implied by a syntactic
      approach.  E.g. if you say "attack X, sustain Y, end with Z", you are not
      saying exactly when X, Y, and Z start and end, and they are free to
      arrange themselves according to context.  But you do need a certain amount
      of precise control over times, at least in some cases.
    . This is similar to the "constraints" idea, at least with regard to some
      aspects being flexible, while others are fixed.  For instance, if
      I write ornaments with no specific times: 'A; B; C' then the start times
      and durations are flexible, and its up to the interpreting code to
      arrange them, but if I make separate events for A, B, and C, then the
      times are fixed.  Of course I also want to be able to fix A and C, but
      leave B's position flexible.
    . How to represent this as events?  I think I need a "macro" facility,
      where a call can interpret following events as a separate mini-language.
      I used to have this, and could probably get it back, by re-introducing
      the "skip following events" return value.  In that case, some notation
      like a leading '=' would indicate that the start time is fixed.
      Otherwise, the event_start is irrelevant except that it's in between
      the previous and next events.
    . Or maybe I do it as sub-notes, that way the one on the left specifies
      the extent of the "note DSL", and I don't need a "skip following" hack.

  . Composition of score fragments.  Similar to the note grammar thing, this
    is a sublanguage, so I can sequence movements or sections without worrying
    about their timing.  It simply derives each one and concatenates them.
    I could implement it as a "sequence" note transformer call.

  . Give a visual indication of the events emitted by a call.  This is the
    note level version of the track signal render.  The underlying problem is
    that textual call names are not necessarily very clear about what the
    notes are, especially if it's a relatively ad-hoc call.  But I think
    I need a fancier GUI for this, since I'd have to have some way of turning
    a bunch of events into a distinctive looking graphic, e.g. a scaled down
    image of the block or something.
  - spline curve interpolator: evoral/Curve.cpp, www.korf.co.uk/spline.pdf

  - If I implement a VST host or patch a DAW to accept VST controls like MIDI
    controls can I get low latency high res controls?
