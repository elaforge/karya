LEGEND
  - todo; + in progress; * done; / obsolete, do not want, or can't repro
  ? open question; . note; bug: marks bugs.

NESS:
  Questions:
    multiplate:
      . You can define membrane and drumshell, but not strike them?
        . It seems like 'strike membrane1 ...' works, but is undocumented?
          Are there any examples of its use?  The demos on the website sound
          pretty good.
      . What's the point of the name on drumshell?
      . In plate, what's rho, H, E, nu, T60, sig1?  Membrane has the same
        parameters, but with an extra T.
        . nu = poisson's ratio?
      . In plate, what does the center coordinates mean?
      . What shape are the plates?  Square, circular?  I assume they're the
        same thickness everywhere?  Depending on the parameters, they can have
        a definite pitch, but where is the continuum between gong and tamtam?
      . How difficult would it be to add features like hand damping, striking
        with soft or hard mallets?
      . Multiplate can be slow!  61m for a 4 second simulation (5m in demo
        mode).  Are there guidelines about what parameters influence runtime?
        It seems like the presence of a membrane makes demo runtime go from
        34s to 5m, and sound become empty.

    soundboard:
      . Each string has its own frets count and distance from the string, but
        you can't place them, and since you can't press on a string, you can't
        generally hear them... I assume they're for collisions only?
      . What's the meaning of the baseboard profile?
      . Each string has start and end coordinates, what does that affect?

    guitar:
      - What's the formula to derive the sounding frequency from the string's
        length, tension, and material?
      - How about the inharmonicity value as used by string_def_gen()?
        I assume it also affects material.

      - "itnum" is presumably iterations for a newton solver... which does what?
      - I guess "tol" would have been its tolerance, but isn't used for the C++
        version?

    bowed string:
      - In this model you can directly set the frequency of a string, but
        isn't that determined by length, tension, and material?
      - The (instrument, instrument_numb) presets affect only strings, right?
        What string definitions do they correspond to?
      - What's kw, alpha, beta, lambda and M in the finger and bow definitions?
        Finger has an extra ku.
      - The bow movements have: w0, vw0, u0, vu0 (initial positions and
        velocities).  I assume w is vertical, and u is horizontal?
      - Then the breakpoints are (position, vertical force, horiz force).
        If the position is horizontal position, what's the relationship
        between it and force?  Wouldn't the force be whatever is necessary to
        put it at the given position and time?

    brass:
      - is the online version the same as the downloadable binary?

  guitar:
    Things that work:
      . Strike open strings, with possible collisions, "jawari fret".
      . Originally, sliding up worked, but not sure how to get that back.
    Things that don't work:
      . Interaction with frets is hard to get right.  If the frets are
        very close (0.0005), then there are lots of string collisions, but
        further distance produces only silence or unpitched jangle.
      . For instance, "fingering", striking with the finger at or below each
        fret, tends to just get a jangle with a tiny bit of pitch.  Also
        touching at or below a fret and striking the string gets a lot of
        collisions.  So try as I might, I can't get the effect of normal
        fingering.
      . Since a finger can only be in one place, I don't think I can do
        artificial harmonics.
      . However, with no frets and a more distant backboard, and touching with
        high force, I can get another pitch, which is presumably the string
        segment on the other side of the finger, which is a nice effect.
    Bugs:
      . Occasionally the guitar model renders the whole sequence with
        a high-pitched whine.  E.g. ness-data/whine-1
      . Segfault, probably when finger movements overlap.
      . Seems like >2 fingers on one string results in no sound output.
      . Negative times or string locations in finger_def causes segfaults or
        no results.
      . For the web interface, output directories marked with seconds means
        parallel submits are unreliable.

    * Try an instrument with several low strings, played on harmonics.
      . Replace note call with 'o'.
      . Play like yangqin.
      . Well, I can't replace "" because harmonic does Call.note, which leads
        to recursion.  Maybe Call.note should call "n" so I can do this kind
        of thing.
      . In fact, maybe I should rename "n" to something like "note" or "NOTE",
        since 'n' is likely to be overidden for something unrelated (nam).
      . The risk is that it will be confusing if I override "" but Call.note
        doesn't do it.  But I think all current "" overrides come from
        instrument definitions, and MidiInst.null_call also overrides the "n"
        call.
      . Wait this is still broken as soon as someone calls Call.note, e.g.
        trem.  What I want is trem calls "", but 'o' calls NOTE.  Is it even
        possible to do it in general?
      . I could make a custom 'o' that calls the note call directly.  In fact,
        maybe I can make any call a "bottom" call by making it revert the note
        call.  So maybe this works: "" calls '^ = NOTE | o'
      . So was that whole NOTE change just pointless?  Kind of yes, but it
        still seems like a "" / NOTE division is useful, and 'n' is definitely
        a bad name for it.
    - Experiment with string connections for sympathetic strings.
    * Why do I get attack artifacts?
      . First, I need a stronger touch, like 0.5.
      . I get a cleaner sound if I go from zero to finger from t-0.05
      . I can't release without a new note.

    - Maybe I can use the "jawari" fret with parallel strings as a special
      effect.
    . Can I get a muted string effect by plucking while touching with low
      force?
      . Yes, sort of, just don't touch a node.
    * Get harmonics working.
      . 1/256 is a good finger pressure for harmonics, 4/256 at a high node is
        good for a muted stroke.
      . For general harmonics, I should be able to address by harmonic number,
        such as 'string=x | o 3', but also find a harmonic by pitch, with
        optional string restriction.
      . For the latter, I can use the harmonic guessing heuristic the lilypond
        call uses.

    * Ornament for strums.
      . zheng gliss should be able to do this.
      . But it only does open strings, I'd have to extend it to work with
        stopped strings.

  * I need a better way to name strings.  string.idiom needs pitches, but the
    instrument needs symbolic names.
    . Maybe I could use custom pitches with a symbolic name, then convert via
      PSignal.pitch_note?  It seems like a misuse, since it's not really the
      pitch name.  Unless it is, and I also name the strings like that, but
      then I can only use an instrument with one scale.
    . Articulation.c_harmonic open_strings uses [NoteNumber]
    . Or why not use PSignal.Pitch, but the instrument definition converts it
      to a Text of the NN?
    . But I can't use just NN as string name, because then it breaks on
      scales.  It's the symbolic name.
    . I can't put PSignal.Pitch in the patch for open_strings, because Pitch
      can't go in a RestrictedEnviron.  Even though these patches are
      definitely code, and don't need to be serialized.  I only need
      RestrictedEnviron for local config, which is saved with the score.
    . Other than that, is using PSignal.Pitch for strings ok?  Basically
      I need a symbolic name and a NN, which is basically what Pitch is, minus
      the transposing stuff.
    . I think only Common.config_environ really needs to be RestrictedEnviron.
      But since Cmd.ResolvedInstrument merges common_environ into
      Common.Config, I'd have to make the environ a type parameter.
    . But there's no reason the string kind of pitch can't be in
      RestrictedEnviron, because it's just a pair.  So the other approach is
      to add an untranspoesable pitch to RestrictedEnviron.
    . Would it be really awful to just call it VPitch?  Then coerce via
      PSignal.constant_pitch.  The danger is silently casting away
      transposability, for instance put pitches in patch environ and expect to
      transpose them.  I could make it a bit clearer by not having ToVal
      Pitch, but requiring an explicit constructor, or ToVal ConstantPitch.
    . Setting patch element in the note call doesn't work, because it's too
      early.  I assign string via postproc.  So I need to assign at convert
      time.  Don't I have a postproc field for that?
    . Yes, Cmd.inst_postproc.
  - How to do strums and rolls with harmonics?
    . A roll transform would do it, and fix the grace note problems too.

  - Have some way to more easily switch between kontakt mockup and ness.
    . How would this look for real?  A hybrid instrument that writes to im but
      otherwise acts like a MIDI instrument.
    . But on playback I want either im or not, which means I'd have to tell im
      to mute the tracks that are now MIDI.
    . Or I could just use a custom thru, but then I can't get the playback
      mockup.  But in the longer term I'm hoping incremental rendering can fix
      that.
  Expressive things:
    . mute note: just do a short note?
    . pdm: make a quick turn at the beginning.  Use hybrid tempo?
    . ping: rapid pitch drop
    . roll

  ideas:
    . yangqin?
    . play string like reyong, with a hand damp
    . string like gangsa with noltol
    . jawari like tambura or sitar
    . solkattu for metal percussion thing
    . can I hand damp metal percussion?

UNSORTED
  - If I use cpphs I might be able to use \ string continuation for CPP
    modules.  It would add another dependency though... worth it?
  * Why does verify_performance give a bunch of "%breath clipped" warnings?
    . 'd' call is going below 0, but it doesn't look like 0 in the track signal
    . I got rid of the 'd' and 'u' limits because stopping at 1 doesn't make
      sense for the tempo track.  Stopping at 0 does, though it should be >0.
    . How can a track tell if it's 0-1 or not?  I could put a normalized-value
      key in the environment.  Cmd could also use it instead of inferring
      based on other 0x events.
    . Most controls are 0-1.  But if I use scale it can be -1 to 1.  Tempo is
      >0.  I think it's ok to limit to 0..1 for -1..1 tracks, because it's
      clear what's going on and it can be overridden.  limit at 1 for tempo is
      confusing though, so I can have it put a key in the environ.
  * fltk: track signal should put a line at 0
    . Why does track signal not look like 0?  Oh, because the draw code
      assumes it's -1..1 and scales accordingly.
  - It seems there's no way to explicitly pass Nothing if the default is Just,
    because _ turns into set the default.
    . Ultimately I think because VNotGiven is special-cased in Derive.Sig.  I
      would need some way to distinguish between "give me the default" and
      "pass Nothing".
    . I could change the default to "pass Nothing" by having Sig check the
      type against VNotGiven and only default if it fails.  But of course
      now there is no way to indicate "use the default" for a Maybe argument.
      This might be more likely to be what I want, but it's inconsistent in
      that the type of the arg influences the process and nothing else does
      that.
    . Meanwhile, there's never a point to defaulting to (Just x) instead of x.
  - generic deriving Monoid?
    . Probably not hard with generics-sop, but what about stories of
      GHC.Generics hurting compile and runtime?
    . How about monoid is_empty that doesn't use Eq?
  - Attributes are not necessarily suited to fundamentally exclusive
    articulations, like striking technique.  For NESS strings I use the
    'element' field, maybe I should be using environ for that at the score
    level.
  * harp harmonic 'o' sticks, I think because it knows to unset keyswitches,
    but not controls.
    . But the next one has control 0, shouldn't it know to cancel?
    . It only cancels keyswitches because all notes explicitly have one.  So
      I need to say if you're not 'o', then %harmonic=0.
  - Switching to Symbols.default_note means any event created via Call.note
    winds up with event_text="NOTE", which is not as informative as the
    original text.
    . Was in always "" before?  If so it's not really a regression.
    . I'm back to Call.note using "" again, but I should still check this out.
  * make Articulation harmonic call use StringUtil.find_harmonic
    . Remember to special case string=Nothing, open_strings=[]
  * Don't allow multiple copies of seq, it's really confusing.
  * Make Cmd.InstrumentPostproc return (Score.Event, [Log.Msg])
  - string_idiom should ignore notes that already have a string.
  * Make Derive.with_constant_control add Score.untyped
  - It's easy to forget to place the note when I use Call.pitched_note, should
    it take args and do a placed_note?
  - Let synth defs log warnings
    . So e.g. MidiInst.compile_library can report shadows.
    . I should be able to incorporate Faust.PatchDb.warnings too.
  - Generic Show and Pretty instances for ScopesT and Scope.
  * Add qualified syntax for calls, so I don't have to import them.  E.g.
    string.idiom.bent-string.
    . I naturally get dots in numbers.  Try qualified only if unqualified
      lookup fails.
    . The [LookupCall] structure is not that great for looking up modules.
      I should have Map Module (Map Symbol Call, [LookupPattern]).
    . But then I'm back to needing a different format for CallMaps, because
      I want to preserve duplicates so I can detect them when merging to
      a Map.  CallMap should be [Either (Symbol, call) (LookupPattern call)]
    . What should the names be?
      . Library for the stuff declared in Derive.C.  This way I don't have to
        change all those again.
      . CallMap for the "compiled" version in Derive.
    * Update Deriver.Lib to use CallMap instead of LookupCall.
    * Implement Library.compile.
    * Use Library.compile in C.All
    * I still have to update all the C modules to Library.Libary
    * CallDoc is a pain because it used to be both Scopes and Library used
      the same LookupCall.  Now Library uses Entry and Scopes uses CallMap.
      So I have to convert CallMap to [Entry]
    . Actually, not so, I'm converting from Builtins, not Library.
      I can ignore the Module, since it's in CallDoc.
      ? But where do I group by it?
        Only doc_html does, in the output.  I guess that's ok?
    . So I don't need Library or Entry at all now... but maybe I should keep
      it anyway, since it flattens CallMap into a list that expresses
      resolution order.
    . It turns out it's really annoying to add every single permutation for
      scope record access again for Builtins.
      . It's annoying because ScopesT is polymorphic, so the definitions are
        all the same, but I can't say ScopesT a b c -> (a|b|c)
    . I can cut down by making Callable on the call type, e.g. Generator Note,
      but then it's more annoying to use, because in the limit I need
        (Callable (Generator d), Callable (Transformer d), Taggable d) =>
    . The problem is always the 2 axes:
      {generator, transformer, track} * {note, control, pitch}
  - Typecheck PSignal.Pitch instance for NoteNumber could use Twelve.nn_pitch.
    . Except it can't because of circular dependencies.  Maybe instead
      Twelve.nn_pitch should replace the one in PSignal.
  - Maybe 'set' should be the default merger, not mul.  It seems less
    confusing.
    . I could still have 'dyn' default to mul, if that's not confusing too.
  - decide if the ( call is called slur or legato, not half and half.
  - Use EnvKey.string for string selection in vsl, not attributes.
    . It would be nice to be able to select by name instead of NN, but the
      calls like NNs.  Maybe val calls that emit the right NNs.
    . I'm using pitches with e.g. '60nn' for names.  g, d, a e are still
      a better UI though.
  * Print something on stdout when I can't find the file to load from the
    cmdline.  Otherwise I get confused.
  - if 'roll' were a transformer I could do 'roll | some-note'.  This is the
    same problem as extending 'grace' to be able to put stuff on the main
    note.
  - Pitch bend doesn't work right on a MIDI instrument with patch scale.
    . Likely because the pitch gamut is not linear, but pitch bend is.
    . I would need to warp the pitch bend by the patch scale... but don't I do
      that?
  - It seems too complicated to set up patch scales, how can I make that
    easier?
  * enable FlexibleInstances globally.  Should I add any other instance ones?
    TypeSynonymInstances?
  - Highlight for block calls which are 1:1, or not 1:1.
    . Use event width for this?  But this is a different mechanism from
      highlights, which uses selections.
    . Or use event color.  Effectively the highlight does that though.
    . How to get the highlight?  Other highlights are postprocs that attach
      the highlight, but I think I can get the block call itself to do that.
    . But highlights go on Score.Events, and this is a UI event.  I could
      extend LEvent.Log with a general Metadata kind of thing, or I could
      also attach a highlight to the first event from the block.
    . The latter means highlight needs to support a time range, and of course
      it won't work if the block produces 0 events.  But in that case it
      doesn't matter if it's 1:1 or not.
    . The problem with LEvent.Metadata is that I don't want to rewrite all the
      LEvent stuff to also deal with logs, but I don't want to pay another
      indirection.  But if I put UNPACK it should solve that:
        data LEvent = Event a | Log {-# UNPACK #-} Log
        data Log = Metadata X | Msg Log.Msg
      Does that work?
    . What other things could I put in Metadata?
      . Highlights for one, I think a ScoreTime range is more appropriate than
        taking RealTime from the events, since the latter is wrong if the note
        extent doesn't match the score extent.
      . What about integrate?  I currently have a special spot in
        Derive.Results, but I could also emit it as a meta-event.
      . But for that matter, why not put highlights in Derive.Result?  It
        seems more elegant to favor the explicit Stream return value over
        implicit Collect results, but the logical conclusion of that is to get
        rid of Collect entirely.  I think I don't want to do that, because
        I take advantage of monoid merge to discard data.  But on the other
        hand, if the output stream is lazy, then it's just the same to do the
        same collection while iterating over the result.  This would make it
        explicit that to get collected data I have to iterate over the events,
        instead of how implicitly touching some fields actually implies
        evaluating the score.  Also I could evaluate Collect only up to
        a certain point, though I don't think I ever want to do that.  And
        then it separates result collection from the deriver, so maybe more
        modular.  Could it be more efficient?  I might spend a lot of time
        combining memptys. and a final fold might get rid of that.  Presumably
        I'd use an ADT for the metadata instead of a record.  On the other
        hand, it's more cons cells for the stream, which maybe means more junk
        to skip when sorting and merging.  Maybe I could mitigate that by
        collecting Metadata together into short vectors, which can be skipped
        as a unit.  It's only a win if they tend to clump together.
      . What would the metadata be?
      . Also I should profile to make sure about Collect usage and of course
        to see a difference if I switch.
      PLAN
        - profile current status, look for Collect allocation
        - enumerate the things that go in Metadata
        - verify UNPACK can flatten Log event
        - estimate work to switch
        - sketch out where and how the collect fold would happen at the end
        - ensure Streams are lazy... I think transforms might actually destroy
          laziness.  But would getting rid of Collect be able to restore it?
          I'd have to do something about exceptions, maybe put it in as
          a Metadata too.  If I can make the whole derivation fully streaming
          then this might be a big win.
  - binary-serialise-cbor is out and implemented by serialise, try switching
    save format to that.
    . But figure out how to use the built-in versioning first.
    . I can, but the encodeListLen stuff is awkward.  Can I get rid of that?
      Maybe make instances for ()?  Of course there already are such
      instances, so maybe just use them?  The result is it goes
      [tag, length, ...] instead of [length, tag, ...], but the former makes
      more sense to me anyway, since the length will likely be different
      depending on tag/version.
  - Adding a new track puts a bit of extra padding on the right side.
  tabuh gari:
    * infer-damp for trompong, or better reyong one
      . After ngoret, the first note overlaps the grace, so the damp is later.
      . But why two +mutes?
      . I should treat a note end before the next note as as a suggestion to
        mute there, which can be ignored.
      . So first transform to use explicit mutes.
      . Normally ngoret's grace note doesn't get damped, so give it +undamped.
        Sometimes it might though, so it could have a flag.
      . Or I could accept the overlap, and infer that I can't damp the grace
        note while striking the next.
      . It was all due to using infer-damp instead of realize-reyong.  Ouch.
    * Have a Derive.run_logs :: Log.LogMonad m => m a -> Derive.Deriver a
      which lets me run pure-except-logs.
    * Log events with their stacks.

    * double strike, like 'oo'
      . For after, I have 't oo', for before I have '-.
    - octaves notation for trompong
    - octaves for gender rambat
    - I get the wrong pitch on too-high trompong notes
      . It shouldn't try to emit pitches above its range.
      . I should extend the samples up a couple pitches anyway.
    - how can I write angsels?  E.g. same as template, but with bits replaced.
      Score derive?
    - It's inconvenient to have two roots, because play-from-root stops
      working right as soon as I change it.  But it does have a definite
      single caller, so shouldn't it be able to figure out a root all the
      same?
  - It's really tempting to put a '>inst = %dyn=.5', but that just forces it
    to always have that dyn.  How can I set a per-instrument default dynamic
    which I can still override?
    . First define exactly what I want.
    . I want to set a baseline dyn per instrument, but I want to be able to
      override it.
    . It should be as if I set a global %dyn, so specific ones can override
      it, but only for that instrument.  So each 'dyn' affects all dyn-*
      signals, and then each instrument can pick out its dyn-me.
    . And of course this should generalize for all controls... well, I don't
      have a use for non-dyn, so I don't really need to generalize.
    . If I always set dyn absolute, I could just set when the instrument comes
      into scope.
    . Wait, why does '>inst=...' not work?  Wouldn't it set at the note track,
      and then the child dyn track would be able to override?
  - Can I have ^j and ^k only move events up to a limit?  How do I set the
    limit?
    . Here's a use for multiple selections.
    . If there's a secondary selection, it should disappear somewhat
      automatically, so I don't get confused by it still being around.
    . Maybe I can get space to do that?
    . Or I could set it to a timestep, e.g. one measure.  Then it would turn
      into move within measure.
    . If I stop clipping events at the end of a block, it's not so annoying to
      move everything, as long as I move it back.  I guess it's still kind of
      annoying though.
  - Figure out how to control vsl legato transition volume mismatches.
    . slur call has a legato-dyn arg to try to address this.
    . Look into http://www.beat-kaufmann.com/vitutorials/index.php
  - (Sig.typed_control "tr-neighbor" 1 Score.Diatonic) when given 1 returns
    an untyped ControlRef.  Can I make it default to Diatonic?
  - ^o should ignore orientation on child control tracks.
    . Otherwise, it would confusingly not delete +0 controls on a negative
      note.
  - LRuler's sections*per_section is awkward when I'm really thinking in
    measures.
  - I had a bug due to using 'Derive.real dur' instead of
    'Call.real_duration start dur'.
    . Separate types for {Score,Real}Time and {Score,Real}Duration would fix
      this, but how much hassle would it be?
  - An 'accent' call on squart/6 @b4 causes a very distant %breath sample to
    go >1.  Why is the note including such distant samples anyway?  Isn't it
    inefficient to scale samples which are clearly not in the note bounds?
  - I often want to see where I am in the parent, e.g. like parent->child
    selection but the other way.
    . I can get this by playing from the point, but why not do it
      automatically?
  - I'd like to use Ui.allocation lens for modification, but I need to be able
    to put it in the monad.  Research once and for all how to do that with
    either fclabels or van-laarhoven lenses.
    . Looks like fclabels can do it, but I need separate monadic lenses, since
      monadic and non-monadic lenses can't be composed.
    . I should be able to write a function to promote a pure one though.
    . Actually I can't figure out how to get lenses to do this.  Lenses can't
      include the Ui.modify, since they have to be composable, which in turn
      they have to be used with Ui.modify, which is the thing I'm trying to
      not use all the time.
    . So maybe just get rid of Ui.allocations.
  - upgrade to ghc 8.2
    . 8.0.2 compile time:
      debug/seq     257.19s user 35.01s system 341% cpu 1:25.63 total
                    242.37s user 32.71s system 336% cpu 1:21.78 total
      opt/seq       619.43s user 44.95s system 331% cpu 3:20.30 total
    . 8.2.1 compile time:
      debug/seq     225.21s user 32.80s system 338% cpu 1:16.20 total
                    201.57s user 30.43s system 328% cpu 1:10.53 total
      opt/seq       712.50s user 42.71s system 329% cpu 3:49.21 total
                    760.40s user 45.88s system 323% cpu 4:09.25 total
    - conduit-audio has base <4.10, I can patch but author is not responding
      . Patched locally, but I'll need a long term solution.
      . Should I fork, or write my own?
    + ghci thinks I have flags changed again
      . f= build/test/obj/Util/CallStack.hs.o; rm $f; mk -V $f
        ghcit -v1  :load Util.Control
      . Flags are same from -XBangPatterns to -fno-warn-duplicate-exports
      . But ghci-flags is missing -W -fwarn-identities ... etc
      . Looks like shakefile uses it twice.
      . ghc -c
        [ -outputdir build/test/obj ... -fno-warn-duplicate-exports ]
        -dynamic
        -fhpc -hide-all-packages -package=...
        Util/CallStack.hs -o build/test/obj/Util/CallStack.hs.o
      . -dynamic
        [ -outputdir build/test/obj ... -fno-warn-duplicate-exports ]
      . Maybe it now considers a flag it didn't consider before?
        But the only difference is -fhpc and packages.
        . And -fhpc can't be used for ghci.
      . Or maybe ghci is including some flag it wasn't before?
        . /usr/local/bin/ghci -ignore-dot-ghci $(cat build/test/ghci-flags)
          also no help.
      . Even with minimal flags, it's still "flags changed."
      . Looks like it is -fhpc, but I can't provide that in ghci.
      . Then why is this tests only, what about opt?
        . Because -O is different, but I can't include that either for
          --interactive.
      . Still works for debug.
      . ghc/compiler/iface/MkIface.hs:checkFlagHash
        iface/FlagChecker
      . Due to https://ghc.haskell.org/trac/ghc/ticket/11798
        https://ghc.haskell.org/trac/ghc/ticket/10923
      . Sent mail to glasgow-haskell-users
      + Trac ticket: https://ghc.haskell.org/trac/ghc/ticket/13604
      . Should be fixed in 8.2.2.
      . Nope.  Maybe the next release.
  - generalize zheng 'gliss'
    . It would use scale instead of open strings.
    . If I wanted to be fancy for harps I could do gliss on whole note or
      diminished minor sevenths that repeat strings tuned to unison.
  - >kontakt/kendang-bali-pasang doesn't work as a dummy instrument because
    those can't have the Patch.Triggered flag, or any flag.  I could move some
    flags to Instrument.Common, but what's wrong with having a MIDI instrument
    with no allocation?
    . Triggered is duplicated in Im.Patch, so I could get rid of that.
  - can I have a block template kind of thing, with a standard set of
    instruments?  Maybe REPL cmds.
    . E.g. for a standard orchestral template.
    . I could also add a track for each allocated instrument, but I'd need an
      order.
  - Also cmds to re-order tracks by instrument.
  - How to add grace notes to a non-null call note?  Also what if I want
    non-null grace notes?
    . I can make a 'g' transformer for the first: 'g 0 1 | x'
    . For all maybe a grace-transform env arg.
  - squart/6 has some jumpy dynamics due to sets in dyn with a scope over them
    e.g. end of @b3, vln2
  - It would be nice to have a text interpolation syntax
    . E.g. "textlike: %s, %v ShowVal, %p Pretty, %x hex, %.3f showFloat 3"
    . Cmd.Load.Mod2.commands_to_controls: "from=%v | %s %v" vol c val
    . But printf style can't work for typeclasses without dependent typing
      because it doesn't know which one to select.
    . text-format: requires importing a bunch of formatters, type-unsafe
      . format "from={} | {} {}" ('val vol, 'str c, 'val val)
      . I don't like it because the format type is out of context.
    . formatting: import a bunch of formatters plus (%), type-safe
      . Probably worse errors.
      . format ("from="%'val%" | "%'str%" "%'val) vol c val
      . Still much noisier than "from=%v | %s %v".
    . fmt: even more operators and imports
  * The EvalTrack rule that skips events that are all comment event is
    confusing, because you have to replace a note with 'n -- blah'.
    . Make the "skip totally" triggered by '--|'.
    . Search dumps for '--', update doc/*.
    . Except control tracks don't have a "" call, so plain '--' is available.
      But maybe not do that anyway, for consistency.
  load octamed files
    - implement set tempo and set frames cmds
  / why does fltk on linux subtract 100 from window width and height?
    . does os x? nope
    . Actually it doesn't, it just affects what fvwm prints for the window
      size.  It prints actual size - window.size_range(w, h).
    . In fact, fvwm always does that for non-fltk apps like xev.  Maybe it's
      a feature.  Probably it's the "client reported" size, e.g. xterm uses
      rows/columns.
  selection-orientation branch cleanup:
    - set_duration: If I have ><---|, I can't set the negative event back to the
      zero dur event because it sets the previous positive event, regardless of
      selection orientation.
    - Slice range should be Events.Range so it can remember the orientation.
      Otherwise I think -0 note slices don't work.
    - I think Slice.events_in_range should get an orientation, which in turn
      means checked_slice_notes needs one.  Otherwise don't negative notes
      not get the end event?  But Sekar maybe relies on include_end.
    - Perhaps related, I removed include_end since negative should work for
      that, but Sekar used it.  Can I use Sekar with negative events to get
      end bias back?

  - QuickCheck for Midi.Encode_test just for practice
    . Ui.Events_test.test_from_list_qc is an example.
  - Will TimeVectorStorable.Sample Double have both fields unpacked?
  - I'd like to make a local scale derived from another one but some notes
    missing, and have input and transposition skip those.
    . Ideally it could be a modifier to any scale, so it would modify input
      and transpose accordingly.  Symbols remain the same.
    . I'm still unhappy with the Scale.Make Make|Simple thing.  Returning
      Scale from a val call would be better, but I think that runs into the
      big Derive / Val circular dependency problem.
    . Do as a Make for now.
  - bug: Track 'mute' status gets increasingly off.  Surely this is due to the
    bug fix in c523680838564ec55752302d1d591482971b9190 where I no longer do
    only absolute updates to the skeleton.
    . Can't reproduce this now.
    . It happens in save/bali/kebyar-duduk, e.g. mute reyong part in @b3
    . It definitely happens occasionally, but always when I'm busy.
  - Add 'angklung' and 'beleganjur' scales.
  - BaliScales should have a default ombak, depending on laras.
    - Also there should be a way to randomize per instrument, so it's not too
      perfect.
  - Legong scale umbang and isep is too close.
    . Maybe something wrong with how I retuned the sc gamelan samples.
  - TSymbol could have a descriptive arg with e.g. instrument, scale, etc.
    . This would get back the documentation I lost when I got rid of
      VInstrument.
  - OutOfRange pitch error should show the pre-transposition pitch.
    . In fact, all the errors from e.g. Pitches.pitch_nn should be annotated
      with information about the pitch.
  - Cmd.Ky: Keep the defining file in a special slot in the call doc, so I can
    print it out in shadowed msgs.
  - Cmd.Backend's Midi.Patch is redundant, since the Inst already has it
    . Not quite, since Backend encodes that alloc and patch backends are
      equal, but is it really necessary?
  - do a renaming pass on all the prev/next pitch function names in Derive.Args.
    . Should Prelude.Pitch.approach use the lookup pitch style?

  - it looks like special kajar calls like 'oo' mess up track signal.
    . I can fix 'oo' by making DUtil.doubled_call inverting, but that doesn't
      work for 'o..'.
    . DUtil.multiple_call doesn't need inverting because it dispatches to
      call that do invert, right?
    . Actually it's pretty pernicious, because without inverting, doubled_call
      will still appear to work because the underlying call inverts.  But
      TrackSignal gets messed up, and if it did anything based on controls
      then they would not take child controls into account.
    . Why is TrackSignal messed up though?
  - do nruk with a static macro
    alias 'o..' 'nruk | o'
    . I could modify c_nruk to have a generator version that takes a deriver,
      but then I have to copy paste it.
    . How can I inherit args?  StaticMacro is no good because I want the
      generator to be late bound.  But 'nruk' should be static bound because
      it's in another module and I want to inherit its args.
    . What I really want is to inherit args and docs from the transformer, and
      apply to the generator dynamically.  So something like a static macro
      where I give all args to one transformer, and the generator is dynamic.
      I think I can do the former with a special arg, and the latter with an
      eval "static call".
    . But what happens with StaticMacro when it hits a Sig.many?  I think it's
      broken.
    . To support this, Sig.required_vals needs to support 'many' parsers.
      I could infer from ArgParser but it seems like it's getting too
      complicated.  I think at that point I had better just be able to copy
      the parser over.  Can't I just reapply to the callee?
  save/sketch/16-04-10-charukesi:
    - fltk/EventTrack.cc:109 sample time didn't increase: 37.2 <= 37.2
    - Use kotekan for >wy with sargam scale.
  - I should collapse adjacent Collapsed tracks so they don't turn into
    a giant blue block.
    . If I do it at the fltk draw level, then I don't have to worry about diff
      complications or tweaking indices, but I still have to model as fewer
      widgets so the index tweaking just happens lower down.
    . If I do it at the haskell level, hopefully I can reuse the existing
      Track / DisplayTrack distinction used for collapsed tracks in the first
      place.
    - I have to also collapse the skeleton, which means I need
      a Block.display_skeleton and Block.display_integrate_skeleton.
    . However, I'm not sure it's worth it.
  * The error selection is still hard to see on a busy block, I usually have
    to zoom in and do it again.
    . I think to be more visible it would have to blink or somehow be larger.
      Ideally I could have some kind of glow
      Or maybe red is just overused, if it were green or blue?
  vsl:
    - figure out how to do tuning
      . I think it needs to be pitch bend, since it doesn't seem to respond to
        MTS.  But VSL ensemble should be able to load multiple copies of the
        patch and share sample data.
      . Figure this out before doing too many more patches, because I'll have
        to update them all with global control config, unless there's a way
        to copy paste that.
      . However, it apparently can be used with hermode, so not sure how that
        happens.  Maybe I can just ask VSL support.
      . Scala files are not very good because I'd have to go manually load
        them every time, and they're static.
    . Legato attack scale control affects the crossfade level of interval
      samples, experiment with that.
      . Wait, where did this go?
    . figure out how perf reps work, and how I should handle them
    - make sure perf_upbeat_repetitions are consistent
    - make sure grace vs. grace.updown is correct
    attribute groups:
      . bass clarinet has nv without vib
    - rename +sec# to +s#?
  - Perf.lookup_instrument on a pitch track could look at its note track.
  - I forgot to add Sub.inverting to mridangam.p1 and mridangam.pn calls.  Can
    I have a warning for when a non-inverting call has a note track below it?

  - empty track doesn't get an Environ, which causes Cmd.Track to not be able
    to find the instrument.
    . It was because the kendang tracks were below >pno, not "tempo".  So, two
      problems:
      . It's too hard to see that the skeleton is wrong.
      . Note track children should have dynamics too.
  - Do I need Perform.perform_control_msgs.trim or not?  Figure it out and
    write a test if I do need it.
  - fix control scope in parent events that cover up an orphan, as
    demonstrated in Sub_test.test_overlapping_parent_control_scope
  - Better solution for the "sample at end of block" problem, as demonstrated
    by Block_test.test_trim_controls_problem
  wayang
    - Infer late damping.  E.g., if there is a jump wider than 2 notes, then
      wait until the hand is free for long enough to damp it.
    - Automatically fill in weak notes?
      . This also applies to reyongan, even more so.
      . In fact this is similar to noltol.
    - many double strikes or ngoret tones land a bit ahead of the beat
    - I want some optional ngoret to happen the same way in both hands.
      I could make it apply to a parallel kempyung or octave.
      . I'd need a fancier ngoret that understands 'inst-top' so it can go
        down if necessary.
  - thru on *legong notes is wrong the first time
    can see this editing rehearsal/kendang-legong
  - %sus-abs=-.x is not quite right for detached, because it should scale
    a bit for shorter notes.  E.g. it's absolute but scales down to 0 below
    a certain threshold.
  - network midi doesn't seem to handle abort?
    playing the second time doesn't happen
  - I have a feeling like FM8 doesn't obey ResetAllControls
    Maybe I should extend Midi.Interface.note_tracker to keep track of
    used CCs to issue resets for them.  Some reset to 1, e.g. cc2 and cc7,
    the rest reset to 0.

IN PROGRESS / branch: branches:
  . This has longer term projects, which are partially complete.
  signal-discontinuity:
    . I need a more systematic solution for signal-discontinuity.
    . A solution here should also be able to solve signal-offset below.
    . As well as docs for the NOTE in Util.TimeVector.
    . Also I worry that it's more expensive but unnecessary for MIDI.  Can I
      disable it if there are no im instruments?
    . Possibly I can model the signal as line segments, not Samples?  If
      I still want it to be disabled, then I'd need some awkward thing in
      between.
    . Or maybe I can optimize the flat line somehow?  The reason I originally
      didn't go with line segments was that I didn't want every single MIDI
      style sample to wind up as two.  I could have some magic flag to
      indicate flat until next sample.
    . But am I really sure efficiency is a concern at all?  Signals are
      relatively small, and I have a lot of memory.  Most memory is probably
      used up on lazy thunks or something anyway.
    ? Actually I should know what most memory is used on. Do some more heap
      profile runs and write that down somewhere.
    . Should I get rid of score level srate, and put it in the MIDI performer?
      In practice I haven't used srate for special effects, and even if
      I wanted to I could insert a sample and hold.  All I've done is adjusted
      it down for gamakams.
    . Then of course there's the continuous signal idea: signal is just
      a function.  This would solve efficient translate and scale too: just
      compose with another function.  If I can figure out the coerce to
      Typecheck.TypedFunction thing, then that's how the Derivers see it too.
    . Explicit line segments or a continuous signal or whatever would also
      fix the problem where Signal.constant uses [(0, y)]... but then it
      doesn't work right at <0.  Or Signal.constant could use -big_x.
    . Investigate hermite curves in 'interpolate' package.
      The curve-fitting stuff would be useful for eventual recording.
  - ControlFunctions are still super confusing. NOTE [fix-control-functions]
    . Yet another confusing thing is that they don't work for arbitrary
      signals given to notes.  I think it would be better to override '' to
      get e.g. %location as %location + rnd ...
    . E.g.  '%strength=.5 | %strength=(cf-rnd ...)' means it looks like
      %strength is .5, but it's actually not, and the only way to get rid of
      the CF is %strength=_.
    . Also the whole implementation is a mess.  Isn't there some other way to
      randomize signals?
    . I could pass a Quoted, and then control functions are val calls that
      return Quoteds: (cf-rnd control 0 1)
    . Then I want to be able to treat those as signals, or coerce them both
      to the same thing.  Really that's a SignalFunction, or maybe just
      RealTime -> Deriver Y.  So this turns into the problem of how to coerce
      various types into SignalFunction, but not have to have an opaque
      SignalFunction for all the defaults.
    . I could have a Convert typeclass.  In fact maybe it would be cleaner to
      split Typecheck and Convert?
      Typecheck: Val -> Maybe a, Convert: a -> b
      Convert would be: Int -> SignalFunction.
    . I think this won't work because the intermediate 'a' will be
      ambiguous.
    . I can always have a Default class that is used only for Sig defaults,
      and provides both ShowVal and the coercion.  It would mean I have to
      duplicate everything in Typecheck, unless I use an overlapping
      typeclass.  Or I could default to... what exactly?
    . The problem with `Convert a b` is that 'a' needs a type annotation,
      which would make signatures annoying to write.  Normally I don't need
      them because they are the Typecheck val, which already needs to be
      fixed.
    . Or I could have defaults be either a Typecheck val, or
      (Doc, Typecheck val), and then have an explicit constructor for Function
      which promotes various types to (Doc, Function).
  Support for adding or removing time in the middle of a score:
    . Status: this is implemented manually via Cmd.BlockResize, and
      specifically LBlock.add_time and remove_time.  It seems to work, but I
      haven't used it extensively.
    - Add a variant of ^z that moves events below and track children.
    . This has overlap with the idea to have a track as a read-only view of an
      expression.  E.g., the expression would be b1, b2, b3, ..., and the
      view would be to get the CallDuration of each and sequence them.  The
      trick is that it would have to re-integrate whenever the callees changed
      CallDuration.  In this approach, I'd have a separate expression with the
      sequence of calls.  That would then be bound to a track, which would
      then become read-only.  I'd have to edit the original expression.
      . The cmds that change a block ruler could trigger re-integration in the
        same way they would have to trigger the caller resize.
      . Even in this case, I need something to put in for ruler.  I guess I'd
        use 'extract'.
      . It may be more awkward to edit the expression instead of directly
        editing the track.
      Advantages:
        . It would be a specific case of a generalized integrate-expression
          feature, which I'm pretty sure I'll eventually add anyway.  Actually
          I can just add an optional read-only option, otherwise it could be
          integrated as normal.
        . If I lock a whole track, then I don't need some special "time locked
          event", I have a whole locked track.  That seems simpler because it
          doesn't have to coexist with normal events.
        . I don't have to scan blocks for calls, since they are explicitly
          listed in an expression.  Presumably the expression is data, not
          code, so I don't have to do any evaluation.  But maybe I have to
          evaluate anyway to get CallDuration?  But it seems clearer to update
          specific expressions, rather than just scan the entire score for all
          calless and try to mess with their durations.  Also, mixing block
          call events and normal events is not necessarily something I want to
          support... even though I have done it in the past.
      Disadvantages:
        . Another language.  If it's just linear sequence then it's trivial,
          but surely that won't be enough.
        . The whole point of the track is that I can line things up in time,
          and I still want to do that with score blocks.  Why should I wind up
          with a whole new language for that?  E.g. initially it's just
          sequence.  But then I want 'clip', so I need explicit durations.
          Then I want time gaps, so I need start times too.  Then I want to
          express alignment, so I don't have to calculate start times... and
          in any case, those times will be invalid when the callee changes, so
          I need alignment anyway.
        . But the clip problem is something I need to express anyway.  In
          a language I could say "Clip | awak" dur=-1gong, but how would
          I tell a track version that?  I guess it would just not update the
          duration of clipped calls.  In fact 'clip' and 'Clip' could express
          that by setting the CallDuration to the event duration.
      . But in fact I don't need a locked event at all, I can just update it
        on demand, but have no particular requirement that it stay that way.
        I could do a universal thing where block calls get a subtle hue that
        indicates they are 1:1.  Or use event width?
    older notes:
    . I want add a measure, and then automatically:
      . Extend the ruler of this block.
      . Extend or contract the duration of the caller in the parent, moving
        all its events as necessary.
      . Also extend or contract the caller's ruler, if necessary.
      . Renumber the ruler in other callees as necessary, e.g. inverse
        LRuler.extract aka LRuler.inject.

      . All of this ruler resizing would not be necessary if I used
        Ui.event_end instead of Ui.ruler_end for the logical block end.  But
        then I'd need a -- event to mark the explicit end.  And it's just
        putting off the inevitable... I'd still need to extend the ruler, so
        why not make it easy, so now I don't mind doing it frequently.
    . If I have a way to mark a call as "unstretchy" it can try to move events
      below it, or at least highlight if it's not 1:1.
      . Or maybe it should even default to unstretchy, and you have to mark
        stretchy.
      . I could do it with special metadata in the event that could cause it
        to render differently, or by prefixing with a magic character, say '='.
      . The advantage of the magic character is that it's visible and I don't
        need any special editing support, but the disadvantage it that it's
        metadata interfering in notation.
      . Presumably it only has an effect on events with CallDuration, and
        maybe even an error on ones without... but I can't find that out
        syntactically.
      . Maybe the first step is to implement the move later events part,
        triggered by a keystroke (like cmd-z for events), and worry about
        doing it automatically later.
  Integrate from dsl.
    . Status: I think it just barely works, via LSol.edit_new, and
      reintegrate, but not tested and not hooked up to the editor.
    - I tend to use multiple korvai sequences as versions of a single korvai.
      Maybe use index -1 to concatenate them all?  Or have a general way to
      concatenate multiple korvais?
    Implement manual integrate, e.g. LSol.integrate korvai
      * I need a Block.EventIndex to do the diff.  ScoreDestinations requires
        a source TrackId, so I need a ManualDestinations without one.
      . Since 'to_score' returns (note, controls), I can assume track
        derivation.
      . I need some kind of key to distinguish between sources.  For
        solkattu, that would be the source korvai.  So make it Text.
      . I need at least some kind of stack since Merge uses that to tell
        the difference between generated and user-added events.  But the
        actual diffing is based solely on Event.IndexKey, which is just
        TrackTime.
    - validate Block.ManualDestinations from Ui.set_integrated_manual
    - If I put a TrackTime offset into the ManualDestination, I could have
      multiple destinations on a single track.  But then I'd have to also
      know to move things around if they change size, and it seems
      complicated.  Maybe it would be better to put them in their own
      block, and then implement a way to nudge calls when one changes
      size.
    - If I put the destination on its own block, I could automatically
      adjust the ruler.
    * connect LSol.realize to manual integrate
      . LSol.integrate_track (LSol.korvais !! 59) 0 "mridangam"
    - make block version of LSol.integrate_track, where integrate also adjusts
      the block ruler to the right length.
      . I need to understand the tala, not just for the ruler, but to know
        if there's a final stroke.
    * cmd to edit a korvai's source file along with the vi save hook
      . 'gz' is normal so I can load in ghci, but 'gs' saves and sends
        a re-integrate for that korvai.
      . It also needs to trigger a reload, but 'send' should work for that
        too.
    - Solkattu realize with an alignment error should still realize, just
      emit a warning.
    - On vim 'gs', output from 'send' messes up the draw.  Maybe bring it
      back to vi and do :echo?
    - Get rid of Korvai index, it gets more annoying as time goes on.  Just
      have separate korvais, and I can tie them together with variable_name if
      necessary.  But I still need a way to distinguish for SourceKey, so
      maybe I still need it but as another tag, added by 'korvais'.
    notes:
      . I'd like to be able to edit e.g. solkattu dsl, then save triggers
        a score integrate.
      . This is also the way to get text language to integrate in general.
      . Also it's visualization for text language.
      . StateConfig can have 'dsl_integrate :: Map Symbol Code', then repl cmds
        to edit them.  This is then haskell, which means I need some way to get
        it into the REPL, and some standard environment in which it is executed.
      . I can actually do this currently but I have to run a repl cmd, e.g.
        LSol.integrate Score.xyz
      . So simpler way would be to hook the editor so it does 'send ...' on
        save.  I should do that first, and think about a more automatic way
        if it's too awkward.
      . The common building block is a manual score integrate like
        integrate :: Symbol -> Track [Ui.Event] | Block Ruler [Ui.Event]
      ? Remind myself about how score integrate works.
        . Manually call LIntegrate.score_block
        . Which sets (source_block, ScoreDestinations []) on the dest block.
        . score_track adds (source_track, ScoreDestinations []) to dest
          block_integrated_tracks.
      . Dsl integration won't have a source track or block.  Instead it needs
        another ID which can link it with the source.  So for code it would be
        defining file or expression.  I also need identifying stacks for the
        generated events.
      . I have to load the module with the dsl.  If that's supposed to be
        per-score then I need to get that into an .hs file and get the repl to
        add that to the targets.  The file should be .hs and loadable anyway so
        I can use ghci on it.
      . But I'll likely have multiple DSLs, so it needs some configurable
        boilderplate, i.e. imports.
      . Two cases: EDSL means it's haskell with a special "prelude", like
        solkattu.  DSL means text with a parser, e.g. Derive.Text.TScore.
      Make this work for solkattu:
        . Make solkattu set Event.stack.  It should have the sollu and position
          as a TrackTime.
        . The score has a link to a module name, e.g. Local.Score.Xyz.  If it
          doesn't exist, create one with the standard set of imports.
        . On refresh, have the REPL load that module, and pull out every symbol
          with the right name, e.g. _xyz.  Each of those should be of Block
          type, and will be used to create score integrate to a block of the
          same name.  I do the integrate for everything, since it will detect
          if there were changes.
        . Figure out how to make the GHC API load a specific module and find
          symbols.  I need to verify their types too.  Trigger like :dsl X.Y.Z
        . Make a Block type, and hook it up with score itegrate, and :dsl.
        . Make solkattu realization retain the original sollu.
        . Add the "dsl modules" score field.
        . Make a REPL cmd to open vi with the file and bind save to the :dsl
          cmd.
  - track calls / track macros:
    . Status: lost motivation after I figured out another solution for
      gamakam, which now uses a t-nn track.  It's implemented all the way
      up to having a spot in Derive.Scopes and special control track syntax,
      but there are no implemented track calls.
      . See also signal-discontinuities.
    - More general and descriptive names for Derive.Scopes and Scope.
    - Use Scopes in Derive.Library
      * Convert note call definitions to Library, then Derive.C.All is just
        a big mconcat.
      * Delete CallMaps.
      * Can I get rid of state_initial_instrument_aliases?
    - Implement calling TrackCalls.
      . Overloading 'x' to mean a call to x or a control %x might cause some
        problems.  E.g. title_to_control can't know unless it looks
      . If I just use a symbol there's no way to tell if it's a control,
        pitch, or note track.  So I need to keep the syntactic clues.
      . Maybe control: '!call', note: '> !call', pitch '*xyz !call'?
      . I'd like to be able to abstract control, e.g. '!gamakam', and the t-nn
        is an implementation detail.  But I can't have track calls return
        (Control, d), because that's only control tracks.
      . I could have it set a control with the same name as the track call,
        and then some way to rename it.  But what is that way?
      . Or I could just fake it by returning Score.Control, and pitch tracks
        just use Score.Control, and note tracks just ignore it.
      . It seems awkward that this is simultaneously giving a way to abstract
        syntax and control name, and they don't seem naturally related.  Can't
        I have an orthogonal way to make 'gamak' an alias to t-nn?
    - Write a TrackCall for gamakam4.  ! calls quote the argument and pass
      to gamakam call.  Or I could invert it and use ! for non-gamakam calls.
      Copy pitch calls over.
    . Maybe this is how to do macros: track title is a lookup in
      a track-macros namespace.  If 'name' isn't found, then it defaults
      to '%name' ala LookupPattern.  Track call namespace should also be
      in the CallMaps and Library so it can be imported with modules.
      Also I think it needs note, pitch, and control variants in the same
      way.
    . As long as I'm doing this I can go back to using pitches for
      gamakam, and just copy over from the pitch track.  Not sure if
      I should though.
    . old notes:
      . consider track calls and block calls:
        note_track :: TrackTree.EventsNode -> Derive.EventDeriver
        derive_tree :: ScoreTime -> TrackTree.EventsTree -> Derive.EventDeriver
      . I could use this to implement is-ly and no-ly, and also totally custom
        track types and block types.
  - draw-text-lines
    . I think it's a bit of an improvement for code simplicity, but still has
      an annoying redraw bug.  So it's almost done but not merged.
  - Sortedness tracking for Stream and Post functions.
    . Track down usage of Stream.from_sorted_list, probably most uses are
      bogus.  Stream.from_list and Stream.from_events have to take
      Score.Events so they can sort them.
    . Sorting vensions of Post functions also have to return Score.Events to
      be able to sort them.  They could take another event_of, but it seems
      like there should be a way to compose the mapped functions instead of
      the maps.
    . I should also come up with a plan for deforesting the intermediate
      lists.
    . Order is easy to check with quickcheck.  I could come up with some ways to
      do quickchecks on certain score fragments.  Or alternately, apply
      a standard set of checks: start =0, >0, in callee block, etc.
  - Make BaliScales which are not saih pitu be fundamentally diatonic, not
    just degenerate chromatic.  Or figure out how to simplify the whole scales
    mess.
    - Disallow 4e# in selisir.  And generally accidentals.
      . Validating the absolute pitch is broken for *legong, because I want to
        make sure the relative pitch is in the key's intervals.
      . I could make validation more complicated, but I think not using
        ChromaticScales would also fix this.
      . I don't get an error because the pitch is created, but will evaluate to
        UnparseableNote, which makes an error only on conversion.
      . It's because ChromaticScales reads a relative pitch, and only checks
        for validity once it's absolute, at which point it already created
        a ScaleDegree.  I could either also validate relative, or get rid of
        the fancy ChromaticScales use for scales without modes.
      . Or maybe UnparseableNote should have a msg arg to show what it was?
      . The thing is, I don't want the whole accidental parsing mechanism,
        I just want 7 symbols, and a relative pitch system.
      . So I could have a simplified ChromaticScales which dispenses with letter
        + accidental, and instead just has a unique name for each scale degree.
      . Then I could use 1234567 for javanese-style notation.
      . I'd basically replace the show/read pitch stuff with a hardcoded map to
        RelativePitches.
      - I can't have different pc_per_octave based on key, without parsing
        the key in input_to_note.
    - It would be nice to have a no-keys version of BaliScales so I don't have
      to mess with a fake key in *selisir and *wayang.
      . I guess it's not a big deal, but at least it means it ignores key.
      . Actually it seems like it might be a pain, because then I can't use
        the same Config.
    Why are scales so complicated?
      - Can I make it simpler?  If I were to rewrite it knowing all this stuff,
        what would it look like?
      . twelve: Keys have mode and tonic, so each key has a signature that
        influences enharmonic spelling.  Has accidentals with enharmonic
        spelling, and a layout which says which pitches are skipped, also based
        on the key.  Both the pitches and accidentals are absolute and so
        independent of the key.
      . twelve-k: Like 'twelve', but while pitches are still absolute,
        accidentals are relative to the scale.
      . twelve-r: like 'twelve', but both pitches and accidentals are relative
        from the key's tonic.
      . just: Keys have mode and tonic as with 'twelve', but they affect the
        tuning.  The layout is diatonic in that there are no skipped pitches,
        and hence no enharmonics and accidentals.  Accidentals are supported
        just as a constant ratio offset, so respelling enharmonics will change
        the frequency.  Since there's no per-key spelling, the key is much
        simpler, just a tonic pitch.
      . just-r: Like 'just', except that pitches and accidentals are relative to
        the tonic.
      . raga: Like 'just-r', except with a much larger selection of modes.
        Also, instead of accidentals, there are multiple candidates for
        certain pitches (e.g. ri1 ri2 ri3), where one will be default based on
        the key.  TODO the last bit is not implemented yet.
      . legong, pelog: These have keys, but like 'just-r', they are simply a
        starting note (tonic) and a layout to indicate skipped notes.  However,
        there are no accidentals, and instead each note has a unique name.
        'legong' (but not 'pelog') has a 'tuning' which indicates pengumbang or
        pengisep, and they also have a 'laras' value, which indicates the tuning
        variant.
      . legong-pemade, legong-kantilan, etc.: Like 'legong', but with octaves
        relative to the tessitura of a particular instrument.
      . selisir, wayang:
      . selisir, wayang -pemade etc.: Relative octave variants.
      . belaganjur, angklung:
      misc notes:
        . Simplest is an absolute scale with no key and no octave structure, just
          a mapping from symbol to pitch.
        . Then we have a relative diatonic scale.  This has a key which influences
          the note names, since they are relative to a certain pitch, but no other
          structure.
  - rewrite shakefile so I can disable features like 'im' and not require
    their dependencies for tests, haddock, etc.
    . branch shake-targets
  - signal-offset:
    . Extend TimeVector with an offset, so I can get rid of
      Score.event_untransformed_controls and the like.
    . After this I'd like to make Score.Event's fields private so e.g.
      I can enforce set_instrument.
    . Also simplify or unify various types in Derive.ScoreTypes,
      Derive.BaseTypes, and Derive.Score.  Maybe get rid of type aliases
      and move simple types to Derive.T.
  - Complete Util.PrettyGeneric so I don't have to hand-write Pretty
    instances.
    . Maybe I should fix the formatting bugs first.

TASKS:
  Performance
    . Solve input lagginess when the score is large.
    . Reduce GHC-API memory usage: NOTE [reduce-repl-memory]
    . Look for memory leaks.
    . Make transformers lazy so they can interleave, aka
      map f . map g -> map (f.g)
  Music / design / language:
    . Clean up tracklang type checking with subtypes: e.g. ValType.types_match.
    . Music Analysis: Look for repeats or repeats with transposition.
    . Text score.
    . Solve how timing changes bubble up.  Text score can do it, or maybe
      integrate from DSL (either text score or haskell) or have a purely
      read-only block or track.
    . Simplify scale implementation 'Why are scales so complicated'
    . Something better than ControlFunctions for randomized signals.
      . I might be able to solve this if I can figure how to get literals in
        Sig.Parser defaults to work.  If I coerce to Typecheck.Function
        from signal or a val call, then I can replace with a val call.  The
        problem is that the default then becomes a Function, which means it
        loses ShowVal and hence documentation.
      . See NOTE [fix-control-functions]
    . Im
  Tests:
    . Quickcheck for derivation.
      . Or hedgehog:
        http://teh.id.au/posts/2017/04/23/property-testing-with-hedgehog/
      . Or Midi.Encode_test.test_encode
      . Or Ui.Diff
    . Test Ui.Diff and Ui.Sync.
    . Properly parallelize tests.  Maybe use a Test monad instead of IO and
      make tests pure.
  . fix bugs in Util.Pretty / Util.Format
    . Or use someone else's library... printcess?
      . Looks like it only has one level of indentation.  Also I think it
        doesn't have breaks, it just always breaks on space.  And uses String.
    . Other formatters:
      . https://ocaml.org/learn/tutorials/format.html
      . https://github.com/google/google-java-format
      . https://github.com/dart-lang/dart_style
        http://journal.stuffwithstuff.com/2015/09/08/the-hardest-program-ive-ever-written/
  GUI:
    . Prettier events, smooth scrolling etc.  OpenGL?
    . TrackSignals could use y position and color / transparency.
    . Window management: automatic tiling, window manager configuration.
    . Switch logview and browser to Fl_Html_Display.
  Linux:
    - Increased scroll sensitivity for the scroll wheel.  Or is that an
      X config?

----------------------------------------------------------------------

documentation:
  - strict markdown parser, and extensible:
    . with https://markkarpov.com/post/announcing-mmark.html
    . But not ready yet (no lists or block quotes).
  - Publish haddock with http://documentup.com/feuerbach/standalone-haddock
  - Can I have Util.Linkify check the validity of single-quote links?  Or
    maybe I could run a link checker against the final output.  Otherwise
    'Module.function' references get out of date.
  calldoc: CallDoc:
    - each call should have type (note, pitch, control), so I can see
      what it is after a search
    - collapse control for modules, option to collapse / expand all
      . Haddock:
        <span id=xyz class="module collapser"
          onclick="toggleSection('n.1')">Title</span>
        <ul id='section.n.1' class='show'> ...
    / put anchors on calls and make single quotes link to calls
      . It's not quite so simple because there is module, and then call type.
        So the linkifier would have to understand that structure and search
        for one, or have some javascript, and then it would have to choose
        if there is >1 match.  Too complicated.
    / For call doc, can I group calls with the same doc but different args,
      especially different defaults?
      . Would look like:
        doc doc doc generator
        bind -- name
          args
    - I could go look through arg docs for controls and list all the controls
      that have someone listening to them in a certain scope.

Util.Linear: linear: linear piecewise signal: signal-discontinuities:
  . Problems I'm trying to solve:
    . Need to remember to use Signal.set, and provide previous y.  Signals
      should be implicitly flat in both directions, and merging them should
      respect that.
    . Transpose signal resampling should "just work", without needing special
      'at_before' stuff.  Why does it require that now?
      . Because it gets raw samples, without treating them as segments.  So I
        could make unsignal return segments: [((X, Y), (X, Y)]
    . Awkward rules where the sample at 0 sets values before.  Or at least the
      part where it leads to errors when asking for the value at <0.
    . Include shift so I can get rid of Score.Event 'untransformed' nonsense.
      I think the problem before is having to use the shift on all signal
      operations even when it's 0 for everyone except Event seemed over
      complex.  Also that I just want a per-event offset, not one for each
      signal inside.  Though if I extend this to stretch as well, then I don't
      need a separate Warp type.  I don't think anyone except warp would use
      it though.
      . Ideally I could optionally layer it on a signal, but then I have to
        reproduce all the functions.  But I could try to make a minimal API
        in a typeclass, and have the functions be generic.
      . Could I use this to unify pitch and control signals?
    . How much would I solve just be changing (<>)?
  . If I want to replace Environ with Val signals, then I'm back to
    non-interpolated.
  . What would a typeclass + associated type actually look like?
    . It would be like Vector.Generic, only with more specialized access
      functions.
    . Maybe in general, I can give a Segment y type, and an interpolation
      function.
    . But a polymorphic interface is only as useful as the number of functions
      that can be polymorphic with it.  So what could be polymorphic?
  Unify Environ and ControlMap:
    . I can get most of the benefit by unifying the syntax: x=y becomes set
      a control or env depending on the type of the rhs.
    . However, they're still separate which means I can make an "invisible"
      numeric env in haskell.
    . Also, I would need Derive.Sig to default from numeric controls.
    . I guess it would then be better to have a single
      Map Key (NumSignal | ValSignal | PitchSignal)
    . This means I can also get rid of the separate pitch and named pitches,
      and just have a signal named "pitch".
  . If I can make signal a typeclass, I should be able to make offset (and
    maybe stretch) a wrapper.  This only works if I can reduce the interface
    to a few things like 'at'.  But I feel like all the various transformation
    functions won't allow that.  They are type specific too.

  Signal functions:
    . at
    . sample_at - Prelude.Block.trim_controls hack: remove sample at end time
      Derive.Note.extract_track_signal: merge event signals
      . Shouldn't I be able to do this with time slicing?
    . before - Gamakam5: for get prev pitch
    . at_linear, at_linear_extend: tempo warp
    . inverse_at, inverse_at_extend: warp
    . constant_val: various optimizations

  TODO:
    * remove Signal.interleave
    * make it generic on Y type
    * implement concat
    implement a Perform.Signal that uses Linear instead of TimeVector
      * linear transformations
      / non-linear transformations (max, min, ...)
        . The scalar versions were already a hassle, and I don't really use
          min and max so maybe just remove them for now.
      / inverse_at
        . If I replace Warp with (f, f-1) then I don't need this.
      * scalar transformations
      + slice, to replace all the drop_before drop_after stuff
        . Slicing a signal will require changing the vector, to add a new
          sample on the beginning or end.  I could eliminate this with _start
          and _extend fields.  Not sure if it's worth it.
        . Do it the simple way first, and profile.
        . I have 'before' and 'after', but wait to see what I'll need before
          implementing the versions that add a sample.
      / compose
        . If I can reduce to an interface like 'at', then I could make this
          real composition.  As well as get shift and stretch for free.
        . In fact maybe I can just make Warp into a real function, what will
          that break?
        . I need inverse I think, but maybe it can just be (f, f-1).
        . What about compose_hybrid?  That's kind of weird.
      - pitches_share
      - flat_duration
      * integrate
    * implement Warp as functions:
      . I need to distinguish id warp, for optimization.
        Or not... if composition is now efficient, maybe no need.
      . Access to the signal has been useful for debugging in the past, maybe
        I should keep it in a separate field.
      . Tempo.with_hybrid uses warp_to_signal so it can use
        Signal.compose_hybrid on them.
    - port Signal_test to Signal2_test
    - port PSignal to PSignal2
    * Rename Util.Linear to Util.Segment
      . There's nothing inherently linear in the module.
    - clean up TimeVector, remove unneeded functions
      . also remove magic x<=0 behaviour

    - Remove Derive.Tempo.extend_signal
    - Get rid of srate.
    - Midi performer has to use a sampling rate.
    - Get rid of infer linear in the fltk drawing code.
    - remove Derive.Deriver.Monad.state_pitch_mergers

  . If I say signals now have linear interpolation by default, then the linear
    interpolator can just emit one sample, but now MIDI needs interpolation.
    I'd have to put srate in the event so it can be configured.
    . Or just pick something high enough.  If I need sample and hold, I can
      write a signal transformer for it.
  . Leaving as nominally non-interpolated, but with explicit discontinuities
    since im actually is interpolated is not so pretty, but doesn't seem
    so bad in practice.
  . This breaks '* interleave', which was always fragile anyway.
    . Can I save it with a hack?  It could get more clever, and move the
      end sample: [(0, y1), (n, y1)] -> [(0, y1), (x, y1), (x, y2), ...]
    . Or I could get rid of it entirely, if I can fill the same need another
      way.  That's where I want to have swarams and gamakam separately, so
      I interleave with the swaram track.
      . I could have the gamakams read from the swaram track, but then
        I want to get the pitch even when there is no gamakam, so I don't
        have to put a dummy call on each note.
      . The most direct way might be a track preprocessor that copies over
        swarams, or maybe adds a "!^".  I worry about how this obscures
        the usual rules of evaluation, but ! notation is already sort of
        its own language.  I'd need some special track-level macro call.
      . What if ! in a track call was a macro symbol.
        Control.d_control_track separates those out, and calls them from
        a special namespace.  I think they have to go at the front.
      . Why is gamakam not emitting a transpose signal?  I can transpose
        to another pitch with scale_read and scale_show.  But then what kind
        of transposition?  t-dia is obvious, but some gamakams are below
        diatonic.  Actually it can emit multiple signals via the
        ControlMod hack.  I can try to do everything with diatonic, but
        I do need absolute pitch deviations.
        . Speaking of ControlMod, what would it take to have a control track
          actually emit multiple control signals?
          . I guess it would have to be a new type of track, with a
            [(Control, Signal)] return value.  It's actually similar to
            ControlMod except without biased towards any particular Control.
        . So try a Gamakam5: build fragments of transpose signals.
      . But can I really use t-dia?  How do I represent alternate ga or
        something?  I think the most straightforward way is treat them as
        chromatic notes.  Then it become t-chrom.  But I think I can do
        t-dia for now, until I have that.
      . But now if I have different types of transposition, I can't go from
        one to the other, e.g. +1nn move to -2d.  I would have to flatten to
        an absolute measure like nn, but scales don't give me that.
      . I could get it though, by reducing to NN and doing a diff.
        I think I do need transposed pitches, though.
      . From would always be NN, to would be (Transposition, Step).
      . This all makes it dependent on the scale, it seems nicer to have
        all those functions just emit signals. I guess I can still do that
        if I supply a Transposition -> NN function.  The output gets kind of
        unreadable though, unless I want to emit (Transposition, Step)
        breakpoints, and assume everything will fit into that.  Might as
        well be (Transition, (Transposition, Step)), but now PCalls don't
        really do much.
      . I still need a value for discontinuities though.  It's code vs. data
        again.
      . Oh yes, and prev pitch doesn't work if I'm a control track.  But
        I can get the prev transpose.
      . Another problem is that I have to make it a t-nn track, which
        doesn't make much sense, and any other control calls wind up being
        in t-nn, which doesn't seem that useful.
      . If pitch gamakam is also in a cantrol track, I can't tell it from
        dyn controls.  Really what I want is to be able to write "gamakam"
        for the transpose, and it can set the interpretation of !.  Or even
        use a lookup so I don't need to use !.
      . Maybe this is how to do macros: track title is a lookup in
        a track-macros namespace.  If 'name' isn't found, then it defaults
        to '%name' ala LookupPattern.  Track call namespace should also be
        in the CallMaps and Library so it can be imported with modules.
        Also I think it needs note, pitch, and control variants in the same
        way.
      . As long as I'm doing this I can go back to using pitches for
        gamakam, and just copy over from the pitch track.  Not sure if
        I should though.

      . Which of these would be best for possible future kinds of notation,
        or further extension?

synth: im:
  - Shift-play plays im cache even when the instruments are gone, but not
    enter-play?
    . Properly I should clear out the cache when instruments go away, but
      meanwhile I should be noticing that there are no im events and not
      starting play_cache.
    . Proper MIDI fallback would also fix this.
  - If I delete an instrument and rerender, the old one is left around.
    This is because the cache won't delete existing files.  This will be fixed
    by making a new cache dir instead of just copying into the existing one.
    . I should be able to cache instruments that don't change.
  * put all notes in one directory, and then have a directory per namespace.
  - put ScoreTypes.Instrument and ScoreTypes.Control in a Shared.Types so
    im and seq can use the same types.
    . On the other hand, maybe they should remain different.  Synth Control
      at least is different in that also includes pitch.  Also Instrument
      is a score-only.  Even though it winds up in Note.instrument, it's not
      really in its original context any more.
  * Now that Instrument IsString, I can change DeriveTest.with_midi_config to
    take Instrument, and similar.
    . Also all the Repl.* modules.
  - I can maybe also just replace unchecked_control with Control, and
    make both Instrument and Control have checked_* constructors.  I can't
    really enforce Id.valid rules, except at score parsing time.
  - Also move callers from Score to ScoreTypes.  Can I give it a shorter name?
    Base types modules should have short names.
  overview:
    . Cmd.Performance will serialize im notes and start the binary.
    . sampler-im or faust-im will read the notes and render wav files for each
      instrument.
    . Cmd.Play.from_realtime can emit the im protocol from Perform.Im.Play,
      which will mix together the unmuted instruments, starting at the given
      time.
    - Im instruments should have a midi thru-like preview sound.
      . One way would be to assign a parallel MIDI instrument for thru.
      . A fancier way would be to have a realtime im interface.  For that
        I think I'd need to run the im synthesizers persistently, and talk to
        them via MIDI or OSC.
      . A compromise would be a general mechanism to render samples, and then
        feed that into a realtime sampler.  Of course commercial samplers can
        do that but would insert a lot of manual work into the process.  So
        maybe I can write a minimal MIDI VST sampler.
      . All it needs to do is play a sample with a given pitch (pitch bend
        and pitch) and velocity.
    - Incremnetal rendering.
      . Propagate score damage up to the im perform step.
      . I have to split the cache into chunks.
      . Save and restore sythesize state.
    . Cache / incremental rendering.  Karya has to also emit damage ranges,
      and the synth has to expand that to notes and rerender just those
      sections.  play_cache has to understand the more complicated cache
      and mix or concatenate the chunks.
    . Atomic cache replacement.  The synth generates a new cache dir, and
      play_cache GCs the old one when it stops.
  Support track muting.
    . First, I need to separate notes per-track.  For models I actually can't
      do this, because notes on the same instrument affect each other.  It
      should be possible if notes are independent, e.g. samples.
    . I can do per-instrument.  For NESS I just have to not mix down the
      result, and save namespace-block-instrument.wav.
    . Then PlayCache has to read namespace-block-*.wav and mix itself.
    . Karya needs to turn track mutes into instrument mutes, then send msgs
      about muted instruments.  I guess it can be more send text with disabled
      instruments with the block.
    . So I need to infer muted instruments from tracks.  This is instrument
      level mute and solo, but track level is more convenient to use.
    * karya infers muted instruments and sends them to PlayCache
    * PlayCache reads blocks and mutes, mixes multiple outfile files
    * Ness.Convert writes separate files for each instrument
    * I should use a subdir for the tracks.

  * if notes start >0, rendering starts at 0 anyway
  * no sample match when guit.wav is muted?

  efficient conduit-audio:
    . Currently I mix [(RealTime, Audio)] by padding all to their start time,
      and mixing them all.  This is inefficient because it generates and adds
      tons of 0s.
    . I'd prefer to have a mix that waits until the start time, allocates
      any resources needed (open source file, allocate synthesizer), and then
      emits samples.
    . Author is nonresponsive.  Maybe I should just write my own:
      . Only one sample rate, only one channel, support only Float.
  play_cache: PlayCache:
    - Move resampling to play_cache.
    - Theoretically I should be doing sample loading in a non-audio thread.
      In practice it seems to be fine
    - Stream samples instead of loading them all at once.
    - The im/ directory is fundamentally global, since PlayCache hardcodes
      a single path.  It could be theoretically configured, but I'd probably
      have to do it manually via some kind of VST GUI, and save in the VST
      preset mechanism, and it sounds like a lot of hassle.
  faust:
    - Extend the guitar single string model into a multi-string instrument.
    * Write separate files for each instrument
      * Concatenate signals for all notes, and synthesize a gate signal to mark
        note starts and stops.
    * Distinguish attack time controls and continuous controls, so I can use
      Note.controlVals for the continuous ones.
      . "Point" controls aren't necessarily only wanted at attack time.
      . And I can imagine wanting pitch plus random offset.  But this requires
        some kind of more complicated per-control thing, because it depends
        a lot on the instrument.  E.g. one with continuous pitch I might want
        to add a offset to 0 curve.
      . So maybe it's better to do this at instrument-level config, where
        I can sample some controls.
      . So revert the Note.control_vals stuff, and introduce a mechanism to
        sample control vals.
      . Actually, configuring an instrument's controls as signals or sampled
        or whatever seems useful for all instruments.  I should have a generic
        way to configure all patches.
      . This could be done by per-instrument note call override.  It would be
        nice to generate this from a description so it can automatically go in
        the doc though.
      . I think the place for that is Instrument.Common, so I could add
        a section concerned with configuration, which is used to automatically
        configure the note call, or whatever else.
      . Or actually, why not just use the note call's documentation?  Just
        make a Derive.Instrument function to make note calls.
    * Get rid of Score.event_control_vals, and use DUtil.attack_sample_note
      instead.
    - Handle amp outside of faust, just by multiplying the signal.  That way
      all instruments support it uniformly.
    * Process each instrument in parallel.
    + If I use GUI elements for controls then they update at "control rate",
      which is probably enough actually.  It also means I can reuse the GUI
      controls.
      . But faust has to resample those to a-rate anyway, so if I use controls
        I do that twice in a complicated way and add some latency, for no
        other benefit.
      . Wait and see if interactive GUI experimentation plus compatibility is
        worth it.  Also MIDI is "GUI."  Probably yes.
      . UI metadata like [key1: val][key2: val] winds up as calls to
        ui->metadata("key1", "val")
    * Add plucked string and woodwind instruments, with control signals.
    * Assert that inst->getNumInputs() == length controls.
    - Figure out decay time instead of hardcoding it.
      . How to know when to drop notes?  I think I have to use a heuristic
        like >1s of audio under a threshold after note off.
      . I think this has to go in the driver.  Implement a gate signal, and
        the driver renders until the output gets low enough and gate is 0.
      . For instruments that play multiple notes, I can use this to suspend
        processing.
    - Instruments with explicit voice assignments (e.g. strings) use Attribues
      to assign the string, and create a set number of Instruments which are
      reused.
    - MIDI thru for im instruments.  Tie to a MIDI instrument for thru.
      . If I support faust controls, I can reuse existing OSC or MIDI bindings
        for an accurate thru.  But I'd have to build the faust library as a
        VST and then have some way to address it.  MIDI would be more
        convenient for reusing existing thru, but OSC could be more convenient
        for communicating with the thru-VST, so I could just address patches
        by name and I don't to fuss with MIDI channels.
    support faust ui controls:
      - Make an instrument into a conduit source.  Then I can render
        progressively instead of a whole note.
        - Then I can use controls by setting controls at the audio chunk rate.
        - Store persistent buffers in Instrument.
      - convert to standard control names:
        . Convert pitch NoteNumber to freq Hz
        . vol -> a special control that always multiples output volume
        . amp -> gain
        . note-on + duration -> gate
    cleanup:
      - Put find_sample into a TimeVector.cc library.
    plan:
      . Faust has a bunch of *.dsp files.
      . shakefile runs faust to generate .cc from the result, and then collect
        into a map of (name, *dsp)
      . Export a Load function that introspects all of those for the inst db.
        If there is karya code, it gets attached by name just like Sampler.
      . faust_driver loads Notes, and maps PatchName to dsp pointers.
      . Based on patch config (polyphonic, strings, etc.), allocate a certain
        number of dsps by cloning them, and allocate Notes among them.
      . Call compute dsp startFrame endFrame controlsp outputp for each time
        range, and mix the output into a wav.
      ? How does FAUST handle global things like a reverb bus?  I guess I have
        to pipe around the samples myself.  But what if you have multiple
        strings with resonance?  I guess it has to have inputs for each one,
        as one giant list of input channels.  But since they're all
        interleaved samples, I can't just leave some empty, or not easily at
        least.
        . A polyphonic instrument could export controls like pitch-1 pitch-2
          etc.  But does it know to turn off the ones that aren't in use?
      ?  Where does the state go?  I.e. how do I save and restore energy in
        strings, etc?
        . It looks like the state winds up in instance variables, so I should
          be able to just save those.
    . https://ccrma.stanford.edu/~rmichon/faustDay2017/
    . http://faust.grame.fr/faustplayground/

  things to change with faust:
    - Use const on const methods.
    - Have a way to save and restore state.  E.g. stick instance variables in
      a bytestring.
    - Provide access to input signal names so I can get rid of the awkward
      declare thing.
    - Export metadata as data, not via the complicated visitor pattern thing.
  csound:
    . Use csound-expression?
    . writeSnd "A.aiff" $ setDur 10 $ osc 440

  / The start time should be in fractions of a second instead of sample
    frames, so I'm not dependent on sample rate.  Also, will I need to emit
    negative time?
    . But as long as the srate constant is shared, what's the problem?  Also,
      for negative I'd have to decide how much, and besides reaper doesn't
      necessarily have negative time.
    . So I have to add a constant anyway.
  cache / incremental rerender
    notes
      . I want the sequencer to only send the damaged range, but the synthesizer
        will have to rewind to the previous chunk boundary, since it can't just
        put every note in its own sample.  I suppose a sampler could actually do
        that, but presumably physical models couldn't.
      . Though actually a model would need to save its state at chunk
        boundaries, so if I go per-note, then I wind up with rendering each note
        separately, with a header with the model's state at start time.  But
        overlapping notes would influence each other, so it would have to be
        chunks of overlapping notes.  Of course it's not guaranteed there will
        be a gap, so it would have to break anyway over a threshold.
      . This is all to say that the cache chunks are synthesizer dependent, so
        it needs access to all the serialized notes and can rewind as much as it
        wants.  If notes are saved individually and indexed by time then I just
        need to re-save the damaged ones and either send the time range or infer
        from file timestamps.
    - Include DamageRange RealTime RealTime in the notes dump.
      . This is assuming a always serialize all notes, but I'd also want to do
        that in chunks.  But I would have to expand the damage range out to
        all overlapping notes, which is not great if there's a drone + control
        and you modify the control in the middle.
      . I should just have to emit the notes with overlapping damage, but only
        rerender the time range.
      . Say I make each note is its own file:
        <start-time>-<instrument>-<voice>, where voice is just a number for
        otherwise overlapping notes.  If there's damage from s to e, I get
        the set of overlapping notes.  I delete everything in the damaged
        range, all all (start, instrument) at the times of overlapping notes
        before the range, and then write overlapping notes.
            |----------->|--->
                |--->
                |--->
                XXXXXXX damage
        . This is like Ui.Diff, except that it's RealTime and for
          Score.Events.
        . I also need to turn ScoreDamage into RealTime.  Maybe not trivial?
      . Actually first let's not bother with incremental, and just rewrite the
        whole dump each time.  The real saving is in not rerendering audio.
    - faust-im breaks output into chunks of n seconds.
      . Chunk = (startTime, InstrumentState, samples)
      . InstrumentState = Map (Instrument, Voice) DspState
      . Voice = Int -- assigned by polyphony, but how can I keep it stable?
        . For unlimited polyphony instruments, it doesn't matter, since it
          doesn't affect the output.  For limited voice, I just map it to
          different instruments.  So no Voice needed.  The difference is
          whether I allocate a new instrument for every note or not.
      . DspState = ByteString -- raw serialization of dsp class.
      . Or I could do a memoize thing where I memoize
        (startTime, Instrument, Controls, DspState) -> Samples.
    - PlayCache can sequence multiple .wav files.  The filenames need to have
      a timestamp so it can know how to seek.
    - As PlayCache does fancier stuff, maybe I need to put the sample
      streaming into a separate thread.
  - If there is only one cache mutated by the synth, then a play in process
    will be spoiled by a new render.  I can fix this by making a new cache
    each time, and hardlinking the unchanged entries.  I can remove the old
    one if the play is stopped and there is a newer one, so this could be done
    by the PlayCache vst.
  * Im signals have to either be audio level, or interpolate between their
    points.  Audio rate is overkill at the sequencer level, so I think I
    make them interpolated.  But since it's ambiguous whether the sequencer
    wants interpolation or a discontinuity, I think I have to disambiguate by
    emitting two samples at a discontinuity.
    . Ideally I'd have resolution independent signals, so just functions.
      Not totally sure what that would entail, but it would be a big change.
  more efficient Perform.Im.Convert
    - Trim signals.
    - I can probably serialize more efficiently by just mmaping the signal
      pointers, or at least directly copying their contents.  But maybe not
      worth it if I can just write the changed bits.
  Is it possible to do physical modelling on GPU?
    . http://futhark-lang.org/index.html
    . http://halide-lang.org/
    . hackage accelerate

shakefile: build:
  - in HsDeps and CcDeps, if I need every intermediate file, then
    I think I don't need Generated.
  - determine Shakefile.cppFiles automatically.
  . To get a path between two rules:
    ancestorOf('Synth/Sampler/Main') && descendantOf('Cmd/Cmd')
  - use new system calls and logging levels
  automatic "All.hs" modules
    . I'm reluctant because it's simpler to have normal files, and it's not
      that hard to update them.
    - Derive.Call.All looks for (note|pitch|control)_calls from Derive/Call/,
      but could also take from Local/Call/*
    - Local.Instrument looks for 'load' from Local/Instrument/
  - once upon a time, the shakefile took .2s to discover the build is up to
    date.  Now it's up to .7s.  Where is the time going?

incremental save / git:
  + try saving individual events for incremental save
    Seems to be just as slow as full save, probably most of the time is in
    the call to git.  Test again with larger tracks.
  - wrap operations in a lock file
  - make sure things are ok if it fails at any step
  - I don't think Ui.State needs to emit CmdTrackAllEvents for cases where
    diff will catch it.
  - See if git's delta compression understands binary and can compress
    tracks.  Otherwise, would it be worth helping it by e.g. separating
    each event with a newline?  But then it makes serializing events more of
    a hassle.
  . Git docs: http://progit.org/book/ch9-2.html

integrate / integration:
  score integrate
    - cascading score integrates
      Is there really a use for this, other than consistency?
  derive integrate
    - attrs that the instrument understands can turn into +attr calls, if
      they're not in the CallMap, e.g. save/test/wayang
    - adding a +soft stroke means it gets both less dyn and +soft again, so
      it's extra soft
    - bug: can't delete a derived track, it just gets regenerated
    - bug: can't undo past a integrate create, it just creates a new one
      Maybe I could not record the integrate step?
    - bug: create tracks, remove <, re-add <, does it work?
      Removing < should break the integrate links.
    - Ensure cascading track integration works.
    - If integrate is committing changes to a track, can that bite me if
      a "canceled" derivation comes through?  Think about this later.
    - quantization

lilypond:
  * The Lily module shouldn't be in Prelude, since it's actually not in the
    prelude namespace.  It could go to Derive.Call.Ly, and current
    Derive.Call.Ly to Derive.Call.Lily or Derive.Call.LyUtil.
    . On the other hand, it's nice to have call definitions in a directory.
      Maybe they should all be in something like Derive.Call.C.Prelude,
      Derive.Call.C.Bali, etc.
  - Lilypond complains about simultaneous tempo marks due to the ly-global
    distribution.
    . I guess I want just one after all.  But what about extracted parts?
    . I probably extract parts by succesively setting staff_display, so I'd
      need something to put ly-global or something in the top visible staff.
  yangqin-zheng-kendang/house-2014
    * :179:21: error: syntax error, unexpected SCM_IDENTIFIER
        \new Staff = "down" \RemoveEmptyStaves {
      . Looks like lilypond changed.
    - xstaff notes are not appearing in the right places
    - Where do those double sharps come from?
  - write a ly function for that quarter = eighth stuff?  I have it in both
    huiyin-concert and squart/spawn
  fix viola-sonata
    - Looks like another lilypond change:
      . score.ly:663:63: warning: this Voice needs a \voiceXx or \shiftXx
        setting
        af8 \mf bf8 c'8 df'8 d'8 a'16 ^( d'16 \change Staff = "down"
        ><
        a16 \change Staff = "up" gf'16 d'16 \change Staff = "down" d16 ) |
        % viola-sonata/pno3-2 viola-sonata/pno3-2.t15 62.75-63; 52
  - It's really confusing how transformer and generators work for ly calls.
    . E.g. I assign ly-span in ky to generator, then doesn't work as
      a transformer.  But if I make it a transformer and add |, then I get the
      bogus 0 dur empty event implied.
  - Similarly, it's awkward to have transformer + generators just so I can put
    multiple bits of code on one event.  I wonder if it's worth adding a ';'
    separator that allows multiple expressions?
  ties: rhythmic spelling:
    - I prefer the old 3/4 spelling: 2~ 8 8 | to the new spelling 4~4. 8
      . Beaming should at least be 3/4, but that's lilypond.
      . Shouldn't I be able to write 16 8. instead of 16 16~8?  Both old and
        new do the latter.
      . The new way spells 16 8 16~16 8 16~16 etc.  Why not 16 8 8 8 8 ?
      . Could I put in ad-hoc spelling rules?
    - I could do manual rhythm spelling with a special directive to turn off the
      meter, and then use a tracklang-level tie to join notes.
      . Or if I could annotate individual notes with tie directions.  That way
        I could apply a pattern to a whole section.
    - Staff notation has a notion of rhythmic spelling, which, being
      proportional, karya lacks.  In most cases I want to automatically infer
      it, but would it make sense to spell it explicitly in some cases, and
      how would that look?
      . I guess I could add a tie annotation, which merges duration with the
        next event, and a lilypond mode that ignores the meter and puts down
        each duration explicitly.
  / add 'ly-~' to add a lilypond-only tie for e.g. trill -> non trill
    transitions
    . Actually I'd want this to delete the following note and extend this one.
      Are there any complications?
    . Yes, of course, I want this to happen at the track level but of course
      that's lost by the time it gets to ly.  I can already do this though,
      with a if-ly type refactor.
  - Can I get it to print time signature on each line?
    . There's no built-in support, I'd have to hook into clef display code to
      add the time signature.
  trill:
    . http://lilypond.org/doc/v2.18/Documentation/internals/trillpitchaccidental
    - It doesn't like my ^\trFlat variants on notes within a chord, while
      \trill is fine with it.
      . This might work:
        trFlat = \once \override TrillSpanner.bound-details.left.text = \markup{
          \concat {
            \musicglyph #"scripts.trill"
            \translate #'(-0.5 . 1.9)
            \fontsize #-7
            \with-dimensions #'(0 . 0) #'(0 . 0)
            \flat
          }
        }
      . Nope, but maybe I have to use that with \trill.
    - Wavy line should extend to the end of the note, not stop at the
      beginning.  Lilypond seems to stop too early.
      . It wants \stopTrillSpan to go after the note *after* it ends.
      . Maybe I can do a AppendNext, which goes after the next note, but
        before any of its other appends.
    - Also the example pitch has an extraneous natural, but this seems to be
      built in to \pitchedTrill.

  - Warn about free code events that don't line up with a note.
    . Test in Process_test.test_note_code
  - add subdivision tests to Process_test
    . Make sure per-voice subdivision changes also work.
  - ly^ is confusing, it seems like it should be ly-^
    . Either that or get rid of the hyphen for everyone.
  - harmonic string arg is hard to use if I have to give nn.  How about
    strings export (g) (d) etc. calls which emit the appropriate string's nn?
    Or should I understand string names?
  - What's the difference between tracks '> | ly-track' and '> | when-ly'?
  - It would be convenient to be able to see where I am in the ly score, e.g.
    measure number.  Lilypond derivation makes a ScoreTime -> measure mapping,
    I'd just have to save that and invert it.
  - Infer ruler from meter markings, or maybe the other way around.  Meter
    markings seem more convenient, but maybe I could just make LRuler
    similarly convenient.
    . But since the ruler is more flexible, it's easier to infer ruler from
      meter than the other way around.
  squart/6:
    - Why does 7/8 not bar the eighth notes?
      . Because lilypond does beaming on its own: lily/Auto_beam_engraver.cc,
        configured in scm/auto-beam.scm and scm/time-signature-settings.scm
      . I should be able to use Meter for beaming too, but for now just beam
        manually.
      . I need to set the subdivision explicitly:
        \set Score.beatStructure = #'(2 3 2)
        Or \compoundMeter #'((2 8) (3 8)) to also set the visible meter.
      . Have the meter and subdivision commands set beatStructure for
        meters where lilypond doesn't already do a good job.
  - lilypond: espressivo <> should be like a normal hairpin
    But the way to do this is awkward, << .. { s4 s4 \< s4 \> s4 \! } >>
    . I also want tied notes to expand to 'c4~ \< c4 \>'
      But that has problems, I need a \!.
    . Even '<< b'2.~ { s4 \< s4 \> s4 } >> | b'4 cs''4 \!'
      is not ideal, the decrescendo extends to underneath the next note.
      If I put \! on the tied-to note, it still won't extend.
    . see \at in https://github.com/openlilylib/openlilylib/tree/master/input-shorthands/articulations-not-aligned-with-notes
    . Ideally:
      a \cresc \decresc % over duration of the note
      a \cresc ~ a \decresc % same
  - Lilypond.write_empty_staff creates incorrect rests for a tuple, as shown
    in Lilypond_test.test_add_bass_staff
  - to make notes without duration, ignore the existing duration and choose
    the simplest possible duration.  For zheng, yangqin, percussion.
    . Exception for +trem
    . Also applies to pizz, and sonically equivalent things like +det detache.
    . Or maybe I can fix detache in VSL by ignoring NoteOff, I think it can do
      that for pizz and staccato too.
  - optionally emit the lilypond to display a compound meter, e.g. 3+2/8
  jianpu
    . Research jianpu conventions, but basically:
      . Hide staff lines, stems, beams.
      . Noteheads replaced by numbers
      . Use a somewhat proportional layout.
      . Lines for 8th, 16th etc. notes.
      . Dots for octaves.
      . Stack chords vertically.
      . Grace notes as superscripts.
      . I still use lilypond's bars, slurs, tuplets, dynamics, etc.
    . http://people.ds.cam.ac.uk/ssb22/mwrhome/jianpu-ly.html
      . Produces extremely mangled lilypond.  I should make my own from first
        principles.
    . standalone commercial software:
      http://www.medeli.com.cn/soft/gb/soft.asp

negative duration / arrival beats:
  new arrival notes scheme infer-duration:
    . I don't want to trim because I might need the controls if I extend the
      duration.  I do want to trim because I don't want e.g. t-dia at start
      from the caller, but I do want pitch at start from the block.
    . t-dia:  0   1   0
              b1  b2
              a b|c   d
              a b|    d
    . If 'c' is present, then I clip off t-dia because I drop controls
      starting at 1.  The starts are replaced with ones from b1.
      So the sample at 'start' should come from the local block only.
      Samples after start can be used from global.  So what if the block
      call just deleted samples at exactly block end?  Any local tracks
      could put a sample there, but otherwise the event gets control signal
      afterwards.  If there is a note to replace, the >start samples are
      replaced, but otherwise, I get the ones from the caller.
    . E.g. global filter sweep.  A infer-duration note would stick out
      because the sweep is meant to be continuous.  In this case, I can
      just use the untrimmed control.  But t-dia should not do that, unless
      I really am treating it continuously.  This is the same problem as
      whether a control should continue changing into the decay or not.  The
      sweep should, but a pitch belongs to the next note.  So maybe this is
      a fundamental limitation of the score language.
  represent arrival notes differently
    . Instead of representing arrival notes as the sounding time plus
      a negative duration, I could represent them as a start time plus a flag.
      If the flag is set, it's considered an arrival note and the trigger line
      is drawn at the bottom instead of the top.
    pros:
      1 Cmds work the same for negative and positive durations, I don't have
        to do any special checks for overlapping with a following negative
        event.
      2 I can have a note arrive and another depart from the same point, e.g.
        trill up to a note.
    cons:
      3 The encoding seems not as elegant.  I can still do it with negative
        durations, but now the negative is just a flag, rather than
        representing the actual extent of the duration.
    4 This means that cmds work spatially rather than logically,
      i.e. I'll need a separate "set beginning" cmd since it becomes set
      duration for negative events.  I don't know if that's a pro or con, but
      it feels like a con since I need more cmds.
    #1 might not be compelling if I've already done the work to get them to
    work, but if it's buggy or turns into continual for for every cmd then it
    becomes a big deal.

external
  parsing "1r" instead of "1s" gives a "unexpected eof" error msg, it should
    say 'r' was an unknown suffix
    Can't get attoparsec to consistently report an error.  Kind of hard when
    it always backtracks.
    - Need to add <||> to attoparsec.
  + send a patch to improve Random.Shuffle?
    . I did a very long time ago, but author unresponsive.

local: plugins:
  . http://simonmar.github.io/posts/2017-10-17-hotswapping-haskell.html
    . packages: ghc-hotswap, ghc-hotswap-demo, ghc-hotswap-so
  I also want local code in haskell.
    . I could put code in Local.Score.SomeName, and have those either
      statically linked in, or dynamically compiled and loaded on each
      derivation.
    . Static linking is easier, but I should at least automatically create
      a All.hs.
    . Also, creating calls is a bit heavyweight, since I likely don't care
      about tags and doc and module can be inferred.  Presumably I can get
      around that with a constructor that defaults those fields, and then
      the generated All.hs overrides the module.
    . Writing in tracklang lacks typechecking.  There could be utilities to
      write like tracklang, but in haskell, e.g.
        c_p1 = with_note_call "p" "subst1" $ block "pattern"
  . ghc can now unload code: http://ghc.haskell.org/trac/ghc/ticket/8039
  . might be relevant: http://hackage.haskell.org/package/dynamic-loader
    http://codeutopia.net/blog/2011/08/20/adventures-in-haskell-dynamic-loading-and-compiling-of-modules/
  . to do per-score code, I can put it in Local.Score.<namespace>
    Convert to module name by replacing -x with (upper x) and capitalizing the
    first letter.
    Then when you load a score, incorporate the static config from that
    module.  Shakefile can link in the local modules under the right name.
    . If it gets to be too much overhead to link on every single build, then
      I can load dynamically at runtime.

cleanup:
  - replace fromIntegral with http://hackage.haskell.org/package/int-cast?
  - visualize module dependencies: https://github.com/yav/graphmod
  . Merge Val and MiniVal (RestrictedEnviron.Val for now).
    . NOTE [val-and-minival]
    . The problem is that I'd like to use Val to communicate with tracklang
      without having to re-parse, e.g. via Expr.ToExpr, but that means I can't
      use Val without dragging in Derive, due to VPitch.  I don't need the
      separate MiniVal if I can get rid of VControlFunction and make VPitch
      not in Derive, have a ShowVal, and serializable.
    . I already want to get rid of ControlFunction, but not sure how to do it.
    . I should be able to do those things with Pitch by adding more function
      fields.  Or alternately, typeclass + existential, but I'm not sure if
      that's any better.
  - switch from parsec to megaparsec?
    . Save it for a big ghc upgrade, since it requires a newer semigroups.
  - Cmds don't indicate when they could abort or throw.  I rely on ad-hoc
    conventions like get_ vs. lookup_, but what about it actually being in the
    type signature?  I could try the "lightweight checked exceptions" in:
      http://www.well-typed.com/blog/2015/07/checked-exceptions/
      https://www.reddit.com/r/haskell/comments/3g41au/follow_up_safe_lightweight_checked_exceptions/
    . Or an easier way would be to put 'throw' in a subclass.
    . I have this implemented in the p-monad branch, but it didn't seem
      terribly compelling.  I think the reason is that it turns out most
      functions can throw.  It doesn't replace get_ vs. lookup_ because they
      are likely to call something else which can throw.
  . Could I simplify slicing and inversion by making it into a score
    preprocessing step?  It would annotate UI Events with children, so the
    sub tracks would be in Event, not in Context.
    . If I could get rid of the ctx_sub_events / ctx_sub_tracks thing too that
      would be nice.
    . Could I also somehow make inversion universal?  The idea is to
      eliminate the thing where I forget to add Sub.inverting.
    . I could also take evaluation control away from the event, effectively it
      would mean the Sub.notes bit would be hardcoded and events would get
      [[Sub.Note]] instead of a TrackTree.  I'd lose power, but what are the
      advantages?
  . Things I don't like about evaluation:
    . All that stuff in Context.  The presence of sub_tracks can cause
      unexpected further inversion.  An example is that when I inherited
      the Context for Call.note_here, it also inherited the sub_tracks,
      which caused Call.with_pitch to be overridden.
    . It's also dumb how Context has the event (start, dur) duplicated
      in the 'event' field.  It's not duplicate info for track events
      because they have TrackTime, which is otherwise unavailable.
      This I think is ultimately due to events being in TrackTime
      context instead of (0, 1) normalized.
    . Maybe the problem is inheriting Context?  Or maybe it's awkward
      how it's effectively a manually passed packet of data, while the
      stuff in Dynamic is dynamically scoped.  Events wanting to know
      about their neighbors really does complicate things.
    simplify Context
      . Maybe I should explicitly provide specific bits of context, e.g.
        . prev, cur, and next event TrackTime
        . prev and next logical pitch
      . Say I do that, and put them in Dynamic.  How can I then get rid of
        sub_tracks?
      . I still need prev_val
      . There's nothing intrinsically wrong with Context, ultimately it's
        just an argument, like passed_vals.  I guess it's easy to remember
        passed_vals as just the arguments and understand how they work,
        while that sub_tracks stuff was confusing.
      . Maybe it's just the presence of sub_tracks in Context?  How can
        I get that out?
    . That 'collect' arg in Eval.eval_expr.  Why False for Eval.reapply
      but other functions make the caller decide?
  - pitch transpose
    . It's confusing how sometimes the environ is applied to the pitch during
      derivation (e.g. Post.set_instrument), and sometimes it waits for Convert
      to do it.  Do I really need both?
      . The environ goes in the Score.Event, which is then applied to the pitch.
        So Post.set_instrument actually maybe doesn't work, if the event
        still has environ.  I have to replace the event environ instead.
    . Post.set_instrument needs to set because I need the environ from the new
      inst.  Could I instead overlay the environ into the event environ?
    . It's error prone because there's nothing that enforces that you set
      instrument with Post.set_instrument, and if you don't, it will work until
      you use a scale with e.g. tuning, and then it will be slightly off.
    - Maybe I should at least not export Score.Event(..) so I can't directly
      modify its fields?
    . Or maybe insist on rederive instead of just changing the instrument.
      In general that's the proper approach.
    . Originally added in the patch 'add interpolate scale':
      The bigger problem was that since pitches got the Environ at conversion
      time, the interpolate scale couldn't substitute `key-from` and `key-to`
      because any environ values it set before evaluating the pitch wouldn't
      "stick".

      So I switched to applying the environ when the pitch is created, but this
      broke the case that made me switch to applying environ at the end in the
      first place, which is when switching instruments in a postproc I want the
      new instrument's environ, specifically Environ.tuning, to apply to the new
      event's pitches.  So now when I switch instruments I have to explicitly
      apply the environ from the new instrument, via Post.set_instrument.
    . Also error prone: I applied octave transpositions via Call.add_constant,
      but then realize-ngoret uses transposed nn to infer, and untransposed
      pitch for the final pitch, so I get a confusingly wrong result.  The
      solution is to apply via Pitches.transpose, but I shouldn't have to make
      complicated decisions like that.
  - It seems I get slicing on an already sliced track if I have an
    intermediate empty note track, e.g.:
      [(">", [(0, 1, "")]), ("> | +a", []), ("*", [(0, 0, "4c")])]
    . Is it a problem?  Should I skip if already sliced?  Document if it's ok.
  - use Data.Vector.Algorithms.Search.binarySearch instead of my own, but
    make sure it has the right specializations.
    . Or at least use mine in Util.Vector.
  - Modification of State is still kind of messy since I have lens and
    non-lens versions.  And if I wanted to modify with a lens I wouldn't be
    able to add an effect, like causing damage.  If I used ekmett lenses maybe
    I could unify effectful modification.  I'd also need a way to focus
    on UI state.
    . For example, I can add an allocation with State.allocations, but if
      I wanted to make that cause damage I couldn't.  Of course maybe it
      doesn't matter since I infer damage based on config changes.
    . Also I can't make sure that UiConfig.allocate is used instead of
      directly modifying the map.  The root of the problem is that I have
      unrestricted modification via State.modify_config, but even if I removed
      that I'd want something as convenient as lenses, but with the posibility
      of effects, or at least access to Ui.State and Cmd.State.
    . That said, I'm not sure how much this actually matters.  Maybe I should
      wait to see if it's actually a problem before worrying about it.
    . I guess it already has been a bit of a problem, in that the test had
      a bug where it put on the wrong backend.
    - If State.allocations is so read-only, why not make it a plain function?
      . Tests use it to write...
  - Research a better solution to records:
    . generic-lens combined with generic-lens-labels, OverloadedLabels, and
      DuplicateRecordFields
  - Why re-export UiConfig from Ui.State?  Why not directly reference
    UiConfig?
  - Can I make prev val or {Note,Control,Pitch}Deriver return values more
    typesafe with GADTs?
    . Study https://github.com/goldfirere/glambda for ideas.
  See about removing type prefix from record fields.
    . However, if there are lenses, then I need those names for the lenses.
      But perhaps the plain version can have a leading _?
    . Another bonus of the leading _ is I don't have to worry about unused
      function warnings.
    - Cmd.State
    - Derive.Deriver.Monad
    - Ui.State
    - Ui.UiConfig
    - Perform.Midi.Instrument
  - Util.TimeVector has a hack where a sample at <=0 is considered to extend
    to -inf.  It's because I want a control track call at 0 to extend back.
    But I could do that directly with a postproc ala the tempo hack.  It seems
    like a hack at a higher level is better than one deep in the signal
    implementation.
  - Expr is NonEmpty since there is always at least a "" call, but this is a
    special feature of events.  Would it make more sense to parse "" as [],
    and then special case [] in EvalTrack.derive_event?
    . But I'd need a newtype, otherwise ShowVal [Call] overlaps.  Of course
      the only reason it doesn't already overlap is that a don't have
      a ShowVal for NonEmpty.
    . But Quoted is also Expr... should it be non-empty?
    . I now don't remember where it was that I had an Expr that made sense as
      [], so maybe I don't care about this anymore?
  - Move Derive.info_prev_val to the environ, maintained by EvalTrack.
    . This gets rid of all the Taggable stuff, at the cost of making
      Args.prev_val in Deriver and dynamically typed.
    . There's no Val for Score.Event, so I can't use it for note tracks.
      Of course I could just add one, maybe not a big deal.
  - Overlap detection in Derive.Slice I think is still messed up, or at the
    least it's more complicated than it should be.
  - I could make the fltk interface clearer by putting c_interface.cc into
    fltk, and then putting all the types it depends on in one header.
    . I could make that a .c file too, and get rid of the sketchy hsc2hs on
      c++, as well as clang's "treating 'c' input as 'c++' when in C++ mode"
  - split up CallInfo depending on type
    I got started but was discouraged when it came time to write
    GetLastSample, maybe I should make another go.
    Note tracks can't get a GetLastSample at all.

performance:
  - profiling for complete scores is broken since I removed them
    . Derive_profile.profile_file etc.
    . Use the the verify score stuff instead.
  - Bring back profiling, and do it regularly.  Look into that graphing stuff,
    I have the links around here somewhere.
  - When I'm using ghc 8.2, try compact regions for inst db, especially vsl.
    . 'compact' package
    . Maybe even serialize it to disk?  Probably not worth it though, since
      startup is pretty fast and probably inst db is not a big part.
      . 0.584cpu / 0.222s.
    . Can I use heap profiling to find other large CAFs?
    . Can I use compact regions for the REPL loaded modules memory?
    . compactWithSharing is slower but retains internal sharing, test to see
      if it's worth it.
  . ghc 8.2 puts heap profile in the eventlog so I can align heap profile
    with events: https://ghc.haskell.org/trac/ghc/ticket/11094
  - Reduce memory used by REPL.  NOTE [reduce-repl-memory]
    . About 200mb.
    . GHC reads interfaces maybe with ghc/compiler/utils/Binary.hs:/readBinMem
    Try -fignore-interface-pragmas
      . From ghci: 210mb without vs. 1552mb with
      . But from REPL seems to make no difference.
      . Actually, I can't reproduce this now.
    . 200mb for an empty score seems excessive.  Where does it go?
      . With inst db: 197, without sysex: 190, without vsl: 187.4
      . Without repl: 12mb
      . So 190mb consumed just by loading .o files!  du on obj dir is just 76mb.
      . Loaded modules:
        [254 of 255] Compiling Local.Repl       ( Local/Repl.hs, interpreted )
        [255 of 255] Compiling Cmd.Repl.Environ (Cmd/Repl/Environ.hs,interpreted
        . with verbosity=2:
        . Stable obj: [Local.Instrument.Kontakt.Wayang, ... 253 modules
        . log: Ready for upsweep
          [NONREC
                ModSummary {
            { ... imports of every module }
        . compile: input file ./Ui/ScoreTime.hs
          *** Checking old interface for Ui.ScoreTime:
          [ 41 of 255] Skipping  Ui.ScoreTime( Ui/ScoreTime.hs,
              build/opt/obj/Ui/ScoreTime.hs.o )
          *** Deleting temp files:
          Warning: deleting non-existent /var/folders/6j/.../ghc_62.hs.o
          . bypecode compile for last two modules
    . 'du -hc build/opt/**/*.hs.o | tail -1' shows 55mb for object code,
      and 19mb for .hi.  I'd think object code would be loaded directly with
      little overhead, but that means .hi code expands by (190 - 55) / 19 = 7x
      expansion, which seems like a lot.
    . Also the memory measurements are haskell heap, which might not include
      loaded object files.
    . However, it's also loading .hi files for external packages too, though
      I'm not sure how much.  The external package code is shared libraries,
      which is shared with the app (and not in the haskell heap anyway).
    . Use dtrace to figure out exactly what the GHC API is loading and when.
    - I should be able to share object code by linking everything as a shared
      library... that might save 55mb at least?
  - Allocation when idle: about 300kb/sec
    . What triggers this?  Nothing, it's basically always happening.
      No, the allocation is always happening, but usually it doesn't get
      retained.
    ? Who is running?
      . Threads:
        / main - Ui.event_loop - should be blocked in Fl::wait,
          though it comes back on every cursor move.  But still allocates even
          when it doesn't have focus.
        . responder - Respond.responder - Should be blocked in STM.atomically
          block.
        / Midi.CoreMidi.initialize forkOS - goes into CFRunLoopRun
        / interpreter
        / Responder accept repl socket
        . Cmd.Performance: eval performance
        . Cmd.PlayC.play - updates the playback
        . Perform.Midi.Play render midi
      . Could it be EKG?
    . It stops during play.
    . Try disabling ekg and use LDebug.memory and see if it's still there.
    . It still grows without ekg.  Well, the second time it seems like it
      moves but doesn't grow.
    . Is there some way to instrument allocation so I can see which thread is
      doing it?
    . Actually it seems like ghci does it all by itself.  So it's either
      inherent to the GHC API or ghc runtime in general.
    . Does it grow with the repl off?  Yes, so apparently not the repl.
  - Control input lag, debug with Trace.traceEventIO
    . http://www.yesodweb.com/blog/2012/10/future-work-warp
    . Can I use custom events to see lags in threadscope?
      . Yes, but hard to visualize with everything there.
        I can get labels with View -> Event labels, but often they are jammed
        together, and draw inconsistently.
      . What do the numbers in threadscope's green bars mean?  ThreadId?
      . What I want is for each respond cycle to see where pauses were, and
        why.  I'd want to bracket the respond cycle outside of waiting for the
        next msg, get the total duration of each one.  Possibly I can do that
        by using ghc-events to process the eventlog.
    - GHC's +RTS -v flag is documented but doesn't exist.
      It only exists when -debug, but this isn't documented.
  - Criterion testing: why is cmd_derive faster than derive?  It should be
    doing more work!
  - Check out score size with 'weigh', ala https://github.com/haskell-perf
  - experiment with GC flags
    memory usage:
      . 200 mb -> 350 rss
      . 250 by LDebug.memory and ekg, 500mb by system viewer.
      . I think I have a very large proportion of static data in the GHC API
        loaded .hi files, so that should avoid GC as much as possible.
        Increase the generation count?
        . In the future can I put that in static memory regions?
      . Then I have a lot of short lived garbage generated on each derivation.
      . Then the rest is medium life: score data, Performances.
    . -A8m - larger generation 0 means fewer collections, good if lots of
      garbage is generated.
    . H - Suggested heap size.  I don't really understand this.
    . -qg - turn off parallel gc
    . -n2m - divide -A into chunks, so the first thread to run out doesn't
      trigger a GC for all of them.  Good for unbalanced allocation?
    . -I0 to turn off idle GC.  But it's designed to be good for interactive
      use, and maybe I do pause for >.3s.  Or turn it up to 1sec?
  - find space leaks with nmitchell's stack limit technique:
    . run build/profile/verify_performance +RTS -K975K -xc -RTS --mode=Profile
        p/cerucuk-punyah.state
      Derive.LEvent.events_of,
      called from Derive.Stream.zip3_on.\,
      called from Derive.Stream.emap,
      called from Derive.Stream.zip3_on,
    . Also, what's with the compile_library stuff in the middle?  Should
      I make it stricter?
    . Giving up for the moment since I don't understand the output.
  . Seq.sort_on winds up calling compare on Stack 13374153 times! 9.1% time
    I have to sort it because the stack is kept in reverse order.
    - Per-track stuff can wind up happening zillions of times due to
      inversion, so look for other places where I do work or collect data
      on every track fragment.
    - At least at one point, keeping EnvKey.seed up to date was expensive, and
      it's not even needed when there's no randomization.
    - I could analyze TrackWarp or TrackDynamic to get stats on how many times
      each block is called, along with overall stats on how many notes.  Just
      an interesting thing to know.
  criterion
    - score from a file
    - parsing
  understand deriver performance
    . I never know if changes I am making help or hurt performance, because I
      don't trust any of my profiles.  This means I hardly ever run them, at
      which point why bother having them?

    . Productivity is actually really good during derivation: 70-80%.  Only if
      I turn on heap profiling does it go down to 33%.  So maybe there's
      nothing to do?  Still, it seems like it's slower than it should be.

    . I want to find out how much list copying happens due to Stream being
      a list.  Perhaps I can use SCC annotations?  For transforms, I want to
      see the effect of a transform copying the whole stream so I can tell if
      making it interleave has an effect.
      . It would be nice to see how many times each cons is copied, but it
        would have to be for the output stream specifically.  How can I do
        that?  I think I would have to make my own list type, then count
        allocated cells?
    . Also, from heap profiling, the vast majority is PINNED, which is
      presumably ByteString.  But what is it then, if I'm using Text for
      events now?

  research using pipes for generators and transformers
    . This would handle the composed transforms thing.
    . What about parallelization?
    . What about the MergeList idea?
    . The bigger question is how do I do dynamic state when all the different
      calls are interleaved?
    . Actually now I'm thinking pipes aren't suitable for this.  Pipes are
      about interleaving effects, but derivation is pure.  But not quite,
      since it does depend on StateT.  In a pipes implementation, a generator
      would be 'P.Producer Event Deriver ()', and a transformer would take
      a Producer to another Producer.  Actually, since calls need to typecheck
      etc., it winds up being:
        type Events = Producer Event Deriver ()
        type Generator = Deriver Events
        type Transformer = Deriver (Events -> Events)
      . In a pure environment, pipes still give a constant bound on how many
        elements I hold on to at a time.  But since I look ahead arbitrarily
        much, maybe I don't want that.
    - Set up a pipeline over a StateT that returns Event.
    . The way to do this without pipes would be for transformer to be
      Deriver (Stream -> Stream).  Then I can run all the transformers, and
      then compose all their functions.  At that point, the only thing pipes
      would really give me is a clear picture of how many elements I need
      because each one needs to be specifically awaited... but it seems like
      the look-ahead stuff would be really inconvenient.  And I do the same
      thing, it's just less convenient with pipes.
      . It does mean I have to express all transformers purely.  This is true
        for the non-monadic Post functions, but it means I can't express ones
        where a previous monadic effect on a previous element effects a later
        one.  But that only applies to Threaded, and I can get that anyway by
        threading myself, so maybe there's no problem?
      . The way to prove that would be to remove the monadic Post.emap
        functions.
  make composed transforms more efficient
    . Composed transforms have to keep the whole event stream in memory since
      they can't interleave.
    . Would it then be possible to deforest the intermediate lists?  Bulit-in
      deforestation won't work because of the intervening call machinery, but
      maybe I can recreate it manually.
    - First, figure out how to measure the amount of memory used by
      intermediate lists.  It might be completely trivial.
    - First, I have to detach threaded state for the actual map.  This is
      possible because I don't care about Threaded or Collect.  So modify
      Post.emap_m to map a Derive.run over every element.  Then I need to
      collect the output and turn Left into a Log... or leave it in the stream
      somehow so I can throw at the end.
    - I think the stream will then remain lazy, and I should be able to GC
      as it goes, but verify with Debug.trace.
  - I'd like to see if directly modifying Collect or a MergeList for LEvents
    could reduce garbage, so I need to get some profiling up first.
    . monad-par-extras Control.Monad.Par.AList is deprecated due to poor
      performance, what's up with that?
  - Internal.merge_collect is constantly merging in mempty, try reducing its
    use.  Can I continue to enforce monoid-nature?
  - I should be able to move samples only when converting to MIDI, this way
    I don't need to move parts of the signal that wind up being trimmed.
    Either try to trim the signal earlier again, or delay transformation to
    Perform.
  - https://github.com/tobami/codespeed can make a web page with perf graphs
  . Signal.sig_op has 4.8% alloc, from Control.cotrol_call ->
    Derive.with_relative_control -> Perform.sig_multiply
    . So default multiplication for dyn is expensive.
  scrolling through giant blocks is slow
    - drawing is stil slow, I'll have to look at the fltk layer
      It happens when the block is wide.  Use test_block to see if it's just
      fltk.
      . It's fltk.  Not alpha draw though.
      Scrolling is weirdly chunky near the top when fl_scroll() is on.
      Curiously it doesn't seem to help at all.
    - Would it be faster to call fl_scroll once for all the tracks?  I could
      also theoretically call find_events all at once too, though that
      shows up low on the profile, so maybe it's not a big deal.
    . The thing is, it seems like fl_scroll doesn't actually help scrolling
      speed at all.  Maybe all the time is spent elsewhere?
  - Store signal chunks in the Ui.Track so they can be directly emitted.
    This is only useful for large chunks of 'set' calls, probably recorded
    from MIDI.  So it's probably not pressing until that feature exists.
    . make Ui.Events into 'Map ScoreTime (Event | Chunk Signal)'
    . collapse chunks of adjacent 'set' calls into a Chunk
    . track_derive on a Chunk just returns the contents
    . fltk event render should detect too dense events and omit them, rely
      on the signal render
    . UI edits should see the Chunk expanded out as Events.  Inserting an
      event should modify the chunk or split it depending on if the inserted
      event is a set call or not.
  Cmd
    - If a msg aborts or doesn't run any cmds, don't bother to run diff.
      Except that hardly ever happens if I do shortcut thru.
    - cache track cmds for each track, update when the track title or skeleton
      changes
  Derive
    - parallelize derivation
    AppendList / MergeList for Derive.Stream
      - switch to AppendList and try to get garbage down
        Avoid copying sublists returned by block calls and cache hits
      - see if a Merge constructor can reduce copying
      - can I cache length and range in AppendList?  does it matter?
      - insert parallelism?  maybe the evaluator can do that when it sees
        Merge?
    - lazy signals
      - check out 'at' and 'bsearch' occurrances and see if they can use tails
      - There are lots of lookups in the tempo map
    - see if making a version of Derive.local that's non-monadic in the
      modifier has any effect on performance
    derive cache:
      - can I cache long blocks by slicing them if they're >n?
      - c_block should only cache if the block has > a certain number of
        events.
      - I won't rederive cached generators if they have control damage outside
        of the event range.  But there's nothing stopping a generator from
        reading ahead or behind... come up with some kind of solution for this.
    - fair amount of garbage generated by SignalBase.bsearch_above, I think
      this is because it has to box the values when it pulls them out.  But
      it's really just comparing to a Double, so I should be able to do the
      operation unboxed.  But decide about lazy signals before going nuts on
      this.  If I revert to linear search then none of this is necessary.
    - at_linear is called a lot by compose, by compose_warp, by d_warp
      can I make this more efficient?

fltk:
  - Floating input in the wrong place for negative events with multiple lines.
    . Because it assumes the text goes downwards.
    . Since haskell doesn't know how the text is wrapped, it can't know where
      to put the input.  I think I'd want the input itself to know it's
      wrapping upwards, so it can get it right during input as well.
    . It seems like too much hassle for a cosmetic issue.
  * It's annoying to edit long words (e.g. kotekan kernel) in FloatingInput
    because the box is too narrow.  Can I automatically expand the width to
    fit the longest word?
  better drawing
    . All this incremental redraw stuff is fussy and seems like it should be
      unnecessary.  I should be able to lay it out and have someone else handle
      selection overlay and scrolling.
    . How hard would an OpenGL version be?
    . Or why not get rid of the callback, and just keep the complete track in
      c++, like I do with the signals.  I think I need to do that anyway for
      OpenGL, and that way I don't have to play with getting event ranges,
      I can just scan the whole range on every draw.
  - Maybe I could ship over a chunk of playback data in advance, and let the
    UI interpolate playback cursors.
    . If I could keep the warp as linear segments then I just need to ship the
      segments.  NOTE [signal-discontinuity]
  - FloatingInput on linux doesn't interact well with a tiling window manager.
    The new window probably needs to be marked transient.
    . Can fltk even do this?  I can't even figure out what xprop should show
      for transient windows.
  - Factoring a bit of score into a call makes it less readable because
    I can't see the events inside.
    . I could put a mini version in the background of the event.  I'd need
      to be careful to retain readability.  Maybe only show the frist track,
      or the first note track.
  - reduce duplication in EventTrack.cc drawable_pixels
  - I need to differentiate DEBUG from LOG.  And LOG can go to seq.log.
    . I'd need to pass a haskell callback, so it can serialize to JSON.
  * negative event text is pushed downwards the more it wraps
    . Probably that padding pixel making it not line up.
    . All these padding tweaks are a real mess.  Can I get rid of them and
      apply them all in one spot?
  * event "a`tamil-i``xie`" clipping with next event is wrong
  - what's going on with SeqScrollbar and FlSeqScrollbar?  Looks incomplete?
    . It still might be useful to put the top level ruler labels, or cues if
      I ever use those, but I'd have to make it wider.
  - Do I want to support set_ruler for Scrollbar?
  - Drag on an event track title doesn't work, because the new FloatingInput
    doesn't realize that a drag has started.
    . Explicitly sending it FL_PUSH doesn't seem to work, but maybe
      something similar could?
  - It gets a few extra focus/unfocus pairs before show, why?
    . I hacked around with FloatingInput::ready.
  - Also, it seems resize on a window which is a child of another window
    goes into endless recursion.  What is a child window supposed to mean
    anyway?
  - Manually fiddling with track widths is annoying.  It seems like I could
    ask the UI about text extents to resize them automatically.
  - I never wound up using rank > 1, so presumably I could simplify things by
    calling it 'bool align_right' or something.
    . I'm using EventTrack::Align, but the haskell side is still sending
      ranks.
  - When multiple marks from different marklists are in the same place, their
    text collides.  The one from the first marklist should take precedence,
    as should its line.  This is visible when I add logical range markers.
  ? There's an extra axis of information in the width of the event body.  How
    could I use that?
  - add edit and windows menu to all apps
    There must be special OS X support for these
    Apparently not?  iTerms is defined in English.lproj/MainMenu.xib
    https://developer.apple.com/library/mac/#documentation/Cocoa/Conceptual/WinPanel/Tasks/UsingWindowsMenu.html
    But it doesn't say how to add the Window menu.
  drawing artifacts on retina:
    . Some of this may be fltk bugs.
    - tops of tracks and the tops of track text boxes still get gunk, visible
      when scrolling horizontally
  - bug: There's a focus bug, but I'm not sure how to reproduce it.
    . The focus bug is still here.  Even clicking on the "unfocused" block
      doesn't fix it.  Don't all msgs contain focus?  What can I log after the
      fact to figure out what's going on?
    . Actually this makes me think it's actually in MsgCollector.
      In that case it would be Fl::focus() which is wrong.  Is there a way to
      just ask the OS what window has focus?
    . Cmd.state_debug_ui_msgs doesn't help because I have to take off focus to
      turn it on.  I would need a key stroke that does that.
  - I could set certain Symbols to stretch to the length of their event, this
    would yield a nicer looking score.  But it would mess up the bounds
    detection.
    + gmail: subject:(scaling text)
      But it's OSX only.
  - figure out how to have a minimal title bar in os x (win.border(0) removes
    it altogether)
    I can set something like kUtilityWindowClass in Fl_mac.cxx:Fl_X::make, but
    it doesn't get any kbd input
    . can I get fltk to omit the jellybean buttons on the window?
      . Yes, but requires hacking fltk.
      . Completely disables resizing.  Apparently this is hardcoded.
  incremental redraw / scrolling
    . I don't like the current situation of incremental redraw and scrolling.
      It's also buggy, i.e. one pixel difference between scroll and redraw.
      Get rid of damage and redraw everything every time.  Then I have to make
      it fast to fetch the data for one screenful.  What makes that slow
      currently?
    . Entirely turned it off, speed seems acceptable.
  Track
    - dividers can have separate color for upper part, for collapsable tracks
  + Disable application persistence for fltk apps:
    http://oleb.net/blog/2011/07/whats-new-for-developers-in-lion-part-1/
    http://developer.apple.com/library/mac/#documentation/General/Conceptual/MOSXAppProgrammingGuide/CoreAppDesign/CoreAppDesign.html#//apple_ref/doc/uid/TP40010543-CH3-SW26
    Can then re-enable ~/Library/Saved Application State.
    . Did the objc call, but doesn't seem to have any effect.

  control track, render signal
    - render option: solid with color gradient
    - combine multiple signals, e.g. one controls xpos, one controls color
      I could combine pitch and dyn.  This is appropriate for the note track.
      . I'm pretty sure OS X can do this, as can cairo, so I would need to
        figure out how to get direct access to that API.  I could get rid of
        the awful alpha_draw.cc hack while I'm at it.
      . Or perhaps I should just switch to OpenGL?

logview:
  - use Fl_Help_View and HTML to display text
  + Logview got some kind of file locked error, presumably trying to track
    a rotated log.
    . It happens if the write handle is still open, for some reason
      Posix.getFileStatus then gets openFile: resource busy (file is locked)
    . But I also got:
      . logview: ./log/seq.log: openFile: resource busy (file is locked)
      . Apparently not caused by log rotation.  Maybe if it checks for
        rotation at the same time a new line is written?
  - can I get the standard edit menu and copy/paste?
  - tabs are not lining up properly
  - option to wrap lines or not?
  - hide or display various attrs: date, file, function, ...

Ui:
  Track
    dense sampled signals
      . efficient storage, preferably as a Signal so no conversion is necessary
      . display dense signals: omit text and trigger lines when zoomed out

test: testing:
  - Write a test for Ui.Diff and Ui.Sync.
    . I think the easiest way to do this is make BlockCStub record its calls,
      then have a UI simulation that interprets those.  Then I can use
      quickcheck to verify a bunch of starting and ending states.  It would
      compare the incremental output against creating the visible UI from
      scratch.
    . It seems non-trivial... but maybe worth it, seeing how complicated
      diff and sync are.
    . If I make Fltk into a typeclass I could substitute a pure State version.
      But I still can't get rid of FltkStub, because the main point is to not
      link in C++.  So as long as I'm doing that anyway, maybe I don't even
      need a typeclass, but I still have to replace the PtrMap functions so
      I don't need MonadIO.
    . Except BlockC uses IO in PtrMap.modify... but that's in BlockC, which
      relies on Fltk (IO a).  BlockCStub wouldn't need that.  So unstubbed
      Fltk is in MonadIO, stubbed one isn't.
    . But how am I supposed to record calls to BlockC without reifying the API
      into a type?  And if I do that, I don't need to do this at all, just
      have Sync return that type.
    . I guess I'm not too worried that an intervening data type will hurt
      performance.  Mostly because just one more allocation is probably not a
      big deal, but also maybe if I inline the interpretation function then
      the allocation goes away.
  - delete build/test/tmp on every test run to avoid test contamination
    . test/run_tests will clear it out, but sometimes I run them directly
    . But this is pretty much limited to expecting a file in a certain
      place, which pretty much only Perform.Im.Convert does.  Tests that
      create tmp files should use Testing.unique_tmp_dir.
  complete quickcheck derive testing
    I switched back to Double for RealTime, but this means the roundoff errors
    are back.  Use quickcheck to repro them.
    + make a simple deriver that creates event and midi output skeletons
    - integrate quickcheck with generate_run_tests.py
    - assert that the reduced deriver output equals the simple deriver output
    - basic pitches: If the score was created with notes aligned to note
      starts, then every NoteOn should have the appropriate key, there should
      be no pitch bends, and "same note" should be the only reason for
      a channel split
    - basic controls: Given randomly placed control events, notes have the
      correct control curves.  Don't worry about times or midi.
    - slicing: Given some simple note transformers (tuple, place, ...),
      pitches and controls are still associated with the right notes as above.
      Don't worry about times, just that the right notes and the right
      controls.
    - block call property: a couple levels of nesting for block calls, notes
      still have the expected pitches and controls as above
    - inversion: as 'basic pitches' and 'basic controls', but controls are
      below the note tracks, results should be the same
    - stack: generate nested events, check that stack is as expected
  - count number of tests in addition to checks within each test

debugging:
  - Can I have a way to display inferred things about notes, such as reyong
    hand, and damping status?  I could integrate it back into a score but
    with text on the notes, sort of like a visual log.

midi record:
  - implement
  . Ideas for editing recorded MIDI:
    . control: realign attacks, smooth or sharpen attacks.
    . pitch: retune intervals, fix wrong note or add notes, change portamento
      speed.  Add, widen, or narrow vibrato.

REPL: repl:
  - sometimes vim fails even though the app is open:
    App/Repl.hs:274 - non-zero exit code from ["vi","-c","source vim-functions.vim","-c","source ky-syntax.vim","-c","nmap gz :call Send('LState.set_ky %s')<cr>","+0","repl-NDpIUn"]: 1
  - vim should abort the changes if I quit with :q instead of ZZ
  - :h should put the selected cmd into the history
  - something like :h where I can edit a single line
    . Maybe a control key, so I can edit the contents of the current line.
  - It would still be useful to save a single unified history.  Then use
    something like :h to search it.
  - It's easy to leave vi open on a ky file and change scores.  Maybe it could
    send the score name, and reject if it's changed.
    . Another way is if I add back push notifications that the score has
      changed, I could kill off the editor.  But I'd lose unwritten changes.
  - Now that save file is a poll instead of being pushed, it takes a return
    to notice a change.  Can I restore the notification thing?  Or maybe it's
    enough to make sure I write the history to the new name?
  - I don't really use ReplStub, can I get rid of the awkward #ifdef then?
  - only write history when the cmd succeeded
  - command to open the haddock for a module
  - is Cmd.Lang.Fast now obsolete?
  - can I get local variable bindings (let x = ...; y <- ...) to work in the
    REPL?
  - :compile cmd that turns on compilation for everything except Environ
  - :browse to look in modules... can I use GHC.getBindings for this?
  - :module cmd to move evaluation context to a certain module, maybe I
    could also get rid of the need for Cmd.Lang.Environ to import everything.

solkattu:
  transcribe:
    - after 2014-06-17
    - complete Mridangam2013.dinnagina_sequence, maybe move to solkattu.
  format: output:
    - nadai changes are invisible, I should put something in the ruler for it
    * avartanams tag is often wrong
    * Solkattu2013.k3s has <hr> in odd places
    - underline for tha+x looks weird.
    html:
      - Decrease font size for higher speed.
      - For high speed split avartanam.
      * write html for everything in the db
      db ideas:
        - similar_to should be a link
        - source should be a list, click on it to see everything from that
          source
        - link to a specific spot in a recording
      * html output for realized strokes
      * I don't have to scale the font down.
      * extend double line instead of = for sarvalaghu
      - Replace a double rest that starts on an even matra with a double
        underline, or something.  This is effectively rhythmic spelling.
        . Alternately, I could put in a number for matra count.
      - Can I align by structure?
        . E.g. reductions or tri would line up vertically.
      * gray letters for light strokes
      * Highlight groups in konnakol html.
      * draw a vertical line on aksharas, maybe double for angas
      * figure out how to get even spacing for the html output
        . style="table-layout: fixed" doesn't seem to work, or at least I don't
          understand how it works.
    ascii:
      - Colors stop right before the last note, not on it.
        . It's probably because I need to highlight the end of the group.  Can
          I use lighter gray?
      - If groups touch each other then I can't tell them apart.  Maybe
        I should alternate two colors.
    / Solkattu.notation should output an abstract formatted output, which can
      be rendered to HTML or ASCII.
      . I added notationHtml, which is more error-prone, but simpler.
    - format: if the ruler changes after an avartanam line break, show the
      partial ruler, e.g. Realize_test.test_format_nadai_change
  * It seems technique is not working for Solkattu2016.c_16_12_06_sriram1
  * Move Solkattu directory to the top level, it's not really part of Derive
    . At some point it might be a completely separate package.
    * I could also switch over to camelCase.
  * Sequence.hasDuration should be hasSustain
    . Otherwise it's confusing because obviously it does have a Duration.
    . Well, it doesn't actually mean has sustain though.  It means this
      note should turn into a call with duration, which in turn is because it
      has other strokes inside of it.  I'm not sure what to call that, but
      duration is definitely confusing because of the local usage of Duration.
  * Sequence.Tempo fields don't have a leading _, make them all consistent.
  - Can't I have a shorter name for dropM?  dr?  dp?
    . Is it really so common?
  - What if I just renamed Sequence to S?
  What would a web UI look like?
    . Have a field for the where block, a field for mridangam (or other)
      strokes, and korvai fields.  Separate entry for name and tags.
    . Enter sends it off, where it gets interpreted, and mridangam and
      konnakol realization appear next to it.  There are probably examples out
      there for semi-securely evaluating haskell, but even without them
      I think it may be hard to do evil things if you can't import modules,
      and I should be able to run as nobody anyway.  The main thing is
      noticing and killing a loop.
    . The DB goes in a separate repo, which is edited and synced from the web
      UI.
    . To render sounds, I don't know if there is software to host and run a VST
      automatically.  If I have my own sampler it's easy though.  I can either
      run karya headless, or just bypass and generate im notes directly via
      the solkattu library.
  - How can I do a reduction with irregular bits?  E.g. replace the
    4 matra version tat.__.din.__ with ta.ka.din.__.
  . Solkattu2017.c_17_07_13 is showing the difficulty of the
    (solkattu, stroke_map) approach, because there are too many meanings
    for taka and din.  Really if it's meant to be useful for different
    realizations, I should emphasize the reusable phrases, so I should
    try to figure out ways to make that easier.  For instance,
    understanding about reduction is good for that.
    . To an extent, it's acceptable that it's harder than just writing
      the strokes, because I'm trying to find a more general
      representation.
    . Still, I could make it easier with tools:
      - Lint to show unmatched stroke sequences.
      - Diff to compare realizations before and after I change the
        stroke map.
        . How can I keep them both around?  If I do it at the haskell
          level, I have to copy the stroke map, and then have multiple
          stroke maps for the same instrument, and then diff between
          them.  This might be useful in general to highlight different
          players style.
        . If I do it at the ghci level, I'd have to somehow stash the
          previous previous Korvai or realize output someplace that
          survives a reload, like write a file.  Then add a function to
          do a text diff with the file contents.
  / Final notes should be cancellable, so e.g. tri will cancel for the
    first two.
    . E.g. tri (taka.tam.__) is ok when it's at the end, but when I nest
      it: tri (tri (taka.tam.__)) I need to rewrite as
      tri (tri_ (tam.__) taka)
    . Actually, don't I already have the karvai mechanism for this?
      What if I do tri (taka. karvai tam.__)?
    . Not quite, I'd have to do 'tri_ __ (taka . karvai tam)
    . The problem is I don't really have a well defined notion of when
      cancelling is ok.
    . Or maybe it's better to use tri_ after all?  Are there cases where
      either I can't express with tri_, or it's really awkward?
  - Some strokes change realization based on the tempo, e.g. 'od' when
    slow to 'o' when fast.  I could add a stroke attribute for that, or
    I could try to do a global instrument realization heuristic.
    . Not just individual strokes, but a whole section can change, e.g.
      okookook -> nakatiku.  This implies just a realization heuristic
      won't be enough, though maybe I want it anyway for things like
      dynamics.
  - Can I put StrokeMap and Patterns together?  Then I can put standard
    strokes along with the stroke map, and override them together.
  - ensure that later entries in the StrokeMap override earlier ones
  - have a mode to warn about unused StrokeMap entries, and overidden
    ones
  karya integration:
    - LSol.insert_* doesn't clear and replace existing notes
    - I want to be able to insert all parts of a korvai in sequence.
      . If I make LSol.insert take [Korvai] then I can use take etc.
      . But it's easier if I get rid of multiple sequences per Korvai.
      . Or keep multiple sequences but take [Index].
    - insert for patterns is messed up, I get p '5' with 0 dur.
      . '5' is because I use Expr Text, and it uses ShowVal, which loses
        the type, so everything becomes a Str.
      . It's Text because I want to avoid relying on Val.
      . Which in turn is because I wanted to emit expressions like (4d)
        and have it be evaluated.
      . But I can do that, just skip parsing, right?  Maybe a Expr MiniVal
        instead of Expr Text.
      . Can I use RestrictedEnviron.Val?
      . Not directly, because of circular imports via RestrictedEnviron ->
        BaseTypes -> Expr.
      . But maybe I could move Val to Expr.MiniVal?
        . VNum !ScoreTypes.TypedVal
        . | VAttributes !Attrs.Attributes
        . | VControlRef !BaseTypes.ControlRef
          if I move Ref ControlRef to ScoreTypes.
        . | VNotePitch !Pitch.Pitch
        . | VStr !Expr.Str
        . | VQuoted !Expr
        . | VList ![Val]
      . See NOTE [val-and-minival]
  sarvalaghu:
    . Fill it in based on position in the tala.
    . Sometimes there's a final note, e.g. D that replaces the first 1.5
      aksharas.  I don't have a way to notate it.  Maybe a sequence
      needs a separate final stroke, which is played when leading back
      to sarva.
    - Sarva fill === gets some spaces in there.
  ? Some patterns are end-weighted, e.g. thom in sarvalaghu.
    . I can just add a rest to the beginning, but I still need to
      take duration from the previous note, e.g.
        d.d.n.n . su (n.d) .d.n.n
      should be ' d d n nnd d n n'
  / rename tri to tir, for tirmanam?
    . Nah, a bunch of changes for no big gain.
  groups:
    This whole groups stuff is still a bit of a mess.
      . Having to keep group count up to date in 'Realize.realize'.  I could
        fix this with a nested FGroup, but of course introducing other
        problems.
      . I think the group _split compensation for After in
        Realize.split_strokes is incorrect.  I think split_strokes or the
        whole collect group thing should be recursive.  Making FGroup nested
        might be good for this.
      . I *still* don't really understand Duration vs. Matra vs. FMatra.
        I think the notion of local FMatra is required.  Duration is useful
        at the DSL level but it only makes sense at the toplevel which means
        it's actually error-prone.  Maybe I should get rid of it entirely,
        except at the global level where I can be sure it's right, which
        basically means after 'Realize.realize'.
      . Can I do quickcheck tests for various durationOf and matrasOf?
      . Do some tests to make sure I understand Solkattu.durationOf and
        Solkattu.matrasOf.
      * Realize.realize should interleave the cancel group thing.
        . But try switching to a proper recursive implementation before doing
          all this work.

    * Mridangam2013.dinnagina_sequence is broken.
      . It's because replaceEnd uses rdropM_, which directly modifies the
        sequence.  That makes the _split from takeD no longer valid.
      . One way is to get rid of the _ variants, but I need them when
        I explicitly don't want to make a group.
      . I think the _ variants could just flatten out any groups in there.
        In practice, replaceStart and replaceEnd are used only in
        Score.Mridangam*, so I could avoid all of this by moving the
        _ variants from Notation to MridangamGlobal, and using them to
        replace the non-_ versions.  Then replaceStart,End are only in
        MridangamGlobal.
      . Well no, actually Solkattu2017. c_17_09_25 uses it, and it seems
        legit.
      . Mridangam scores don't need groups for realization, just for
        highlighting.
      / Move replaceStart and replaceEnd to MridangamGlobal, along with takeM_
        variants.
      * Make splitM_ flatten a group it splits.  It doesn't makes ense to
        leave partial groups anyway.
      * But it's still broken with eg.. takeM_, because matrasOf understands
        group Solkattu._split, while the splitM_ doesn't.
    * Make FGroup recursive.
      . This means the consumers will have to become recursive too.  This may
        not be convenient since they are rendering to flat text.
      . Recursive makes it harder to collect output before failing.
      . Also splitStrokes has to split a group.
      * Realize Flat2 versions.
      * Put UntilFail in its own Util module.
      - Solkattu.cancelKarvai
        . This is a pain to do with nested FGroup because I want to look at
          and modify a future stroke.  Karvai is likely to happen acros group
          boundaries.
        . However it turns out I don't use karvai at all anymore, so I can
          remove it.
        . But it seems bad in general if this kind of modification is too
          hard.  The totally flat format has that advantage at least.
        . E.g. what if I want to do the same in a technique?
        . Maybe worry about that when it happens.  I can still flatten out
          groups after realize.
        . That's wrong, I do use karvai, in one spot.
        . I can get rid of it, but it does seem to better express things, and
          it seems a shame to lose it just because the implementation seems
          annoying.
      * Korvai realize2, has to process UntilFail.
      * Realize.format
      * technique, and instPostprocess
      * tests

    - Get Nakatiku out of Pattern.  I can use the Standard tag, but I like
      the unexpanded form.  I think this does need named groups.
    - Don't make tk and tktu groups, or at least don't highlight them.
    unify patterns and groups:
      . Groups have an optional name and highlight :: Bool.
      . Then a realizeByDefault :: Bool, which says if realizePatterns :: Bool
        will replace it.  Otherwise it can use name or "p" <> matras.
    / dropM shouldn't make a new group if there already is one
      . E.g.  dropM n (group x . y) puts both x and y into a group, instead of
        leaving y out.
      . This breaks 'sandi'
    * I have a problem with nested groups, e.g. dropM 1 . dropM 1.
      . I could try to simplify away nested groups.  That means making
        each one absolute, so the outer one loses its sollus, and they go
        on the inner ones.  Of course if there aren't inner ones, then
        I gave to give them the group, and it seems complicated.
      . I could try to simplify just simple nested groups, where all the
        children are groups.
      . I could try to not produce them in the first place, so splitD
        could do the simplification.  I think it's the same, just built
        into splitD.
      . Or I could try to get realize to understand nested groups.
        I guess it would have to accumulate sollus when it sees a group,
        and put them on any sub-groups.  Still I'd like to simplify for
        the same reason I simplify tempo changes, which is to make the
        intermediate data less hairy.
      . For now, just make reduce not produce them.  Try simple
        simplification later.
      . The reason to make 'realize' understand nested groups is that then
        it works for other ways to wind up with them.  For example?
      . dropM 1 (ta . dropM 1 (di . ki))
      . But do I really want this to look for tadiki, or should it be taki?
        I need a realistic example.
        . Reduce a phrase, where one element has a replaceStart on it?
          No, because replaceStart explicitly doesn't use a group.
        . Nested reduction? reduce (reduce takita) =>
          takita kita ta, kita kita ta, ta kita ta, kita ta, ta ta, ta
        . These should definitely use takita.
        . But on the other hand, what about simultaneous reduction:
          takita dhomdhomka thom
            kita     dhomka thom
              ta         ka thom
        . I could model this as:
          zipWith (.thom) (reduce takita) (reduce dhomdhomka)
        . Ok, then what about dropM 1 (takita . dropM 1 dhomdhomka)
          The least confusing would be to look for takita and dhomdhomka,
          but with nested groups this would look for takita and tadhomdhomka,
          which is definitely no good.
        . But dropM 1 (dropM 1 takita) should look for takita, not kita.
        . Of course I'd actually write dropM 1 takita . dropM 1 dhomdhomka
          but maybe there are cases where I get the nested one accidentally?
        . What exactly is the sandi error about?
          t4 t3 t2 are each groups.  sandi (t3.t2) drops the first t3.t2 from
          the tri, which should reduce it to [].
        . How then does this become looking for t3 and t2 separately instead
          of t4?  I should wind up with:
            dropM 1 t4 . dropM 2 t4
            . dropM (5) (dropM 1 t4 . dropM 2 t4 . tat.__.tam.__ ...)
        . So the group winds up being (t3.t2.tat.__.tam.__)
        . Since in this case the t3.t2 is totally dropped, I could fix this
          by saying if I can find the suffix (tat.tam), then don't bother
          looking for the prefix (t3.t2).  But this in turn would cause groups
          with identical tails to match wrong, e.g. dropM 1 takita would match
          kita.  The key thing is I don't know if a match with the prefix
          would have included the suffix or not.
        . But not necessarily, because I first try with the prefix, and only
          try suffix only if there is no match with the prefix.
        . But even if this does work, it seems like a hack that will break as
          soon as I'm not happening to drop an entire group.  E.g. I could
          sandi away a fragment:
            reduce3 (taka.takadinna.naka)
            . sandi naka (tri_ din (naka.dinna))
              =>
            taka.takadinna.naka
                 takadinna.naka
                     dinna{naka
                           naka}dinna.din
                           naka.dinna.din
                           naka.dinna
        . This works though, it's just dropM 2 (naka.dinna).
        . But, if nested groups were implemented, then the dropM 5 add
          dropM 1 t4 . dropM 2 t4 back on, which in turn would turn into
          t4.t4, which matches on t4 as expected, even though they all wind up
          getting dropped.

      . It seems there are two ways to implement groups: distributed, and
        plain.  Distributed means given
          group x (a . group y b . group z c),
        'x' is distributed among the subgroups:
          a . group xy b . group xz c.
        Plain means it's just goes on the beginning:
          group x (a . group y b . group z c)
          group x a . group y b . group z c
          . If there's no 'a', i.e. directly nested groups, then the 'x' is
            lost.

      . Still, what about reduce (takita . dropM 1 theme . din)?
        It seems like it should match takita and theme.
        plain: match takita and theme        ==> good.
        distributed: match takita . ta.theme ==> bogus.
      . But it also seems like nested drops should work:
          dropM 1 (dropM 1 nakita).
        plain: group [na]+ kita ==> group [ki]+ (group [na] ta) ==> bogus.
        distributed: group [ki]+ (group [na] ta) ==> group [na, ki]+ ta ==> good

      . Unless I could specifically looked for directly nested groups, so:
          group [na] kita ==> group [na, ki]+ ta
        which is now unnested and sensible.  But it only works when both
        sides are the same, e.g.:
          group [na]+ kita ==> group +[ta] (group [na]+ ta)
        is back to needing distributed groups.

      . It's like I want distributed for directly nested groups, but not if
        there's something in between.  But is that too ad-hoc and complicated?
      . How could I even implement it?
        That would be the hack in Notation.splitD.

      . Ok, since I don't know what to do, and I think plain groups are
        currently implemented, let's just do that.  But:
        * Change Sequence._marks from Maybe (GroupMark g) to [GroupMark g] so
          I can represent directly nested groups at least.
        . realize looks for suffix if prefix++suffix doesn't match.
          . This should fix the sandi examples.
        . splitD implements the directly nested hack.
      . Actually it turns out the sandi situation is not what I thought:
        . Given (dropM 3 $ dropM 1 nakita <> nakita)
        . The dropM 3 drops the first group with the leading Na, so the
          fact that there was one is lost:
           group [na] [ki, ta] . [na, ki, ta] ==> group [ki, ta, na] [ki, ta]
        . Instead it could collect the [na] from the group at the front:
               ==> group [na, ki, ta, na] [ki, ta]
        . Alternately, I could omit the [ki, ta] from the dropped group from
          the prefix.  I guess the rule would be don't include parts of other
          groups in a group's prefix.
        . Is there any reason prefer one over the other?  The first would be
          better if I needed that prefix to match, and doesn't happen to drop
          a whole group, e.g. dropM 1 . dropM 1.
        . For both I need splitD_ to return something extra, either the extra
          prefix/suffix, or the number of sollus to leave off the
          prefix/suffix.

        . Another way is that the group prefix can have nested groups in it.
          Then they have to be expanded recursively.  Then
           dropM 3 $ group na [ki, ta] . [na, ki, ta]
              ==> group (group [na] [ki, ta] . na) [ki, ta]
        . Expanding recursively might not be as scary as it sounds, because
          it's just a full SequenceT, so I just tack it on in
          'Realize.realize_group', instead of faking up Solkattu.Notes.
        . Then I have Group sollu = [sollu] ==> [S.Note (Group sollu) sollu].
          It's still not exactly a SequenceT, so I still have to do some
          faking up to get it to one, specifically:
            S.Note (Solkattu.Group sollu) sollu -->
            S.Note (Solkattu.Group sollu) (Solkattu.Note sollu)
          That's not bad at all, fmap (Solkattu.Note . Solkattu.note) should
          do it.
        . So it seems possible, but worth it?  I think maybe so, because
          I don't need any ad-hoc rules like collect sollus from the first
          group... which breaks if there is a second group.
        . In fact, maybe this implements the non-distributed "plain" group
          technique already.  Actually no, it just makes it work from inside
          the _dropped.  I think it already works outside.
      / Change Solkattu._dropped to [S.Note (Group sollu) sollu].
        . It turns out S.Note (Solkattu.Group sollu) sollu ->
            S.Note (Solkattu.Group sollu) (Solkattu.Note sollu)
          above is wrong.  I need to go
            S.Note (Solkattu.Group sollu) sollu -> Solkattu.Note sollu
          It's because it's already flattened, so I need to flatten the
          _dropped.  But the groups have also been flattened out, so I can't
          do it unless the caller can not do that.
        . Realize.realize gets them as [(Meta, Solkattu.Note sollu)], so
          I need to go to (Meta, Solkattu.Note)
        . Oh and it turns out 'reassociate_strokes' uses Meta == Nothing to
          identify the strokes from _dropped, and stuff them back in again.
          I'll need another way to do that.
        . Presumably the stroke groups should now also retain group structure,
          even though I don't think I actually care what's in there.  Can
          I reassociate right after the realize and use the count?  I know how
          long 'extras' is
        . reassociate_strokes might even be wrong, because it always puts
          Nothings into the following Meta, but that's assuming everything is
          a Front group.
        . What if the dropM splits a group?  I'd have to put it back together,
          but if I make another S.Group the size has been lost.  But if I put
          it in flattened, then I can just mash them back together.  Well,
          except I'm still splitting the S.Group, so I lose the size anyway.
        . Maybe I can get around it by not splitting the group at all, just
          put in the complete sequence, along with a split point.  Then the
          job of realize is to drop the extra strokes after realizing them,
          and emit the group boundaries.
        . Actually I could leave that to a later step, and in fact leaving it
          generic might be best because if I do this then pretty printing can
          get confusing because the extra dropped bits are still in there, and
          having a way to strip them out could be useful.
      * Change Solkattu._dropped to (Side, Duration).
      * The realized output needs dropped strokes, since Technique relies on
        it.
      * I have to make matrasOf understand Groups.
      * realize c_17_08_29 gets an alignment error, but it looks right?
        . Because verify_alignment is using pre-degrouped notes.
      * _dropped Durations are wrong.  This is because they are taken as
        absolute, but of course they are relative.  Maybe I should keep
        Duration as absolute, and use FMatra as an explicitly relative
        matra-level fractional duration.
        . The wrinkle is nadai as always.  How can I know what a matra should
          be after a nadai change if I don't know the surrounding nadai?
        . It doesn't help that realize knows absolute timing, because I put
          the value in in the score, where I don't know.  So the only way is
          that the duration unit is always relative to the current tempo.
          If I say it's N nadai at s0, then I think it works, but then I'm
          back to FMatra being nadai-independent.  I think?
        . Realize.split_at can know that the _dropped is relative to the
          tempo in scope.  So if it says 2, then we take it as matras and
          convert to Duration.
        . But currently it's matras/4, so should it still work out the same,
          just /4?
        . Wait, maybe the problem is entirely different.  Both flatten the same:
          . su $ dropM 1 taka:
            [(1/4, Front)(s+1(ta ka))]
            [(([2 (1/4, Front)], s1n4), ta), (([], s1n4), ka)]
          . dropM 1 $ su taka:
            [s+1((1/4, Front)(ta ka))]
            [(([2 (1/4, Front)], s1n4), ta), (([], s1n4), ka)]
        . This is because both TempoChange and Group are merged into
          Meta, and the order is lost.  I need to change the representation
          to fix this.
        . data Meta g a = TempoChange tempo | Group (GroupMark g) | Notes [a]
        . This would totally change all that MetaNote stuff, and maps would
          have to be mapAccumLs with state.  But since I can now see that
          the TempoChange happens before the Group, I know the right tempo
          when stripping out group prefix/suffix.  When I see Group, I scale
          _dropped by the current tempo.
        . One problem is that now the group counts don't work, because there
          are non-Notes in there.  I suppose I could make the count be for
          non-meta events.
        . Why wasn't this a problem before?  Because splitD used to work
          over the nested S.Note structure, so the order was still present.
        . Another way to fix this but preserve the pairs format is to have
          ([Meta], a), but it could have [] for no tempo, and I still lose
          order of notes with meta... so it doesn't really help.

        . This is still annoying because previous code could just pass through
          meta without caring about tempo or groups, but now it has to
          explicitly deal with groups.
        . What about making Group still be nested?  The reason to flatten
          notes is so they all have tempo, and I can easily find sequences.
          But that doesn't hold for groups, because I don't match sequences
          across group boundaries anyway.
        . realize_patterns changes the number of notes, which makes the group
          count inaccurate.  I have to update it.
        . Using a non-flat group means I wouldn't have worry about getting
          count wrong.
        . I feel like collect_group does adding dropped time wrong.  It seems
          like I should be able to do all the groups recursively.
        . matrasOf is 12, should be 8*3 - 2 - 4 = 18/2 = 9
        . It's because I don't take tempo into account when calculating
          dropped matras.

        * Implement Realize.format_table.
        * Clean out the Pretty etc. gunk and commented out code.
        * compile build/debug/seq, fix exports

      - Another side-effect is that "can't split" errors are only detected
        on realization.  But if it's important to get them earlier, I could
        have splitD verify even if it doesn't use the result immediately.

    - Various Notation functions like 'spread' should work with groups.
  - Ornaments to fill in karvai, e.g. with taka and takatiku
  - Mark for variations, e.g. mark a 'tri_ x 345' for 345.x.345.x.3333.
    end4 (tri_ x (p6, tk.p6, tknk.p6)) -> can play final as p6.p6.p6.p6
    . Variation markers put a branch in the realization, so now I have
      multiple realizations, and I need some way to not just enumerate
      them, but choose a certain path.
    . This is also part of the intensity pattern, where the final repeat
      may have an alternate more intense realization.
  - Different tags for patterns within a Korvai, e.g. for performance
    and exercise variants.
    . Also useful to mark the sections, e.g. development, and related
      sequences.  Ideally I could have separate stroke maps, but maybe
      that's overkill.
  - I should be able to add multiple realizations of the same
    instrument, keyed by string, e.g. for different mridangists
    realizations.
  - Duration assertions, e.g. matra 4 (ta.ka.din.na)
  pakhawaj:
    - integrate pakhawaj bols
      . I think I need "kre" support.
      . The other thing is tette infer.
    - Copy the stuff from Derive.C.India.PakhawajScore.
  reyong realization:
    - some way to select between melodic and rythmic realization, and
      transposition for melodic
      . This could be the same as the emphasis mechanism, if I extend
        it to attach Attributes.
      . Or if I have alternate StrokeMaps by name, then I can use that.
  - Emphasis or automatic variant versions of patterns, e.g.
    . kt_kno -> ki_kno.  k_t_kno -> i_i_kno, i _ i _ ktkto _,
      pu_ pu_ ktkto
    . The emphasis note can be i, or pu, or maybe u, or p+u (play like
      kre on pakhawaj).
  - Mridangam patterns can vary by intensity in addition to duration and
    family. How can I represent and realize that?  E.g. the final of
    a group of three can be higher intensity.
    . It can also be a variant pattern, e.g.
      k_kto k_k_kto k_t_k_kto -> repeat 4 k_kto
  * Notation {take,drop}M functions get matras via duration_of and
    divide, while matras_of counts matras directly.  I'm not totally
    sure what the difference is and which one is correct.
    . With division I can get matras even if nadai changes but it winds
      up being integral.  So nadai 4 -> 8 would be equivalent to a speed
      change, which is good.  But 4 -> 6 will also be valid matras if
      I have a multiple of 3.
    matrasOf:
      . ignore if there's a single top-level tempo change
        . so matrasOf (su (k.t)) => matrasOf (k.t)
        . This seems wrong?
      . Ignore nadai change.
      . Handle tempo change, but error if the result is non-integral.
      . 'sandi' and reduce reduceTo{L,R} use matrasOf.
    splitD:
      . Convert Matras to Duration by (*matra_duration), which is 1/4.
      . splitD keeps track of tempo, and errors if you try to split
        a non-rest.  Rests can be split arbitrarily, though.
    . The matra units are relative, so
      su (dropM 1 kt) == su t
    . They are independent of nadai, so
      nadai 6 (dropM 1 x) == dropM 1 (nadai 6 x)
    . On the other hand, dropM 2 (t . nadai 6 tkt) should be [].  So actually
      I think being an absolute time is more predictable, and more likely to
      be correct.  Especially for reductions, which all seem to work on
      absolute times.
    . I think I need matrasOf for things like sandi, but splitD needs to count
      because it needs to keep track.  So I have to make sure they use the
      same way of counting.
    . Also I should preserve that nadai *2 == speed +1, so that means use the
      duration, and don't ignore nadai.  So matrasOf needs to return
      a fractional matras.
      . How is this different from Duration then?  Is it valid to just (/4)?
        dropM 3 (ta . nadai 6 takita) => []
        1/4 + 3/6 = 3/4
      . I think this does work.
    . Also I think reduction is more likely to reduce a constant amount of
      time, so e.g. dropM 2 (n 3 takita) should drop all 3.
  - replacements, e.g. ta.ki.ta -> nang.__ . su (kita.taka)
    . use this in koraippu_janahan
  / I think I need an absolute SetSpeed, so I can pad a number of
    aksharas, regardless of the speed.
    . I also need it to rest by Duration, or to turn that into matras.
    . At the score level it's most convenient to work with sollu-matras.
      These are relative to nadai, but that's actually good.  With speed
      changes I can get fractional matras, and operations can actually
      work as long as the speeds line up and I don't have to drop
      half of a sollu.
    . However, for things like 'align', I need to know that tala and
      nadai, so I can emit a certain number of aksharas.
    . Actually since align is used at the top level, I can assume s0.
  - extend Karvai to take a minimum number of Rests before it applies.
    Default to 2, but a chapu might require 3.
  * Use a typeclass for format-conversion, instead of Pretty.
    . I use Pretty for format, which is awkward for Realize.Stroke, since
      I can tolerate some ambiguity for the same of a single letter width,
      but Pretty shouldn't have such a restriction.  Add Format class?
      But it still returns Text instead of Char since patterns have two
      characters.
    . I still need Pretty for error msgs, because I have Pretty [a].
  - This turns into a general way to represent unparsed expressions.
    . Text shouldn't have ShowVal, it should be Symbol, and then CallId
      should have a separate type, its ShowVal doesn't need quotes,
      unless there is a space.
    . Then Unparsed represents parseable text, so actually ShowVal
      should return that.  Is it worth having a separate type over using
      Text, though?
    . I should be able to parse Expr Unparsed without the intervening
      ShowVal by directly parsing the Unparsed vals.
  variation:
    - 345 x 345 x 345 can be transformed to 345 x 345 x 3333, or generally
      any arithmetic progression.
    . This is automatic derivation of variations.
      transformations:
        . karvai u u u -> u i u
        . X X X -> gap X, gap-1 kpX, gap-2 kpnpX
        . X X X -> gap X, gap-2 oktpX, gap-4 ktktoktpX
        . alternate realization for 3rd repeat: 345 345 3333
        . __3 -> __2.p or __2.o if o follows
        . variation for a phrase prefix, usually on its repeat:
          k_k -> kpk, or k_p -> kpt
        . stroke substitution in a transformation, e.g. reduce or expand:
          pk -> kk, e.g. k_kto, k_k_kto, k_t_k_kto.
      . If I can apply them as a postproc, then I can get even random
        variations.
      . Or maybe I should write them explicitly, but make them easier to
        write?
    - Higher level variation, e.g. 666 666 666 -> 555 666 777 or even
      777 777 777 -> 567 876 789.  Actually the latter seems not so
      interesting.
    - Repeat oriented variation, e.g. 3 5 33 5 333 -> 333 5 33 5 3
  - Implement PatternFamilies so I can have 6 8 6 7 6 5, or even just
    distinct realizations within a single korvai.
  - Should I change mridangam notes to be consistent with Solkattu.Dsl?
    I have to put thoppi on the left, for 'od' instead of the keyword
    'do'.  And I have to change tha to p instead of +.
  . Conditional derivation that depends on position in the tala, e.g.
    thali / khali.
  alternate realization
    - kendang pasangan
    - kajar
    - gangsa
  ? Crazy idea: it might be nice to use underline or double underline
    for faster.  Is there a way I could get the editor to display
    special brackets as underline, and then turn those special brackets
    into a 'faster' call?  I think if I'm doing this, I definitely need
    a preprocessor, though if I keep basic haskell syntax and define it
    as a translation to haskell, then I can keep all the usual features.
    . Alternately, use syntax highlighting.  Sufficiently fancy
      highlighting could highlight 'faster (...)'.  I don't think ascii
      can do double underlines, though it could do italic+underline or
      something.
    . I could also try to automatically align by time.  I imagine
      a sufficiently advanced vim macro could do that, e.g. bind ^tab to
      annotate the current expression with line info, evaluate it, and
      align the current line, or try to move the cursor to the next
      beat.  Maybe not worth it though, since the whole idea of the dsl
      is that time can be abstract.

Cmd:
  Repl:
    - LNote.sort_on_pitch is still not right.
      . With multiple chords I get stacked up extra tracks.
      . Turns out this seems really complicated.  Do I really care that much?
  - Paste between blocks with different track layout is awkward.  Can I have
    a note-oriented paste that reuses or creates the track structure?
  - ModifyNotes doesn't seem to understand about parent note tracks.
  - Interpret a midi file with keyswitches back to the attrs.
    . This is so I can load VSL examples and learn from them.
    . Should it be a score transformation, or start from the parsed MIDI?
    . MIDI seems easier because it's already in a linear format, while for
      the score I'd have to interpret it into one.
    . But then I need to pass the instrument mapping to Midi.load.
    . Maybe not really worth it?  For learning I can load in reaper and just
      watch the VSL UI.
    . But still worth keeping existing work, because I'll need something like
      that for MIDI record.
  - Figure out exactly what bad things could happen because of the
    Ui.fltk_event_loop race.  Also figure out what kind of cancelling I'd need
    to fix them.
  + Write a fancy tile like ViewConfig.horizontal_tile but guesses if you mean
    to tile vertically.
  - Create tempo by "stretching", i.e. select start and end, and create tempo
    mark that will cause the start point to be played where the end point used
    to be played.
  - give Cmd.ModifyEvents.Track the ability to change the track title?
    Cmd.Repl.LPitch.change_scale and to_relative could use this.
  meter / timestep
    - timestep 64*2 skips two 's', because 's' is the minimum match
      skip should be ignored when the match is a larger rank than exists, or
      maybe step should fail.

  ruler:
    - meter type and the construction functions should be integrated more
      tightly
    - LRuler.inject, opposite of extract, replaces sub-block rulers
  Cmd.Edit
    - Make Edit.cmd_invert_orientation set orientation based on the first
      selected event, so I can easily set all to the same.
    - alternate finale-like note entry: hold down step key to set step and
      turn on edit mode, but only while the key is down
      (merge will clip them to the next event)
  copy / paste / Clip
    - clip block should use the ruler, just to make it easier to look at
    - clip could also copy over the skeleton
      It could use it to make sure the paste is compatible, but that might
      be more of an annoyance than a convenience.

  Undo:
    * shift [ and ] undo and redo zooms.  or one key to toggle last zoom?
      . record view changes, at least zoom / scroll so it can be undone
        and redone separately
    - Suppressed undo for val edit is surprising since I tend to do a lot of
      edits without leaving val edit.  Maybe don't do it for pitch val edit.
      Try going back to using the name to suppress, but ignore cmds with no
      name.
    - Add a "revert within selection" that searches backward for the last
      change within the selection.
    - Along those lines, should each block have its own independent history?
      This is supported naturally by the git layout since each block has its own
      file.  Wait, actually it's track, and that would be awkward if I undo one
      block and it changes tracks on another.  How do a say what position
      a block is in the history in that case?
      . One appealing thing is that I don't necessarily want things like config
        changes to be included in undo.
    - Visual display of undo history, because stepping back one-by-one is
      a bit of a hassle.

Derive:
  - A block with logical range called at time 0 gets messed up.
  - signal-offset: Add time offset to TimeVector
    . event_transformed_controls etc. are really annoying.  I can get rid of
      them by building the translation into Perform.Signal.
    . The downside is that every signal gets an offset, even though it's
      just for Score.Event ones, and their offset is all the same.  But still,
      what's another Double in signal full of them?
    . However, Warps also have it, so I could take that field out of the Warp.
    . I'd want to add an X offset to TimeVector.Boxed and Unboxed, but those
      are type aliases so they work with the Vector.Generic functions.
      So how can I resue Vector.Generic?
    . Presumably I could put my new types in the Generic.Vector class too, but
      that might actually be wrong since then they would ignore the offset.
      So maybe I just stop directly using the generic functions.
    . I also want to consider that I may want to have a TimeVector Val to
      replace the Environ.  So it would be nice to eliminate the duplication
      between PSignal and Signal.  Presumably I could do that by putting them
      in a 'class ToVector a where to_vector :: a -> TimeVector.Offset ?',
      then I can either re-export the shared ones directly, or specialize the
      type.
    . I could make an Offset wrapper and have all the TimeVector functions
      apply the offset.  But it seems like a lot of work for what is really
      just a way to fuse multiple translations for just Score.Events.  It's
      only worth it if I do multiple translations before unpacking.
    . I could put just the event controls into Offset, and require a translate
      to get the control out.  This would be like event_untransformed_controls
      except put it in the type.
  idiom
    - In string-idiom, the end of the attack curve always coincides with the
      start of the next note.  There also could be an attack prepare time,
      analogous to the release delay.
  sekaran
    How to apply sekaran?
      . >hang -> sekar abab -> notes
      . I want to change the pattern, so the problem is how to set an env
        var for a range on one track?
      . I can add a 'sekar-pattern = abc', but I need to repeat it whenever
        there is a gap.
  fancier randomization
    . How much a note differs depends on its neighbors, so it's not an even
      distribution.  Use brownian noise, or a fractal subdivision scheme.  But
      it's also constrained in how far it can wander from the base value.
      Regardless, I think this means I need history, so it can't be
      a stateless control function.
    . Divide on instrument and hand, so each part gets its own individuality.
    - randomization should be centered on a value, with variance as a signal,
      so I can turn accuracy up or down.
    - Randomness could have some hysteresis, so I can e.g. reduce omit chance,
      but not get isolated notes.  At the extreme setting, it means it turns
      on in a slightly random spot, but stays on after that.
      . Is there a simpler way to get this effect?
  tracklang: TrackLang:
    - Keyword args.
      . A problem with environ defaulted args is that if I do e.g.
        'merge=add | a=b | block', then all of 'block' will have merge=add.
        There's no way to set it just for 'a=b'.  So they're not necessarily
        a great substitute for keyword args.  Also keyword args should
        complain if you give one it doesn't understand.
      . I think a=b syntax is available, but do I want to make a Val out of it?
        It would be resolved by Derive.Sig, and not actually make it to calls,
        but Quoted is like that too.
      . And realistically it seems really invasive to support a=b if it's not
        a Val.  But I wind up with weird things like a=b=c.
    generalize sub-event calls
      - Generalize sub-event calls so that they can also take block names.  This
        is just another way to write sub-tracks, perhaps more convenient if
        I want them to be independent.
      - Also generalize them so if I put it as a transformer in a track title,
        the track is treated like a sub-event call.  This way I can apply a
        transformation to the whole track without needing to wrap it with an
        event.  Paired with the Sub.modify_notes macro feature, I can have
        a track with its own little language, e.g. pakhawaj bols.
        . Could do this by making 'ctx_sub_tracks' available in the track title
          call.
        . I think there were calls in Prelude.Lily that would be interested in
          a more defined distinction between track and note level transformers.
      - Could also do a block-level thing.
    - Perhaps I should have a separation between "" as called by Util.note by
      other calls, and "" as called from the track.  The problem is that it
      applies Flags.can_cancel at TrackTime 0, which is only appropriate for
      a direct call from the track.  This is the reason for
      Gangsa.realize_notes.remove.
      . Flags.can_cancel is now obsolete, but maybe the issue still stands?
    - I was confused because I wrote '%just-base = (nn (c3))' instead of
      '%just-base = (hz (nn c3))'.  Can I use type tags to catch that sort of
      thing?
      . Hz doesn't have its own type, so it winds up being Untyped.  But any
        type can coerce to Untyped, so it can't complain if you passed NN.
        I could make Typecheck Double require Untyped, but that would break all
        the stuff that doesn't care about types.
      . Ultimately, this is because pitches take a PitchConfig, which takes
        ControlValMap, which is untyped.  I started a branch making it typed,
        but eventually lost interest since it seemed overly complicated.
    - Rethink if I really want track event calls in TrackTime, rather than
      normalized time.
      . Implementing c_sequence I was confused how stretch was applied twice,
        since Eval.eval_quoted doesn't normalize the event duration.  Same
        problem is in Gamakam2.  It's error prone that you can place the note
        via both Derive.place and via the Derive.info_event.
      . On the other hand, working in TrackTime is convenient, e.g. in gangsa
        norot I can place notes based on the passed-in dur.  If it were
        normalized, I'd have to unwarp back to TrackTime... can I even do that?
      . Details are also in "Derive.EvalTrack".
      . Adding the repeat call was unintuitive because deriver placement is
        unintuitive.
        . Ideally I could just say (0, 2), (2, 2) and it would work.
          Instead, I get (0, 8) and (2, 8)
          This is because the block isn't normalized, so stretch by 2 makes it
          4, then the stretch by 2 for the event goes to 8.
        . This is so that just 'deriver' by itself gets it right.  If I instead
          made deriver always normalized, then the above would work, but
          I would have to do 'Derive.place (Args.start args) (Args.duration
          args) deriver' to avoid it always showing up at 0-1.  And actually,
          I couldn't do that from a transformer, because what about the next
          transformer?  I should instead have each transformer be in
          normalized time.  'repeat' becomes
            [Derive.place start (1/times) | start <- Seq.range_ 0 (1/times)]
        . For blocks, it's actually almost that, except I have to translate
          back by the start time first.  This is because blocks are already
          normalized to the event duration.  I think?
    Typecheck coerces to TypedFunction as a common signal type
      - It turns out this is not so useful because a default TypedFunction
        doesn't have a default control name like a Sig.typed_control does.
        The documentation is also worse.  The way to fix this would be to
        let the default be any coercible type.  But to do that and be type safe
        I'd want a separate class for pairs of types that can definitely be
        converted.
        . Possibly a way around is to include ControlFunction in ControlRef...
          but why do I want so much to pass control functions?  Especially since
          I can already pass a concrete signal as a ControlSignal.
    . It would be nice to be able to have an arg default to ControlRef and
      have typecheck coerce to scalar via Call.control_at.  But once again the
      problem is that I can't coerce to a type different from the default.
    - if I had a boolean type, I could generalize calls in Conditional:
      . when-e key -> when (env key)
        when-e key val -> when (= (env key) val)
      . when-c 1 cont -> when (= %cont 1)
      . if-c< cont 1 a b -> cond (< %cont 1) a b
      . However, they get more wordy, so maybe I don't want it.  E.g. for
        cond I'd actually want a 'switch %cont' and then I need either
        partially applied functions, or just write 'switch<'.
    - replace VAttributes with a general purpose VSet.
      . No users though?
    - there should be a character that triggers a parse failure, which is used
      by invalid ShowVal instances like ShowVal Pitch
    - it's confusing how some calls expect env vals like 'x = 1' and some
      expect controls like '%x = 1'.
      . The obvious way to solve this would be to merge env vals and controls,
        but that's a big change.
    - Track caching is too fragile, if I add a track with scope over everything
      then I get no caching.  Instead I should cache the bottom note track, or
      perhaps every note track.  But that doesn't work because they're all
      sliced up.
  Derive.Sig:
    - Support pairs, e.g. a list of pairs of arguments.
      . many_pairs :: (Typecheck a, Typecheck b) => Text -> Parser [(a, b)]
      . Can I generalize to triplets etc. without a separate function for
        each?  Also, could I reuse many / many1?
      . Can I have a Typecheck instance for (,)?  No, becaues it comes from
        a single Val.
      . I would have to turn Sig into a real parser.
    - Try writing a new Typecheck / Sig which is a real parser.  It can have
      backtracking and nested parsers.
    - if I add an Alternative instance to Sig.Parser I can write arg parsers
      like 'Sig.many xs <|> Sig.many ys'.  I think.  If I wind up with something
      else like Derive.Call.Val.num_or_pitch it would be worth trying out.
      . E.g. Conditional.c_if_c takes: Symbol (Number, Quoted)* Quoted
      . Implement empty as pure (), then (<|>) should try left and if it fails,
        try right.  Doc is (x | y).  'some' and 'many' are like Sig.many1 and
        Sig.many, except they have to backtrack.
      . But derivation may evaluate expressions and check the type after that.
        Do I really want to do that with backtracking?
  postproc
    performance details / humanization
      - irregularize runs based on fingering patterns, e.g. groups of 3
    - retune a note depending on the previous interval (e.g. sloppy pitches
      when playing quickly)

  tempo track:
    - Nested tempo tracks at the toplevel block should normalize like they do
      when called.
    - Nested tempo tracks are probably broken for hybrid and absolute tempo.
    - Nested tempo tracks are probably also broken with a logical start.
  note calls:
    - retune call: differences based on speed should be more obvious, so that
      should also be on a curve.
    + chord calls, with automatic dyns for the notes.
      Originally I intended each note to go in its own track, with the idea
      that it takes about the same space but is more powerful and flexible.
      But it's not quite true, because the extra track is there for the whole
      block, though perhaps that's a side-effect of having blocks which are
      too large.  More compellingly, chords can automatically fiddle with dyn
      and start time, and can also interpret chord symbols.
    mridangam:
      - Automatic inference for Ki vs. Mi, e.g. in sarvalaghu.  E.g.
        dxd -> dld, but dxpx -> dkpk.  Also it can change based on speed and
        emphasis.
      - connect kendang, reyong, etc. to 'tir' and 'seq' calls.
      - make india.mridangam seq call align to the end for -0 dur
      . It would be nice to alternate mridangam and kendang tirmanam, e.g.:
        mridangam, kendang, both.  But I'd need to either write the tirmanam
        in solkattu dsl and give it a name, or have a mini solkattu dsl, e.g.
        with syllable breaking:
        . tri-mk 'kitakitataka nakadit_ talang_ talang_ ta' lang_
      . I'd have to have a standard stroke map, but I'm not sure how well that
        would work in practice.
      . reyong: takadinna -> cccc, nakadit -> i12, talang -> +O
        . c = cek, k = kempyung, 0123 -> relative scale degree, .+ -> byut,
          oO -> byong
        . I could also have shift up, shift down annotations, like speed or
          nadai.
      - Perhaps mridangam should automatically transpose the octave to be within
        its range.
        . I can use something like Cmd.Instrument.Bali.wrap
      - tha is too loud... I can compensate by using -, but maybe the scale is
        off.  Velocity should be logical, so if you play all at the same
        velocity it's like the same dynamic for all strokes.
        . Or I could make + be 0.5, and * be full volume.
      sarvalaghu
        - get them from Score or MridangamScore.
        - adjust to the talam
        - subdivide at slower speeds
    pakhawaj bols
      . Score integrate to convert bols to low level calls
        . Actually score integrate doesn't work like that, it just copies the
          input.  It would have to be derive integration.
      . Or maybe just interpret the bols directly, but due to context
        sensitivity they need to be all processed together, not as separate
        calls.
        . In general I don't have a way to interpret a track as a whole.  This
          is the "track call" thing I was thinking about a long time ago.
      - Add an input mode for bols.
    bali:
      - kajar: automatic hand muting as with reyong.
      + add additional legong and wayang tunings.  Probably 'tuning' would be
        the most appropriate, but it's already using for umbang/isep.  Maybe
        saih=umbang/isep?  Or keep tuning the same and use laras?  Kelamin
        would be cheeky but only appropriate to kendang and not even Balinese.
      legong scale:
        - add isep to *legong
        - pick better nns for pemero notes 4 and 7
        - dotted cipher notation should use 4 and 7 instead of 3# and 6#.
      kotekan: gangsa:
        - >gangsa instrument, which is pemade + kantilan
          . It can be a alias of `multiple`:
            gangsa = multiple "(inst=pemade) "(%t-oct=1 | inst=kantilan)
        - nyog polos first can be inferred based on whether it's a major ruler
          division.  But should I?  I can just write 's+' to be explicit.
        - Simplify reyong norot in the same way as gangsa norot.  I also
          want to add the prepare_start feature.
          - Can I remove Once now?
        Kotekan kernel notation can be hard to use:
          . The kotekan call can be hard to use for irregular sections like:
            . |       |       |
               3-23-3-23-23-23-5
              2-12-2-12-12-1234-34-4-3
              |       |       |
              -3-23-3-23-23-21-
              2-12-2-12-12-1-10
              |
            . 4-3-4-3-44
              12-212-211
          . Maybe just a literal "once" kotekan call?
            Start at 0.
          . Maybe it's not "once" but "normal alignment", so maybe I can unify
            this with orientation.  But I think I need an explicit Positive
            orientation call like 'ko', rather than using event orientation.
          . For end orientation I still want to align to the end, but can I
            do that just by rotating the kernel?
          . I could say rotate or not based on the leading 'k'.
            (1)-12-1-21
          . Actually, maybe rotation isn't the problem.  Instead I have places
            where the inference rules don't work because the pitch is moving:
                 3-23-21
              (2)-12-1-10
            . Can I infer?  (2)-12-1-10  -> ... not sure
            . Or write both? ke '-12-1-10' '3-23-21-'
            . I can, but it still takes longer than just writing it out.  And
              if it's not pitch-independent, there's not much benefit to the
              specialized kotekan notation.
        - k '-21-21-21-21-12-' infers with 1 below the pitch.  It should be
          . 43-43-43-43-434- 3-43-43-43-434-3
            1-21-21-21-21-12 -12-12-12-12-1-21

                            56-56-56-56-565-2
            2-32-32-32-32-23 23-23-23-23-2-32
          . Write as:
             -21-21-21-21-12- 12-12-12-12-1-21
          . Maybe it would be more predictable to say that 1 is always the
            pitch.  Then I can know if sangsih is above or below by looking at
            pitches.
            . 2-32-32-32-3232- 32-32-32-32-323-
              21-21-21-21-2-21 6-16-16-16-16-612
          . I can get it work, but it takes a lot of thinking.
        - Maybe have a character extend previous note.
        - Another option is to write the polos notes directly, and then
          a parent call that infers sangsih.  This avoids the problem where
          I have to figure out how many little numbers.
          . But if I'm going to do that, why not just use +p, +s, and +k to
            write the whole thing explicitly?
          . Well, that's quite a bit more fiddly.
        - in norot -> nyog transition, the last norot note cancels the first
          nyog note.
          . sangsih 6i cancels out the explicit 5e
          . Since {final} cancels normal notes, this is working as intended, and
            I can fix with final=f or 'strong', but it's surprising.  Maybe
            I should only have a final for negative events?
        - make gangsa and reyong norot and noltol dispatch to 'm' instead of
          directly applying +mute.  Or should I have a call for a weak note, and
          leave 'm' for an explicitly muted note?
        - gangsa zero dur mutes too loud
          . Really I need loose and tight mute, but I'll have to do my own
            samples, or maybe add a loose mute as open with just envelope.
        - noltol puts a mute stroke after a final note.
          . It's becasue it has a lower threshold, but not an upper one.
            But really it's not the threshold, but the form, noltol should be
            during kotekan.  So maybe I should really build this into kotekan
            calls.
        - clip should be end-weighted.  If I used a negative duration I could
          make it based on that...
          . Wait, isn't that what Clip is?
        - generate all possible kernels following some playability rules,
          e.g. no more than 2 notes in a row, only one rest
          . I could then use that to automatically select a pattern for
            a given destination, with some constraints like playability from
            the previous pattern (no fast jumps), above vs. below, telu vs.
            empat.
          . Then do that to make a random kotekan for ngubeng and majalan.
        - in Gangsa.realize_kotekan_pattern, pass Nothing as the start to not
          limit the start
        - inst postproc can interpret +mute as either just a mute, or open, or
          in between depending on %mute.
          . Then I don't need a configurable mute for
            Gangsa.gangsa_norot_arrival.
          . Reapply the 'm' call instead, and override that as appropriate.
        - an optional special pattern which switching between kotekan and back,
          e.g. 112-2-2-
      wayang in octaves
        . pemade: >p=>p-umbang | >s=>p-isep
          kantilan: >p=>k-umbang | >s=>k-isep | %t-diatonic=5
        . I could do it with >wayang-both that emits >wayang-p and >wayang-k. Or
          just call the score twice, once with transpose +1 oct.
        . I definitely want two calls because then kantilan randomizes
          differently.
        . Or I could create the kantilan as a integration of the pemade, so it
          can still be modified. I think this would want a "score integration"
          which just copies and merges the events directly, and doesn't do
          the intermediate derivation.
        . I could add inst aliases, e.g. >umbang = >p-umbang, etc.
          Or a note-track call: '>umbang = "(>p-umbang)'
          This can't be done with call aliasing because it's actually
          'note-title >inst', and anyway wouldn't help with 'inst = >x'.
        . The intended way to do this is have > instrument, and then set it in
          the caller.  But then you can't put >1 inst on the same block.
        . But this way doesn't work if I want differences in the kantilan
          version.  I would have to do correspondingly more copy and paste to
          replace the bit I want to change.
        . Ideally I'd like something like integration: everything is
          duplicated with no extra work, but an integration is available to
          edit.  But it would be a kind of "deep integration", where
          I duplicate the entire structure, from score on down.  Score
          integration could theoretically do that.
      trompong:
        - octaves shouldn't be able to infer damping
          . E.g. (6e 6o 6o, 5e - 5o)
        - I need a better way to notate a section as lower octave.
          . vv doesn't work is a note parent.
          . This is similar to octaves notation for gender rambat.
        - split to ngembat
          . There are several ngembat variations:
            . fast:
              5 61    35 61
                 1        1
            . slow:
              561   53561
               21      21
        - double note, like oo in kajar
          . tabuh-gari, @b4 2.5t
      reyong:
        - Damp level is way too high, I have to put %damp=.2 everywhere.
        - remove kilit, isn't it just norot now?
        - for infer-damp, also infer damp level
          . Damp gets louder when notes are closer, or faster.
          . Also longer note is a quieter damp, or just say if the length is
            over a threshold don't damp at all.
        - How to configure open and closed damping?  I can currently do it
          by adding +open, but that might be too broad because it also applies
          to +cek.  Or I could always damp closed if that sounds good.
          Or I could infer it based on speed.  Otherwise, I can change the
          attr to +loose-mute or +tight-mute to explicitly configure.
        - kbd entry for /, X, O, + etc.?
        kilitan: norot:
          . How to do norot for real?
            . Each voice is semi-independent, and may have different
              preparation patterns and times.  But then sometimes they
              coordinate.
            . Variations are random, but frequency is controlled by
              "kewayahan".
          variants:
            - controlled by variant control
            - omit notes
            - hardcoded variants, e.g. p1 on dong
            - Delayed note, e.g. on ding, oiioioi
            - Pickup can be iioi style, but parts that don't have the pitch
              often play the normal kilitan, or a passing tone.
          above speed threshold:
            - omit notes
            - Entirely different fast patterns.
          - Also I want to be able to control the dyn.  There should be
            a single control for +mute dyn.  Actually I already have that
            if I multiply %damp, right?  Still, explicit +mute notes and
            kilitan +mute notes are stronger than damping, so I need two
            I think.  Damping should default to a fraction of +mute dyn.
          - write an alternate style of kilitan, e.g. with a 6 note scale in
            tisram
        kotekan
          - reyong-voices doesn't seem to affect 'k' 'k//' and 'k\\', but does
            k_\ and k//\\ (and shouldn't the last be k/\ for consistency with
            gangsa?).
          - support high dung for position 4
      gender:
        - rambat damping emulation: notes ring on by default until they can be
          damped.  Damp at the first opportunity, where opportunity is defined
          as a break with no notes for a certain amount of time.  Can only damp
          two neighboring notes at a time.
  india: gamakam:
    - It doesn't emit signal discontinuities correctly.
    . Get rid of gamakam1-4:
      - Remove gamakam4.
      Save what I want from 1-3 and remove.
        - gamakam1:
          . kampita and nkampita implementations
        - gamakam2:
          . use @ begin; middle;* end
          . middle can be kam, to get multiple oscillations + lilt as
            appropriate
          . It has a separate implementation of kampita, which might be more
            modern.  Also I still like the idea of a stretchy middle section,
            and I think I'll need something like that to write higher-level
            gamakam.
      - Remove ; syntax when gamakam2 is gone.
    - How to represent sangitas?
      . Also what about accumulating phrases, as in kuvalaya dala or mosaboku?
      . Maybe define a time range, then an edit in that time range will cause
        a score derive to be appended to the end of the range.  Since the
        "repeat" mark is also included, as soon as you edit the next section,
        it appends another one, unless you delete the repeat mark.  Editing
        a section will cause integrates down the line.
      . This would be a new kind of score derive that integrates into the
        same block and tracks, just at a time offset.  I could do the same
        thing with blocks, and maybe I should to avoid the additional
        complexity of a new "within track" integrate.
    - Bowing ornamonts.
      . gradual attack, and "puff" attack, ...?
    - I think Gamakam4 doesn't test next event pitch, e.g.
      Gamakam3_test.test_sequence on '!!-v-'
    dyn:
      - I think T is messed up, it seems to not know it's 0 dur.
      - Add support for '_' and, why not, '.'.
    - '.' call on the note messes up gamakam
    - 'v' for next pitch is wrong when the next pitch isn't on a note start
    - There still seems to be a case where prev pitch is wrong, it has to
      do with a '--' event.
    - And another prev pitch bug:
      [ (">", [(0, 3, ""), (3, 1, "")])
      , ("*", [(0, 0, "2d"), (1, 0, "3s"), (2, 0, "3r"), (4, 0, "3s")])
      , ("*", [(0, 0, "!^20"), (1, 0, "!0="), (4, 0, "!=")])
      ]
      . Last note should get 3r, but instead gets 3s.
    . For the violin, I want to experiment with other controls, e.g. pitch
      slides also do less bow-force, or dyn can reduce bow-force and
      bow-speed.

    - overshoot "curve" for 'smooth': over2 over3, depending how far over
    . instead of hardcoding specific times, I should say short, medium, long,
      which can vary and have some randomization:
      . short, medium, long: -s = "(rnd low high) | -m = .. | -l = ..

  control calls:
    - signal transformations: +, *, max, min
    - saturation limit, e.g. flatten sine wave but without clipping
    - continuous tempo warping for signals
      tempo: "2" -> "1", "2", cont: "2" -> "i, 1", should emit a bent line

  control functions:
    I'm unhappy with control functions in general - NOTE [fix-control-functions]
      . More details in BaseTypes NOTE [control-function]
      . They duplicate Deriver but can't use it
      . they add another layer on top of controls that you have to take into
        account manually.
      . Also, depending on the pos means the signal is no longer a continuous
        function, and can't be displayed as a line.
      . Making calls all take Call.Function was my attempt to abstract that
        away, but I wound up giving up on that because then the default of an
        optional arg would have to be a Function which is then unshowable.
        To solve this I would have to make a total 'coerce' for Typecheck.
      uses:
        . Randomization, with various ranges and distributions.
        . Some CFs like cf-swing could just be another signal, I only do it as
          a function for efficiency, which is due to my choice to make signals
          fully sampled.
        . A way to pass an interpolation function.  This is a disjoint use
          since it doesn't need any of the BaseTypes.Dynamic state and isn't
          useful as a normal CF.
    - Could use rank to modify dyn and emphasize or de-emphasize notes on
      important beats.
    . With 'real' and 'score' and the signal conversion functions, I gradually
      rewrite more and more functions from Deriver to functions with a
      TrackLang.Dynamic argument.  Also they're going to start to want an
      exception, and why not logging too, and I'm right back to Deriver.
    . Why can't I make ControlFunction into a Deriver?
      ControlFunction moves to Deriver.Monad, so Val must also.
      Now control function stuff must be exported from Deriver, not TrackLang
      and Score.  But also Val can't be exported from TrackLang, and there are
      tons of users for TrackLang.Val.  Maybe I can split TrackLang into a low
      level version.  In fact I already have, everything Deriver uses
      TrackLang for can come from BaseTypes, except Typecheck.  Monad.val_call
      must move to Lib.
      . Environ, Pitch, and Val all move into Derive.  And Score.Event.
        This is getting to be pretty much everything.
      . Another option is to make Derivers polymorphic.  I can put the
        fields in TrackLang.Dynamic in a typeclass.

pitch: scales: scale:
  - twelve-k doesn't work entirely correctly.
    . The problem is that ChromaticScales.pitch_note doesn't preserve an
      explicit natural, so it gets lost after a pitch->note.  I think
      show_pitch has to have twelve-k support.
    . I don't care enough about twelve-k to fix this now, but maybe some day.
  scales / Derive.Scale:
    - I think the symbolic pitch_note functions should use RelativePitch,
      otherwise the symbolic pitch they produce can't be parsed back in to
      produce the same pitch.
      . Demonstrate with some tests and fix if necessary.
      . For ChromaticScales and JustScales
    - TheoryFormat.make_relative_format is a confusing name because it makes
      a Format from a RelativeFormat.
    - It's confusing how the default_key is built-in to parse_key but also
      passed separately... maybe it should take a flag to say whether an error
      should become the default?
    - Strip type prefixes from Pitch.Pitch and Pitch.Degree?  Add lenses?
    - add ratio transpose signal, that multiplies hz
    support scales that are different ascending vs. descending
      . Scales have two versions of each degree.
      . scale_input_to_note takes a previous Note arg, which it can use to
        guess the appropriate variant.
      . Variants have to have unambiguous names though, maybe 4n^ and 4n_
      . Use scale_alternate to switch a note between alternates, bind to the
        same key as enharmonic.  If there are no enharmonics, then fall back
        on alternate.
    raga: ragam:
      - arohana / avarohana:
        . Select which depending on an env var, and have a postproc to go
          through and assign those.
        . Try octatonic with 21 ascending, and 12 descending.
        - I also want a cmd to cycle unspecified and explicitly arohana or
          avarohana.  I can bind it to the flip-enharmonic key unless I want
          to have scales with both concepts.
        old notes:
          . I could keep it at the Cmd level by remembering the last entered
            pitch and defaulting this one based on it, or I could try to put it
            at the Derive level too by having the pitch itself be based on the
            previous one.
          . Putting it at the derive level seems really hard and unreliable, so
            I should have separate symbols, e.g. 4r^ and 4r_ for up and down
            variants.  For western modes this isn't necessary since the notation
            is already absolute.
          . Or I can model r1 r2 r3 as accidentals.  The raga gives the default,
            and then I can change the cycle enharmonics binding to instead cycle
            number of "accidentals" to force a particular one.
          . So I would model as a chromatic scale but with a custom number of
            accidentals per degree:
              s, r1 r2 r3, g1 g2 g3, m1 m2, p, d1 d2 d3, n1 n2 n3
          . How should ragams look anyway?
            . Absolute chromatic scale with all pitches, and g[123] notation to
              explicitly choose one.  Arohana and avarohana show how to infer
              given plain g.  If >1 exist, then try to infer based on the
              previous pitch.  Also g^ and g_ chooses between 2, if applicable.
            . I need inference for gamakam, but I'll need an override, maybe
              ^_ postfix for numbers?

    - letter and jianpu but with implicit accidentals based on the key
  intonation: think about how to do e.g. meantone melody, with just harmony
    . Do a postproc to analyze simultaneous notes.  If I use an attr to
      tag the melody, I can tune everyone else to it.  But how do I retune
      notes with non-trivial pitch curves?  Well, I could use a transpose
      signal to tell the pitch calls what's going on.  I think I might just
      need the frequency of the melody note.
    . Do an analysis pass, and insert environment that says what the harmony
      is.  Then pitch calls use that to tune.  Doing the analysis might be
      tricky since I have to extract a "principle pitch" from each event,
      but it might be useful in general to have an analysis framework.

Perform:
  - Overlapping notes with different ControlSwitch cc numbers should share
    a channel.  Of course it'll work anyway if only one channel is
    allocated.
    . Currently they definitely won't, because the performer assumes that
      all controls affect the sound, and so you can't share with any control.
  - Pick the best channel instead of the first one.
    . An event can share a channel if it has different controls but the events
      don't overlap.  This is required so that a sequence of notes that each
      set a different control will go on the same channel.  But since it always
      picks the first usable channel, you can have controls trade channels,
      depending on how the coincident events are sorted:
        [(0, 1, c1), (0, 1, c2), (1, 1, c2), (1, 1, c1)]
      This should put the c1s together, but they will trade channels if they
      come in that order.
    . I think to fix this I'd have to have can_share_chan return
      Left fail_reason or Right priority, and pick the highest priority.
      It would have to give a lower priority to events that could share, but
      have incompatible controls just out of the event range.
    . let f = Perform.shareable_chan
      let mkevent start controls pitch =
              Perform.Event inst1 start 0.33 controls
                  (Signal.signal [(0, pitch)]) DeriveTest.fake_stack
      let pedal = Map.fromList [("pedal", Signal.signal [(0, 1), (6, 0)])]
      pprint (f [(mkevent 3.33 pedal 45, 0)] (mkevent 3.66 mempty 72))

  - I can work around the pianoteq tuning bug by not stripping redundant
    conrol changes.  This also means that recorded MIDI can be played from any
    point.  If bandwidth isn't a concern then why not?
  - damper pedal causes all notes to extend until the pedal comes up, should
    the performer know about that?  Is there anything that this breaks?
    I don't think so, it affects channel allotment so notes could be
    improperly joined, but mixing pedal and multiplexing seems rare enough.
  - Perform.Midi.Perform: should be possible to lead keyswitches as long as
    they don't precede the previous NoteOn, since I think samplers will only
    switch on the next NoteOn
  Instrument
    - some basic midi instrument defs for generic midi (dev, patch)

Util.Format:
  HsPretty:
    problems:
      . Missing close paren after wrapped constructors.
      . If I add an indent after each constructor then I get tons of indents.
        What I really want is a way to collapse multiple constructor calls
        with a single argument.
      . For some reason it's not wrapping tuples properly, they become
          (a, B
            c
          )
        instead of
          ( a
          , B c
          )
  - Util.Pretty still broken: pprint Vsl.violin_harmonics
  - move format related modules to Util.Format.*
  - don't use 'reverse' in 'flatten'
  - lazy implementation?

Instrument DB / browser:
  - Fl_Help_View supports limited HTML, use it to display formatted text
  - browser has lots of empty space on the bottom
  - z1/virus-bass has UnknownMessage for initialization?
  - patch files could go in the Local/Instrument dir with the source?
    at least it should go in source control
  - colorize the info_pane so tags are easier to read
  - search lang supports quotes
  sysex
    z1
      - convert patches to larger pitch bend and send them back
      - I need control over which program and bank the patches go when they
        are initialized.  I can use the card as scratch space.
      - I also need to initialize a new multiset, and give the score
        a multiset config, or derive one from the midi config.
    vl1
      - test sending sysexes back
      - move patches to new format
      - figure out how to set category for builtin patches
        . *word shorthand for category=word?
        but I want to use the inst name, not the score name...

OSC backend
  in doc/dev_notes/sythesizer
  - Write a simple supercollider instrument and try controlling that with OSC.
  - Even if reaktor and supercollider don't understand bundles, I could write
    a scheduler server that takes bundles and emits their msgs at the correct
    time.

jack: JACK: linux midi:
  bugs
    - something is still wrong, I get "no space in output port" and then
      corrupted output
    ? jack1 doesn't work at all: other clients don't see writes, until I quit,
      and then they get continuously spammed.  Apparently the jack_port_t*
      from the registration and the lookup are different.
      - Try stashing port from port_by_name port instead of jack_register_port.
  - does jack not support sysex at all?  Maybe I can't use it at all then.
  - Ensure that shutdown stuff is being called correctly.  I don't care but
    maybe JACK does?
  use jack transport
    I don't think I need to be the master.
    - When starting a play, call jack_transport_locate,
      then jack_transport_start().  The play then blocks on a lock which is
      released by JackSyncCallback when it gets a JackRolling state.
    - Register with jack_set_sync_callback.  JackSyncCallback sets a syncing
      flag, emits a Msg that forces the needed bits of performance, then that
      cmd must call back and reset the flag, at which point the sync function
      can return true.
    Then the next step is to test, and then figure out a way to get ardour to
    automatically set up a bunch of instruments and make MIDI in ports for
    them.

misc ideas:
  . What would a generalized staged evaluation system look like?
    E.g. evaluate note (start, dur) and first pitch track.  Then go through
    again and evaluate the rest of the tracks.  The second time the
    neighbors are now incomplete Score.Events with timing and pitch.
    I would also flatten out the block structure and cancel weak notes so
    I have access to true next and prev.  This implies some way to stash the
    unevaluated tracks in the Score.Event.  Then a postproc pass would go
    through and evaluate again, providing new context to the unevaluated bits.
    . I already have something vaguely like this in the Inversion dynamic
      state.  I can provide new context with Dynamic... though it would be an
      essentially untyped way to do it since there's no type difference
      between the first and second evaluation.
    . At the moment I don't need a generalized solution, so I could just
      hardcode:
      event_stage2 :: Maybe (([Score.Event], [Score.Event]) -> NoteDeriver)
      Then at conversion time, any event with an event_stage2 is replaced by
      its evaluation.
    . Conversion isn't quite right, because I still want next event on track
      etc... but actually no, I've been here before.
    . Then I need some way to specify notation that wants to wait until
      conversion.  I guess it would go by track, so maybe a magic symbol in
      the track title.  Then slicing separately returns slices from those
      tracks.  These still have to be evaluated in their original environment,
      so I then wrap in a derive_tracks and store as a NoteDeriver.
    . So I think this could work... but is it really worth it?  It seems like
      it introduces a whole new level of complexity.  And, if I go the
      typesafe route, a whole new type of calls, which a new accompanying
      namespace.
  . Import or trace curve from a pitch tracker into the pitch track.
  . Staff notation represents chords well, but tracks don't.  Think of a more
    compact notation.
  . Why can't I write a 'tr' that generates pitch signal in some cases, and
    adds an attribute in others?  It would be redesigning control tracks so
    they are just note tracks that slice their children and apply
    a transformer to them.  I'm not sure that will coexist with the curve
    description language that control tracks currently implement.
    It would be interesting to get rid of track types entirely though.
  darcs to git:
    . https://github.com/purcell/darcs-to-git
    . http://darcs.net/DarcsBridgeUsage

tracklang problems
  . It's too low level for chord-oriented music like piano.  For instance, I
    have to care about which note is on which track, while staff notation
    only has one way to write the cord.  So I have to do busywork like sorting
    notes by pitch, or copy pasting notes around between hands.  The whole
    thing about "what track is it on" is a result of the proportional time
    display, otherwise the horizontal position is unnecessary complexity.
  . The way that note, pitch, and dyn are separate is a hassle for reading and
    for editing.  Automatic pitch track selection and collapsing helps a bit,
    but it's still awkward.
  . Also it's not so easy to differentiate all those tracks, especially if
    every pitch track has its dyn track.
  . It can also be complicated to copy paste around if there is a bit of
    non-trivial structure like parent note tracks.
  . It's still hard for me to see relative positions and chords just from
    text.  Staff notation seems much easier.  Also hard to see enharmonic
    spelling.
  . In large scores, especially lilypond-using ones, I wind up with
    a complicated 2d structure to get all of the right transforms on the right
    notes.
    . One problem is that it's hard to see and understand the skeleton
      relationships, but also that each instrument has a unique ad-hoc setup
      based on what it happened to need, and then I fit in whatever I can into
      that ad-hoc structure.
    . Not only does the complicated structure consume thinking power, it makes
      things like copy paste awkward.
    . Also I spend time fiddling with track widths.  Because one track has the
      same width for the whole block, it should generally be wide enough for
      the widest text, but frequently that makes it too wide in general.
    . Also it makes me reluctant to solve problems by adding a new track.
    . Maybe the problem is blocks are too large.  They're generally awkward to
      navigate.  But on the other hand, things scattered into lots of separate
      blocks make it hard to read, and annoying to update.  A "1:1" mode could
      alleviate the update part.
  Solutions?
    . Theoretically lilypond could give the advantages of staff notation for
      reading only, but it's too slow for realtime update.
    . I could use verovio to maintain a instant staff display of the current
      surroundings.  Of course all this only helps with reading, not writing.
    . More utils like LNote.sort_on_pitch to automate away hassle could help
      with writing, but not reading.  So maybe it's worth trying to make
      sort_on_pitch more robust.
  verovio:
    . Lilypond is really slow.  If I use verovio maybe I could have a realtime
      display in staff notation.
    . I'd need a lightweight svg viewer, or svg display widget.  A web browser
      might work, if I can get it to update.
    . It has a standalone binary that can read MusicXML or PAE or various other
      formats, but why should I use some awkward intermediate format when
      I could link it in and use serialized notes as im does.
    . How much work this is depends on what format it expects.  Probably similar
      to lilypond, and should be able to use the same tracklang notation, except
      of course embedded lilypond code won't work.
    . But it's probably not worth it unless there's really a good reason for it.
      It could be a simpler than the lilypond backend since it's just meant to
      give a basic overview of durations and intervals, but still it's probably
      a fair amount of work to create and maintain a binding.
    . One complication is that it might be necessary to do an incremental or
      local-only update for speed, and I'd need to come up with some mechanism
      for that.


long term:
  - midi record
  - dense / efficient control signals
  - stable api
  - solution for per score haskell
  - text score
  + non-realtime synthesizer: doc/dev_notes/synthesizer
    - include audio inline, so I can write signal transforms like event
      transforms
  - horizontal layout
  - Unify environ, controls, and pitch signals by making signals of
    arbitrary type.
  - print scores

planning / research
  text score: doc/dev_notes/text-score.md
    . Time problems:
      . I want to say "repeat n times".
      . I want sections with their own tempo, and then the caller just sequences
        them.  If I turn the whole thing into one call, then I can still fit it
        into a global timeline, and apply transformations or tempo there.
      . If there is meter information in the text score, I can derive a ruler.
    . I could generalize Pitch.Pitch to 'Pitch pc'.  Then Bounded types would
      have per_octave built-in, but I could still use Int for generic cases.
    . Rhythmic framework: in the solkattu branch I extracted the rhythmic DSL
      to 'Note a | TempoChange (Speed | Nadai)' and I have have generic
      functions to get durations and check tala alignment using matras, and
      flatten to (Time Ratio, a).
    . This winds up being more general than haskore, but probably less general
      than music-suite.  It looks like 'temporal-media' is analogous, though
      with arbitrary time shift/stretch, and events have duration.  Also since
      it uses (start, dur, note) events, it doesn't need rests, and can do
      overlapping events.
    . Henning Thielemann's LiveSequencer highlights score as it plays:
      https://hackage.haskell.org/package/live-sequencer-0.0.6
      . He does it with a custom gui widget and language, but I wonder if
        I could do this with by sending highlighting info in real time to vim?
  cmj:
    . bezier-spline-modeling-of-pitch-continuous-melodic-expression.pdf
      Contact Bret Battey about PICACS: http://www.mti.dmu.ac.uk/~bbattey/
    . Wendy Carlos' tuning article: "Tuning at the crossroads", CMJ 11/1
  things for expressive music
    There needs to be some way for notes to affect surrounding notes.  For
    example
      . A trill might want to push the next note back a bit so it can complete
        its cycle.
      . Portamento might want to put controls points on a curve, so the speed
        a distance between pitches affects how quickly they approach, and
        quick notes will have less accurate pitch.
      . Gender tick affects the damping of the previous note.
      . If I control uses bezier curves, the curve is determined by the last
        control point of the previous and the first point of the current call.
    Other ideas:
      . Switch samples when played quickly.
      . Drum thing where successive strokes lose some energy.
    . Randomization is a first step, but true variation in playing is not
      random.  Things to study:
      . Tempo variation.  This is related to intentional tempo variation, but
        there should be slight tempo variations all the time.  This also has
        to do with higher level controls like rushing or lagging, and slight
        amounts of swing.
        E.g. some instruments may tend to rush when they want to be more
        prominent, or get louder.
      . Start / duration variation.  Related to tempo but at a lower level and
        less systematic.  Interpretation of staccato depends on surrounding
        tempo.
      . Dynamic variation.  Many instruments tend to get louder at higher
        pitches.  Tempo speed up tends to increase volume.
      . Pitch variation.  Some instruments tend to attack inaccurately and
        then correct.  Higher dynamics and tempo could make pitch less
        accurate.
    Modelling notation as a set of constraints:
      Notation specifies parameters along with how "fixed" they are.  For
      example, specified pitches are usually immovable, but onset time might
      be variable, depending on how important the beat is.  Higher level
      notation then assembles components and combines the constraints, and
      results in either conflicts, or a set of more specific constraints.

      . Example: janta attacks from below, normally one diatonic step, but
        avoids repeating the previous note.  A trill can end on either low
        or high, but if followed by janta, will change to avoid making janta
        repeat a note.  If trill speed is unfixed, it can change that,
        otherwise change attack time of the following note.  If the trill end
        is fixed, then the grace note must adapt by picking another higher
        note.
      . Carnatic ornaments change when time is reduced.

  think about grammar for ornaments
    . Notes have a syntax: there are ornaments or articulations only valid at
      the attack time, ones that apply to the sustain, and ones that serve as
      transitions to the next note.  Also, the shapes of ornaments vary based on
      the note or absence of a note preceding and following, in addition to the
      speed.  It makes me think of cursive Arabic, where letters change shape
      and placement based on the previous letter, along with rules about which
      letters go where in the word (I'm sure linguists have a name for this,
      e.g. English has "ng", but won't start a word with it).  I've noticed
      there's a tension between specifying exact times via a timeline or
      whatever, and the kind of higher level flexibility implied by a syntactic
      approach.  E.g. if you say "attack X, sustain Y, end with Z", you are not
      saying exactly when X, Y, and Z start and end, and they are free to
      arrange themselves according to context.  But you do need a certain amount
      of precise control over times, at least in some cases.
    . This is similar to the "constraints" idea, at least with regard to some
      aspects being flexible, while others are fixed.  For instance, if
      I write ornaments with no specific times: 'A; B; C' then the start times
      and durations are flexible, and its up to the interpreting code to
      arrange them, but if I make separate events for A, B, and C, then the
      times are fixed.  Of course I also want to be able to fix A and C, but
      leave B's position flexible.
    . How to represent this as events?  I think I need a "macro" facility,
      where a call can interpret following events as a separate mini-language.
      I used to have this, and could probably get it back, by re-introducing
      the "skip following events" return value.  In that case, some notation
      like a leading '=' would indicate that the start time is fixed.
      Otherwise, the event_start is irrelevant except that it's in between
      the previous and next events.
    . Or maybe I do it as sub-notes, that way the one on the left specifies
      the extent of the "note DSL", and I don't need a "skip following" hack.

  . Give a visual indication of the events emitted by a call.  This is the
    note level version of the track signal render.  The underlying problem is
    that textual call names are not necessarily very clear about what the
    notes are, especially if it's a relatively ad-hoc call.  But I think
    I need a fancier GUI for this, since I'd have to have some way of turning
    a bunch of events into a distinctive looking graphic, e.g. a scaled down
    image of the block or something.
  . spline curve interpolator: evoral/Curve.cpp, www.korf.co.uk/spline.pdf

  . If I implement a VST host or patch a DAW to accept VST controls like MIDI
    controls can I get low latency high res controls?
