LEGEND
  - todo; + in progress; * done; / obsolete, do not want, or can't repro
  ? open question; . note; bug: marks bugs.

UNSORTED
  * Cmd.Edit.strip_call should only apply to a note track if you have note and
    pitch tracks selected.  Or maybe it would be simpler to make it only apply
    to the point track?
  * can I get rid of Merger's identity field and instead apply that
    optimization in the functions themselves?  Then I don't have to pretend
    it's a monoid.
  * should I have generic soft and loud transformers?
    e.g. p for piano, f for forte
    . How to coexist with both 'scale' and 'mul' merging?  I could use the
      trick of setting absolute dyn, but I don't exactly want it to be
      absolute, just say *1.5 or *0.3.  Wait, I guess that's mul.  So merge is
      another argument.
    . Then maybe a key to add them.  Then I have 'p | o' instead of '.'.
      Maybe it should be a symbol to be more distinctive?  '>' for 'f', and '-'
      for 'p'.
      . Then '=' to extend dur, and '^' to reduce it?
  - If I have if an arg is Sig.Both, and I have call-arg=x, and then arg=y,
    the arg=y should override the call-arg=x.
    . The problem is that it can't know at assignment time when args belong to
      the same call, but then the call can't tell which one was more recent.
    . For the first, I could assume that arg should override *-arg.
    . For the second, I could attach stack depth metadata to the val, then
      prefer the one with more depth.
    . The first is simpler, but it seems sketchy to go replace call-arg just
      because I assigned to arg.  Maybe the argument isn't even supposed to
      have an Unprefixed variant!
  - If there was a Sig.Named [x, y, z] then I could have a call default from
    arbitrary env vars.  Doing this could break the call-arg assumption above
    though.
  * fltk: If I have a non-point selection with the cur_pos at the top, and
    move it, it gets cut off when moving up, and leaves a bit of the triangle
    when moving down.  Probably damage is not expanded enough.
  - naming: use either 'attrs' or 'attributes' consistently
  Should selection moving use Selection.Move or Selection.Replace?
    . Move is useful when adding another thing of the same duration, or
      keeping a zoom level.
    . Replace is useful when I want to enter notes after a selection.  But
      sometimes I just want to set the point at the end of the selection,
      winds up being down-up.  If I had a collapse to point it would do this
      directly.
    * Try with space as Selection.to_point.
  * 'a' keeps getting shadowed by kbd entry.  Can I move it to a symbol on
    the right side, and have a rule against shadowing those?  Maybe :?
    * Actually this is not right for non-dvorak, I should bind by position.
  * How can I get dyn to only affect attacks?  I could have a 'dyn-atk' and use
    that only at attack time, but what about other controls?
    . Just hardcode a few signals for now.
    . But I also want to use vel for some articulations, and cc2 for others.
      So I think even for pressure instruments I still emit velocity.
    . Sometimes dyn stays constant for the note, and sometimes
      it's continuous.  Also, in the constant case it sets velocity instead of
      cc2.
    . For the second, I think I can just set the velocity to the dyn.
      Presumably most instruments won't care.
    . When I have a 'dyn-atk', the note deriver gets its value, and merges it
      with dyn as a constant, using the default dyn merge.
      . It's all so ad-hoc, but I can't think of any way to generalize.
  - Interpret a midi file with keyswitches back to the attrs.
    . This is so I can load VSL examples and learn from them.
    . Should it be a score transformation, or start from the parsed MIDI?
    . MIDI seems easier because it's already in a linear format, while for
      the score I'd have to interpret it into one.
    . But then I need to pass the instrument mapping to Midi.load.
    . Maybe not really worth it?  For learning I can load in reaper and just
      watch the VSL UI.
    . But still worth keeping existing work, because I'll need something like
      that for MIDI record.
  * Move cmd-m to GlobalKeymap, so it works when you have several tracks
    selected.
  * When there is a non-point selection, make it obvious where cur_pos and
    cur_track are.
    . I still want arrows on point selections because of a multiple track
      point selection.  But maybe I can make it red only for the track point.
  vsl:
    * attr priority:
      . +pizz over +nv
      . +harsh over +stac
    * Can I automatically extend real duration of +stac notes while leaving
      logical duration alone?  This is because vsl sounds better if you give
      the duration, but it wouldn't be notated that way.
      . Also I can add +stac if it's played like that, but doesn't get a dot
        in staff notation.
      . Actually, wouldn't it be better to set release time to long for those
        articulations?
    - figure out how to do tuning
      . I think it needs to be pitch bend, since it doesn't seem to respond to
        MTS.  But VSL ensemble should be able to load multiple copies of the
        patch and share sample data.
      . Figure this out before doing too many more patches, because I'll have
        to update them all with global control config, unless there's a way
        to copy paste that.
      . However, it apparently can be used with hermode, so not sure how that
        happens.  Maybe I can just ask VSL support.
      . Scala files are not very good because I'd have to go manually load
        them every time, and they're static.
    . Legato attack scale control affects the crossfade level of interval
      samples, experiment with that.
      . Wait, where did this go?
    . figure out how perf reps work, and how I should handle them
    - make sure perf_upbeat_repetitions are consistent
    - make sure grace vs. grace.updown is correct
    attribute groups:
      . bass clarinet has nv without vib
    - rename +sec# to +s#?
    * should be able to select the most appropriate sec# dyn given
      +cresc or +dim on a note.
      . But derive doesn't have access to the full Patch, so it can't get
        attributes.  I could either have the inst put a list of its attrs in
        the environ, or just let derive at the patch.  Is there any harm to
        the latter?  The original idea was that there are multiple backends
        so derive shouldn't depend on a particular kind of instrument, but
        attrs are already generic, and besides portability across instruments
        is never a goal.
    * Figure out how to map continuous controls, and crossfade.
  * it's annoying to apply an attr over a period of time because it requires
    a parent track.  Can I make attr controls, e.g. a control named +nv which
    only applies when >0?
    . This is another reason to unify Environ and signals.
  UI awkwardness:
    * Hitting note entry in a parent track makes a pitch track.  I can detect
      those and not do that.
    * Sometimes I want to move all tracks down by time.  Key to select all
      tracks?
    - Paste between blocks with different track layout is awkward.  Can I have
      a note-oriented paste that reuses or creates the track structure?
    * It seems inconsistent how horizontal movement retains the selection, but
      not vertical movement.  And it seems useful to keep the duration.
  . I wind up with a sequence of note transformers, e.g. a rhythmic pattern
    with '('.  Can I abstract that?
    . It would be like textual substitution of a block into a parent track,
      possibly with loop or tile.  Can I do it with a plain call?  I think I
      can, though I'd have to slice after the substitution.  Also, I think it
      would have to name a block call, a renamed one wouldn't work.
      . If that continues to be a problem, maybe I could have c_equal
        understand renames specially.
    * I could have a 'cycle' parent, which takes n transformers and cycles
      them over its children.
    * A time-based variant would have to somehow get transformer + duration.
      I could do it with two layers of transformers, but awkwardly.
      . Would have to look directly at subs without slicing to get text and
        durations, then delete the direct sub and do slicing.  Maybe easier to
        name a block?
      . The other option is to give up on the graphical version
  * State.insert_block_events clips to the end of the ruler, which makes
      working with a ruler-less block always delete events.
    . I added it because I wanted move events to clip events at the end of the
      ruler: 'make insert and delete time clip events to the block'
    . I think this was a problem because it was inconvenient to select events
      past the end of the ruler and delete them.  So maybe a better solution
      would be select to end of track to be to the last event?
  Format:
    HsPretty:
      problems:
        . Missing close paren after wrapped constructors.
        . If I add an indent after each constructor then I get tons of indents.
          What I really want is a way to collapse multiple constructor calls
          with a single argument.
        . For some reason it's not wrapping tuples properly, they become
            (a, B
              c
            )
          instead of
            ( a
            , B c
            )
    - Util.Pretty still broken: pprint Vsl.violin_harmonics
    - move format related modules to Util.Format.*
  * support Controls.octave, then I can use it at Vsl.harmonic
  * See if the vsl arp patches are all divided by key, then I can update them
    all at once.
  * ShowVal.doc_val I always type wrong.  How about ShowVal.doc?
  * pianoteq harp should set gliss pedal for grace notes
  * pianoteq `o` and `m` calls are wrong, because they set the control but
    don't unset it.
  - Sortedness tracking for Stream and Post functions.
    . Track down usage of Stream.from_sorted_list, probably most uses are
      bogus.  Stream.from_list and Stream.from_events have to take
      Score.Events so they can sort them.
    . Sorting vensions of Post functions also have to return Score.Events to
      be able to sort them.  They could take another event_of, but it seems
      like there should be a way to compose the mapped functions instead of
      the maps.
    . I should also come up with a plan for deforesting the intermediate
      lists.
    . Order is easy to check with quickcheck.  I could come up with some ways to
      do quickchecks on certain score fragments.  Or alternately, apply
      a standard set of checks: start =0, >0, in callee block, etc.

  - Cmds don't indicate when they could abort or throw.  I rely on ad-hoc
    conventions like get_ vs. lookup_, but what about it actually being in the
    type signature?  I could try the "lightweight checked exceptions" in:
      http://www.well-typed.com/blog/2015/07/checked-exceptions/
      https://www.reddit.com/r/haskell/comments/3g41au/follow_up_safe_lightweight_checked_exceptions/
    . Or an easier way would be to put 'throw' in a subclass.
    . I have this implemented in the p-monad branch, but it didn't seem
      terribly compelling.  I think the reason is that it turns out most
      functions can throw.  It doesn't replace get_ vs. lookup_ because they
      are likely to call something else which can throw.
  - No thru on pitch track of >pemade in save/rehearsal/bali/legong/semara-dana.
  - Perf.lookup_instrument on a pitch track could look at its note track.
  - Criterion testing: why is cmd_derive faster than derive?  It should be
    doing more work!
  - A block with logical range called at time 0 gets messed up.

  - I forgot to add Sub.inverting to mridangam.p1 and mridangam.pn calls.  Can
    I have a warning for when a non-inverting call has a note track below it?
  - It's confusing how sometimes the environ is applied to the pitch during
    derivation (e.g. Post.set_instrument), and sometimes it waits for Convert
    to do it.  Do I really need both?
    . Post.set_instrument needs to set because I need the environ from the new
      inst.  Could I instead overlay the environ into the event environ?
    . It's error prone because there's nothing that enforces that you set
      instrument with Post.set_instrument, and if you don't, it will work until
      you use a scale with e.g. tuning, and then it will be slightly off.
    . Originally added in the patch 'add interpolate scale':
      The bigger problem was that since pitches got the Environ at conversion
      time, the interpolate scale couldn't substitute `key-from` and `key-to`
      because any environ values it set before evaluating the pitch wouldn't
      "stick".

      So I switched to applying the environ when the pitch is created, but this
      broke the case that made me switch to applying environ at the end in the
      first place, which is when switching instruments in a postproc I want the
      new instrument's environ, specifically Environ.tuning, to apply to the new
      event's pitches.  So now when I switch instruments I have to explicitly
      apply the environ from the new instrument, via Post.set_instrument.

  - kotekan calls leave keys down in kontakt
  format: Pretty:
    * format is messed up with
        (Score.Instrument, Map.Map Score.Instrument Score.Instrument)
        ( >u
        , { >i
                : >kontakt/wayang-isep
            , >u: >kontakt/wayang-umbang, >w: >kontakt/wayang-pemade
            }
        )
      should be:
        ( >u
        , { >i: >kontakt/wayang-isep, >u: >kontakt/wayang-umbang
          , >w: >kontakt/wayang-pemade
          }
        )
      . Possible solution is that ", { >i" starts with indent 2, but
        internally has a indent 1.  If it ends with indent 1, then I have
        to use that when finding the break.
        . This is necessary because when a section uses withIndent

    * also pprint Maps are messed up:
      . Derive.Derive_test test_tempo_funcs2:
          prettyp (Derive.collect_warp_map $ Derive.state_collect
            $ Derive.r_state res
      { [block (bid "test/b0"), (bid "test/b0"), (tid "test/b0.t1")]
          : Left ( 0s, 8.5s
          , Warp (0s, .5s) { signal = <0s:0, 4294967296s:4294967296> }
          , (bid "test/b0"), (tid "test/b0.t1")
          )
      , [ block (bid "test/b0")
          , (bid "test/b0"), (tid "test/b0.t1"), (tid "test/b0.t2")
          , (tid "test/b0.t2")
          ]
          : Right (tid "test/b0.t2")
      ...
    / pp LPerf.sel_events has an extra level of indent after the [.  Not due
      to LEvents.
      . Actually this is correct, 1 for list, 1 for record continuation.
    - Add Util.Format backend for AST as in Util.PPrint

  - empty track doesn't get an Environ, which causes Cmd.Track to not be able
    to find the instrument.
    . It was because the kendang tracks were below >pno, not "tempo".  So, two
      problems:
      . It's too hard to see that the skeleton is wrong.
      . Note track children should have dynamics too.
  - Local.Instrument modules include configuration functions, how to call them?
    . Kontakt.configure_wayang, configure_legong, Spicy.configure
    . import into a Local.Repl module
      - hmm, looks like I'm not importing Local.Repl any more
    . make the repl support :m
    . bundle them into the instrument db
  - Do I need Perform.perform_control_msgs.trim or not?  Figure it out and
    write a test if I do need it.
  - fix control scope in parent events that cover up an orphan, as
    demonstrated in Sub_test.test_overlapping_parent_control_scope
  - Better solution for the "sample at end of block" problem, as demonstrated
    by Block_test.test_trim_controls_problem
  wayang
    - Automatically fill in weak notes?
      . This also applies to reyongan, even more so.
      . In fact this is similar to noltol.
    - many double strikes or ngoret tones land a bit ahead of the beat
    - I want some optional ngoret to happen the same way in both hands.
      I could make it apply to a parallel kempyung or octave.
      . I'd need a fancier ngoret that understands 'inst-top' so it can go
        down if necessary.
  - thru on *legong notes is wrong the first time
    can see this editing rehearsal/kendang-legong
  - can I make Edit.cmd_set_duration use alter_duration?  Also, why do I need
    modify_event_near_point, doesn't ModifyEvent.selection already do that?
  + in rehearsal/telek, one ugal sometimes gets stuck on +mute, why doesn't
    a new play send the keyswitch?
    . can repro with bug/stuck-mute.  But MIDI looks normal.  Record in reaper
      and play back to see if it's a kontakt bug.
  - Play position doesn't work right for 'loop' and 'tile' calls, it only
    understands the first loop, and doesn't know that 'tile' cuts off the
    beginning.
  india: gamakam:
    . It seems like way too much work to try to implement these things in the
      constraints of the existing system.  Perhaps it would be better to do
      something very specialized, and see if it works nicely, and if so, only
      then try to integrate it with the rest of the system.  Then again, the
      future pitch problem has come up in all sorts of places and I need
      a better answer for it.
    Gamakam3:
      - < is incorrect: in @b5 4.3.4 change to '!!<c' and it comes from
        m instead of r.
      * Switch 123 abc from prev pitch relative to swaram relative.
      * Instead of compact and space-separated notations, have just compact
        notation, but calls >1 char can use a delimiter, e.g.
        . What if the delimeter is space?  Then I have to write '! P1 a12'.
        . Then if I have multiple in a row: '! P1 P2 123'
          But then I need a trailing space to make the last one long.
        . Otherwise: '!,P1 P2,123'
        . This seems like no better than the current scheme.
        . How about a simpler scheme where capital letters get a single
          character argument, and the rest have no arguments.
      * 'T' call should take next digit and set pitch, so I don't have to go
        out of compact notation.
      * How about negative?  Can I do '-' with an arg?  Then '=' has to be
        flat.  Since the arg is just one character, I can't do T-1.  If
        Ta Tb Tc Td is up to -4.  Do I need an escape hatch?  I could write
        T-4, where an arg can go up to the next comma.
        Ta00a
      * Perhaps I should always start from the previous pitch, and '<' is the
        previous swaram.
      notation:
        - Is it weird to have dyn as a postfix operator?  Should I put it in
          front, e.g. <[-]?
          . Well, one thing is that it's easier to parse as postfix because
            I see a '[' character.  Given '<[-]', the '<' will look like the
            pitch call '<'.
        - It should be easier come from current + n than '!Pn !...'.
        - Maybe aliases for '!<-c-' and '!-d-'?
        - Snapping to the next pitch at the start of a note is unnatural.
          Perhaps I can have some easy way to come quickly from the previous
          real pitch.
        - It's annoying how a DynCall will break a compact notation, e.g.
          '![-]< !---' would be nicer as !![-]<--- or even !!-<---
          Since dynamic calls have a limited character set, maybe I could do
          this just by making allowed characters non-overlapping.
          . I could do the same thing with P, for e.g. !!P4---
          . Maybe I should give separate dynamics a try before thinking about
            this too much.
        - !!<c should work for move from previous pitch.
        - In a janya raga certain notes may be missing, and I should be able
          to skip them.
        - Also ragams with narrow intervals, e.g. mayamalavagoula sr
      . I'm not yet sure how to handle dynamics.  If I do a scale merge, then
        I can have the dyn calls have defaults around 0, e.g. > is 0 to -1,
        and => is 1 to 0, or .5 to 0.  Experiment more before I decide if this
        is a good approach.

      ? I could make gamakam into a postproc.  This means I could get next
        pitch even across block boundaries.  But ScoreTime is not available.
        I would need some way to make a control track modify the environ
        instead of emitting signal, so the note call can then pick that up.
        Presumably it would emit something like [(start, dur, text)] and then
        those values have to be merged into a special "Val signal" in Dynamic,
        which the note can pick up.
        . pros:
          . Get next logical pitch even across block boundaries.
        . cons:
          . Need special machinery to have a control track emit structured
            values.  In full generality this is approaching the idea about
            unifying environ with signals.
          . No track signal, have to rely on the note track signal.
      - Currently 0 and - have the same meaning.  Decide which one I want and
        remove the other.
        . Currently - is winning... but if I use separate worcds then 0 -1
          seems a lot easier to read than - -1.
      - Write docs.
      - The only reason '* interleave' works is that I trust gamakam calls to
        always produce a sample at the same time as the parent track's sample,
        and thus replace it.  This seems like a sketchy thing to rely on.  Can
        I come up with something more robust?

      . This approach means I can't do variable stretchiness, where I set
        the oscillation speed to a constant and fit as many as I can, or do
        a set number but stretch the beginning, middle, or end enough to
        make up the time.  And it would be a real pain to get a consistent
        speed.
      . So it seems like I still want I way to do set duration, and variable
        duration.  Effectively the even duration division is just a kind of
        stretchy where everyone wants to stretch equally.  I could incorporate
        infinite stretchy and nonstretchy with special duration values.  Then
        duration becomes a weight.  If everyone is 1 then everyone divides
        evenly as before.
      . Also since each ornament happens at the same speed it seems like
        it would sound mechanical.  Of course this is also true if I use
        a constant kam speed, but at least with that I could have a global
        speed with a bit of randomization.  I could warp the division times
        randomly, but really it's not random.

      . For the violin, I want to experiment with other controls, e.g. pitch
        slides also do less bow-force, or dyn can reduce bow-force and
        bow-speed.

    / Gamakam2:
      - '!; k -1' means 'k' is a end call, which doesn't exist, but I get
        "pitch generator not found: 'k'".  Should mention that it's an end
        call.
      begin
        - j needs to stretch when the notes are fast, but expand to a maximum
          otherwise.
          . Doesn't it already do that?  I want it to still leave a bit of
            pitch.  If that's universal, I can add that as the default middle
            or end call.  Or just manually add an unstretchy end to notes that
            should have a minimum of swaram pitch.
          . > as a special hack for a 0 length fade-out seems awkward, maybe
            I should have a special symbol, e.g. <' and >'?  But since it's
            only ever going to be fade in and fade out I can just reserve <>
            for it.
          . Would it better to treat all calls as stretchy, but they
            themselves decide how much to stretch?
        - janta
      middle
        - kam: accelerate near end
        - test hold and lilt for kam and nkam, adjust for nkam
        - maybe 'flat' should transition to the pitch instead of snapping
      end
      - precomposed calls, e.g. '! j 2 -1; h -1; to 0'
      - select precomposed calls based on scale degree, previous pitch,
        and tempo
      - Currently, if there isn't enough time, the begin call will compress the
        middle and end down to nothing.  Perhaps begin and end should compress
        evenly?
      - When this is usable, I can get rid of all the old gamakam calls.
      How to get the next pitch?
        . 'approach' does it by evaluating the next
          event on the pitch track.  I could do the same, but I'd have to go
          find the pitch track, and it would be wrong if anything fancy was
          happening.
        . What I really want is to run once with the basic pitches, and then add
          the gamakam later.  That means a postproc, but then I'm doing awkward
          postproc evaluation.
        . If I know a note track has a set of basic pitches, then I can evaluate
          once, ignoring '!'.  Then evaluate again, and stash the events where
          I can get them.
        . I could do it with a special track evaluation.  This seems like a lot
          of work for something I'm not sure is even right.  I'm not even sure
          gamakam will need the next pitch.  On the other hand, getting next
          values, or this kind of staged evaluation in general, is a problem
          that comes up in different contexts.
    . The split between >, *, t-diatonic, and t-nn is pretty awkward,
      especially how I duplicate all the pitch calls as control calls.
      I think I'm going to want a higher level layer, and only work with
      those calls when I need more precise control.
      . Could I make everything t-diatonic by using fractions?  On the pitch
        track I can just use number types, which is so much more appealing.
      . The nice thing about transpose tracks is that I don't have to repeat
        the pitch all the time.  And it seems cleaner to put gamakam on its
        own track.
      . Maybe I can have a generic transpose track, that expects its calls to
        return typed values.  Then when it mconcats the signals, it first has
        to partition into different types, and apply separately.
      . If I extend this for pitch tracks too, then I can get rid of the
        ControlMod stuff, but I need basically the same mechanism to say
        where the signals go, and how they are combined.  It does seem cleaner
        to return them in LEvents instead of through Collect.  But it means
        that the control track title becomes a default, since actually it
        can create any type of control signal.
        . It would look like: ("transpose", [..])
      . What about split control tracks?  I think it's too low level and
        awkward to use, since it requires a separate %t-whatever event
        squeezed in there somehow.
      ! However, I could use a pitch track, and then get rid of the extra
        argument by expecting a separate pitch track above it.
    . Low level ornaments are control or pitch curves, as I have now.  They
      are used directly with pitch or control.
    . Medium level ornaments are for generic pitch, and go on a generic
      transpose track, they use arg types for diatonic vs. nn.  They can also
      emit dyn control.  They are specific motions, e.g. (-1 1)
    - overshoot "curve" for 'smooth': over2 over3, depending how far over
    . instead of hardcoding specific times, I should say short, medium, long,
      which can vary and have some randomization:
      . short, medium, long: -s = "(rnd low high) | -m = .. | -l = ..

  - %sus-abs=-.x is not quite right for detached, because it should scale
    a bit for shorter notes.  E.g. it's absolute but scales down to 0 below
    a certain threshold.
  calls:
    / 'u' and 'd' have a problem with long notes because pitches can only be
      transposed so far.
      . If I knew how far a pitch could be transposed, I could clip the end
        time to the bottom pitch.  But I don't.  Maybe pitches should be
        transposable infinitely far, but emit a -1 NN signal when they cross
        the boundary?  Or would this hurt error reporting?
      . Or I could verify the transpose, and if it fails, transpose half as
        much, etc.
      . Or do the transpose in Pitch.Pitch, and then I can ask the scale for
        the bottom Pitch.
      . Or I could just call it a feature, after all you shouldn't ask for
        a pitch to go below its range and you can explicitly mark the stop
        time if you want.

  - network midi doesn't seem to handle abort?
    playing the second time doesn't happen
  - I have a feeling like FM8 doesn't obey ResetAllControls
    Maybe I should extend Midi.Interface.note_tracker to keep track of
    used CCs to issue resets for them.  Some reset to 1, e.g. cc2 and cc7,
    the rest reset to 0.

MILESTONES
  0.1
    * support diatonics, enharmonics, and symbolic transposition for church
      modes, modes of limited transposition, and exotic scales
      (e.g. octatonic a-h)
    * record chords
    + integration
    * just scales, and other ratio-oriented scales that use letters and
      accidentals
    * complete Idiom.Wind, experiment with the Idiom postprocs
    + bring back negative duration / arrival beats
    * scales and keyswitches
    / efficient thru
    * tracklang complete with set of basic calls
    * better REPL situation
    * derive cache
    * symbolic score
    + save undo history / incremental save - more extensive testing
    * solution for audio, plugins, track bouncing, etc.  ardour / reaper + MTC
    + jack support on linux
    / simple csound backend
    * lilypond backend: good enough to render viola-sonata
    * documentation
  1.0
    - midi record
    - dense / efficient control signals
    - stable api
    - solution for local data / code
  future
    - non-realtime synthesizer: doc/dev_notes/synthesizer
    - horizontal layout
    - mouse oriented signal editing
    - Unify environ, controls, and pitch signals by making signals of
      arbitrary type.
    - print scores
    - include audio inline, so I can write signal transforms like event
      transforms

----------------------------------------------------------------------

documentation:
  - Publish haddock with http://documentup.com/feuerbach/standalone-haddock
  calldoc: CallDoc:
    * instrument browser should omit modules, since they don't matter
    * put newline between each call doc in instrument browser
    - collapse control for modules, option to collapse / expand all
      . Haddock:
        <span id=xyz class="module collapser"
          onclick="toggleSection('n.1')">Title</span>
        <ul id='section.n.1' class='show'> ...
    / put anchors on calls and make single quotes link to calls
      . It's not quite so simple because there is module, and then namespace.
        So the linkifier would have to understand that structure and search
        for one, or have some javascript, and then it would have to choose
        if there is >1 match.  Too complicated.
    / For call doc, can I group calls with the same doc but different args,
      especially different defaults?
      . Would look like:
        doc doc doc generator
        bind -- name
          args
    - I could go look through arg docs for controls and list all the controls
      that have someone listening to them in a certain scope.

shakefile: build:
  - use new system calls and logging levels
  automatic "All.hs" modules
    . I'm reluctant because it's simpler to have normal files, and it's not
      that hard to update them.
    - Derive.Call.All looks for (note|pitch|control)_calls from Derive/Call/,
      but could also take from Local/Call/*
    - Local.Instrument looks for 'load' from Local/Instrument/
  - once upon a time, the shakefile took .2s to discover the build is up to
    date.  Now it's up to .7s.  Where is the time going?

incremental save / git:
  + try saving individual events for incremental save
    Seems to be just as slow as full save, probably most of the time is in
    the call to git.  Test again with larger tracks.
  - wrap operations in a lock file
  - make sure things are ok if it fails at any step
  - I don't think Ui.State needs to emit CmdTrackAllEvents for cases where
    diff will catch it.
  - See if git's delta compression understands binary and can compress
    tracks.  Otherwise, would it be worth helping it by e.g. separating
    each event with a newline?  But then it makes serializing events more of
    a hassle.
  . Git docs: http://progit.org/book/ch9-2.html

integrate / integration:
  score integrate
    - cascading score integrates
      Is there really a use for this, other than consistency?
  derive integrate
    - attrs that the instrument understands can turn into +attr calls, if
      they're not in the CallMap, e.g. save/test/wayang
    - adding a +soft stroke means it gets both less dyn and +soft again, so
      it's extra soft
    - bug: can't delete a derived track, it just gets regenerated
    - bug: can't undo past a integrate create, it just creates a new one
      Maybe I could not record the integrate step?
    - bug: create tracks, remove <, re-add <, does it work?
      Removing < should break the integrate links.
    - Ensure cascading track integration works.
    - If integrate is committing changes to a track, can that bite me if
      a "canceled" derivation comes through?  Think about this later.
    - quantization

lilypond:
  - lilypond: espressivo <> should be like a normal hairpin
    But the way to do this is awkward, << .. { s4 s4 \< s4 \> s4 \! } >>
    . I also want tied notes to expand to 'c4~ \< c4 \>'
      But that has problems, I need a \!.
    . Even '<< b'2.~ { s4 \< s4 \> s4 } >> | b'4 cs''4 \!'
      is not ideal, the decrescendo extends to underneath the next note.
      If I put \! on the tied-to note, it still won't extend.
    . see \at in https://github.com/openlilylib/openlilylib/tree/master/input-shorthands/articulations-not-aligned-with-notes
    . Ideally:
      a \cresc \decresc % over duration of the note
      a \cresc ~ a \decresc % same
  - Lilypond.write_empty_staff creates incorrect rests for a tuple, as shown
    in Lilypond_test.test_add_bass_staff
  - to make notes without duration, ignore the existing duration and choose
    the simplest possible duration.  For zheng, yangqin, percussion.
    . Exception for +trem
  - warning if ly-prepend or ly-append is being omitted due to a chord
  - Maybe code events with a voice should go in the voice requested rather
    than mixed into the first one.  E.g. would have fixed grace notes.
  - one track has voice, the other doesn't, causes a "can't advance time
    backward" error
  - Support ly-append-first and ly-append-last for zero-dur notes.
    . First come up with uses for them?  Or do it just for orthogonality?
  - code events in >ly-global can be distributed to all staves
    Otherwise I have to remember to add e.g. ly-key to all staves manually.
    . But ly-key is no good, I really do need to set the key.  I think I have
      to break up the block.  Why can't I do assignment more easily?
    . Well, I have to grab a deriver to dynamically scope the new value around.
      Unless I let a deriver mutate the environ, then it has to be nested.  If
      a deriver can mutate, then events have to be evaluated in order.  Of
      course, they already do for controls because of the previous sample.
      And since it's unset at the end of the block, block caching still works,
      the same way as for previous sample.
    . On the other hand, I think I want to encourage nestedness and it should
      be easy to split.  The only reason viola-sonata has huge blocks is that
      it's a midi import.
  / Derive.Call.Lily needs a naming refactor since there are too many vaguely
    named flavours.
  / I need some way to hide rests.
    Add magic bit of code that turns its rest r4 into s4.
  - If I can figure out the meter from just the name, then I can get rid
    of the awkward map with hardcoded meters.
    I could have parse generate the Meter and memoize it.
  - optionally emit the lilypond to display a compound meter, e.g. 3+2/8
  / use Util.Format in ly output
  jianpu
    . Research jianpu conventions, but basically:
      . Hide staff lines, stems, beams.
      . Noteheads replaced by numbers
      . Use a somewhat proportional layout.
      . Lines for 8th, 16th etc. notes.
      . Dots for octaves.
      . Stack chords vertically.
      . Grace notes as superscripts.
      . I still use lilypond's bars, slurs, tuplets, dynamics, etc.
    . http://people.ds.cam.ac.uk/ssb22/mwrhome/jianpu-ly.html
      . Produces extremely mangled lilypond.  I should make my own from first
        principles.
    . standalone commercial software:
      http://www.medeli.com.cn/soft/gb/soft.asp

negative duration / arrival beats:
  new arrival notes scheme infer-duration:
    . I don't want to trim because I might need the controls if I extend the
      duration.  I do want to trim because I don't want e.g. t-dia at start
      from the caller, but I do want pitch at start from the block.
    . t-dia:  0   1   0
              b1  b2
              a b|c   d
              a b|    d
    . If 'c' is present, then I clip off t-dia because I drop controls
      starting at 1.  The starts are replaced with ones from b1.
      So the sample at 'start' should come from the local block only.
      Samples after start can be used from global.  So what if the block
      call just deleted samples at exactly block end?  Any local tracks
      could put a sample there, but otherwise the event gets control signal
      afterwards.  If there is a note to replace, the >start samples are
      replaced, but otherwise, I get the ones from the caller.
    . E.g. global filter sweep.  A infer-duration note would stick out
      because the sweep is meant to be continuous.  In this case, I can
      just use the untrimmed control.  But t-dia should not do that, unless
      I really am treating it continuously.  This is the same problem as
      whether a control should continue changing into the decay or not.  The
      sweep should, but a pitch belongs to the next note.  So maybe this is
      a fundamental limitation of the score language.
  represent arrival notes differently
    . Instead of representing arrival notes as the sounding time plus
      a negative duration, I could represent them as a start time plus a flag.
      If the flag is set, it's considered an arrival note and the trigger line
      is drawn at the bottom instead of the top.
    pros:
      1 Cmds work the same for negative and positive durations, I don't have
        to do any special checks for overlapping with a following negative
        event.
      2 I can have a note arrive and another depart from the same point, e.g.
        trill up to a note.
    cons:
      3 The encoding seems not as elegant.  I can still do it with negative
        durations, but now the negative is just a flag, rather than
        representing the actual extent of the duration.
    4 This means that cmds work spatially rather than logically,
      i.e. I'll need a separate "set beginning" cmd since it becomes set
      duration for negative events.  I don't know if that's a pro or con, but
      it feels like a con since I need more cmds.
    #1 might not be compelling if I've already done the work to get them to
    work, but if it's buggy or turns into continual for for every cmd then it
    becomes a big deal.
  / ensure inversion works (it should slice >start <=end)
  - ensure redraw works
    I have to make SymbolTable wrap text above too.

external
  parsing "1r" instead of "1s" gives a "unexpected eof" error msg, it should
    say 'r' was an unknown suffix
    Can't get attoparsec to consistently report an error.  Kind of hard when
    it always backtracks.
    - Need to add <||> to attoparsec.
  - problem with pianoteq: if the same note occurs on two channels, one
    will be dropped.  Report to pianoteq.  I could work around, but it won't
    occur with real multitimbral instruments anyway.
    . Could also work around this with realtime midi tuning
  + send a patch to improve Random.Shuffle?
  / patch for hsc2hs for #alignment
    Just doing alignment manually now.

local: plugins:
  I also want local code in haskell.
    . I could put code in Local.Score.SomeName, and have those either
      statically linked in, or dynamically compiled and loaded on each
      derivation.
    . Static linking is easier, but I should at least automatically create
      a All.hs.
    . Also, creating calls is a bit heavyweight, since I likely don't care
      about tags and doc and module can be inferred.  Presumably I can get
      around that with a constructor that defaults those fields, and then
      the generated All.hs overrides the module.
    . Writing in tracklang lacks typechecking.  There could be utilities to
      write like tracklang, but in haskell, e.g.
        c_p1 = with_note_call "p" "subst1" $ block "pattern"
  . ghc can now unload code: http://ghc.haskell.org/trac/ghc/ticket/8039
  . might be relevant: http://hackage.haskell.org/package/dynamic-loader
    http://codeutopia.net/blog/2011/08/20/adventures-in-haskell-dynamic-loading-and-compiling-of-modules/
  - to do per-score code, I can put it in Local.Score.<namespace>
    Convert to module name by replacing -x with (upper x) and capitalizing the
    first letter.
    Then when you load a score, incorporate the static config from that
    module.  Shakefile can link in the local modules under the right name.
    . If it gets to be too much overhead to link on every single build, then
      I can load dynamically at runtime.
  - Either dynamically load local inst definitions and local StaticConfig, or
    auto-generate the link file Local/Instrument.hs.
  - come up with plan for reloading inst config and static config
    Really what I want to be able to do is recompile the static config
    incrementally, relink it with the main binary *quickly*, and restart the
    app with exactly the same state.  This should be a lightweight operation,
    so it's feasible to edit some code, press play, edit code, and play
    again.  That means a full-on serialize restart is out, because the cache
    could be quite large.

    Of course, you want this stuff in a library so it can be reused across
    projects, so you can put it all in Local/.  Then the song state would
    have a (hopefully minimal) linkage from hs namespaces to the tracklang
    namespaces.

    So with hs-plugins: The static config is considered a plugin.  You edit
    Local/Config.hs, or edit other files in Local/.  It detects the change,
    regenerates Local/Config.hs, recompiles and reloads it.  Then the
    responder is called again with the new static config.

    So I need to be able to re-initialize the responder with a new static
    config.  Actually, the bits I care about are the call map and the cmd
    map.

cleanup:
  See about removing type prefix from record fields.
    . However, if there are lenses, then I need those names for the lenses.
      But perhaps the plain version can have a leading _?
    - Cmd.State
    - Derive.Deriver.Monad
    - Ui.State
    - Ui.StateConfig
    - Perform.Midi.Instrument
  - Util.TimeVector has a hack where a sample at <=0 is considered to extend
    to -inf.  It's because I want a control track call at 0 to extend back.
    But I could do that directly with a postproc ala the tempo hack.  It seems
    like a hack at a higher level is better than one deep in the signal
    implementation.
  - Expr is NonEmpty since there is always at least a "" call, but this is a
    special feature of events.  Would it make more sense to parse "" as [],
    and then special case [] in EvalTrack.derive_event?
    . But I'd need a newtype, otherwise ShowVal [Call] overlaps.  Of course
      the only reason it doesn't already overlap is that a don't have
      a ShowVal for NonEmpty.
    . But Quoted is also Expr... should it be non-empty?
    . I now don't remember where it was that I had an Expr that made sense as
      [], so maybe I don't care about this anymore?
  - Perhaps I should get rid of TrackLang entirely.  Currently it re-exports
    from Derive.BaseTypes, and has a few utilities to create BaseTypes.  It
    seems like a win for clarity if I can get rid of re-export modules, and
    I already have a lot of places directly using BaseTypes.  But on the other
    hand, BaseTypes is already too large, and I don't really want to further
    clutter it up with little constructor utilities.
  - use Control.Monad.Except instead of Error
    . not worth it until I don't need to support 7.8, can I suppress the
      warnings?
  - Move Derive.info_prev_val to the environ, maintained by EvalTrack.
    . This gets rid of all the Taggable stuff, at the cost of making
      Args.prev_val in Deriver and dynamically typed.
    . There's no Val for Score.Event, so I can't use it for note tracks.
      Of course I could just add one, maybe not a big deal.
  - Overlap detection in Derive.Slice I think is still messed up, or at the
    least it's more complicated than it should be.
  Util.Format:
    - don't use 'reverse' in 'flatten'
    - lazy implementation?
  - I could make the fltk interface clearer by putting c_interface.cc into
    fltk, and then putting all the types it depends on in one header.
    . I could make that a .c file too, and get rid of the sketchy hsc2hs on
      c++, as well as clang's "treating 'c' input as 'c++' when in C++ mode"
  - Update.BlockSkeleton sets Block.Status, and so does Update.BlockTrack.  If
    I merge status update into skeleton updates I can take Status out of
    Block.DisplayTrack.
  - split up CallInfo depending on type
    I got started but was discouraged when it came time to write
    GetLastSample, maybe I should make another go.
    Note tracks can't get a GetLastSample at all.
  - storing TrackEvents without duration would make maintaining the
    no-overlap invariant easier.  E.g. have explicit 'off' events, otherwise
    each event extends to the next one.  It means after merging I have to
    clear redundant offs, but that's easier right?

performance:
  - find space leaks with nmitchell's stack limit technique:
    . run build/profile/verify_performance +RTS -K975K -xc -RTS --mode=Profile
        p/cerucuk-punyah.state
      Derive.LEvent.events_of,
      called from Derive.Stream.zip3_on.\,
      called from Derive.Stream.emap,
      called from Derive.Stream.zip3_on,
    . Also, what's with the compile_library stuff in the middle?  Should
      I make it stricter?
    . Giving up for the moment since I don't understand the output.
  . Seq.sort_on winds up calling compare on Stack 13374153 times! 9.1% time
    I have to sort it because the stack is kept in reverse order.
    - Per-track stuff can wind up happening zillions of times due to
      inversion, so look for other places where I do work or collect data
      on every track fragment.
    - At least at one point, keeping EnvKey.seed up to date was expensive, and
      it's not even needed when there's no randomization.
    - I could analyze TrackWarp or TrackDynamic to get stats on how many times
      each block is called, along with overall stats on how many notes.  Just
      an interesting thing to know.
  understand deriver performance
    . I never know if changes I am making help or hurt performance, because I
      don't trust any of my profiles.  This means I hardly ever run them, at
      which point why bother having them?

    . Productivity is actually really good during derivation: 70-80%.  Only if
      I turn on heap profiling does it go down to 33%.  So maybe there's
      nothing to do?  Still, it seems like it's slower than it should be.

    . I want to find out how much list copying happens due to Stream being
      a list.  Perhaps I can use SCC annotations?  For transforms, I want to
      see the effect of a transform copying the whole stream so I can tell if
      making it interleave has an effect.
      . It would be nice to see how many times each cons is copied, but it
        would have to be for the output stream specifically.  How can I do
        that?  I think I would have to make my own list type, then count
        allocated cells?
    . Also, from heap profiling, the vast majority is PINNED, which is
      presumably ByteString.  But what is it then, if I'm using Text for
      events now?

  research using pipes for generators and transformers
    . This would handle the composed transforms thing.
    . What about parallelization?
    . What about the MergeList idea?
    . The bigger question is how do I do dynamic state when all the different
      calls are interleaved?
    . Actually now I'm thinking pipes aren't suitable for this.  Pipes are
      about interleaving effects, but derivation is pure.  But not quite,
      since it does depend on StateT.  In a pipes implementation, a generator
      would be 'P.Producer Event Deriver ()', and a transformer would take
      a Producer to another Producer.  Actually, since calls need to typecheck
      etc., it winds up being:
        type Events = Producer Event Deriver ()
        type Generator = Deriver Events
        type Transformer = Deriver (Events -> Events)
      . In a pure environment, pipes still give a constant bound on how many
        elements I hold on to at a time.  But since I look ahead arbitrarily
        much, maybe I don't want that.
    - Set up a pipeline over a StateT that returns Event.
    . The way to do this without pipes would be for transformer to be
      Deriver (Stream -> Stream).  Then I can run all the transformers, and
      then compose all their functions.  At that point, the only thing pipes
      would really give me is a clear picture of how many elements I need
      because each one needs to be specifically awaited... but it seems like
      the look-ahead stuff would be really inconvenient.  And I do the same
      thing, it's just less convenient with pipes.
      . It does mean I have to express all transformers purely.  This is true
        for the non-monadic Post functions, but it means I can't express ones
        where a previous monadic effect on a previous element effects a later
        one.  But that only applies to Threaded, and I can get that anyway by
        threading myself, so maybe there's no problem?
      . The way to prove that would be to remove the monadic Post.emap
        functions.
  make composed transforms more efficient
    . Composed transforms have to keep the whole event stream in memory since
      they can't interleave.
    . Would it then be possible to deforest the intermediate lists?  Bulit-in
      deforestation won't work because of the intervening call machinery, but
      maybe I can recreate it manually.
    - First, figure out how to measure the amount of memory used by
      intermediate lists.  It might be completely trivial.
    - First, I have to detach threaded state for the actual map.  This is
      possible because I don't care about Threaded or Collect.  So modify
      Post.emap_m to map a Derive.run over every element.  Then I need to
      collect the output and turn Left into a Log... or leave it in the stream
      somehow so I can throw at the end.
    - I think the stream will then remain lazy, and I should be able to GC
      as it goes, but verify with Debug.trace.
  - I'd like to see if directly modifying Collect or a MergeList for LEvents
    could reduce garbage, so I need to get some profiling up first.
    . monad-par-extras Control.Monad.Par.AList is deprecated due to poor
      performance, what's up with that?
  - Internal.merge_collect is constantly merging in mempty, try reducing its
    use.  Can I continue to enforce monoid-nature?
  - I should be able to move samples only when converting to MIDI, this way
    I don't need to move parts of the signal that wind up being trimmed.
    Either try to trim the signal earlier again, or delay transformation to
    Perform.
  - https://github.com/tobami/codespeed can make a web page with perf graphs
  . Signal.sig_op has 4.8% alloc, from Control.cotrol_call ->
    Derive.with_relative_control -> Perform.sig_multiply
    . So default multiplication for dyn is expensive.
  / The Control.put_signal_fragment work is done on a second call to
    a track, even though the output is never used.  Can I fix that?
    . I would need to notice in the collect that there's already an entry in
      Derive.collect_track_signals.  But for that I can't pass an empty
      collect.  I still think it belongs in collect though, because it's
      not an actual data dependency, it just makes it more efficient if it
      is.
    . This is possible now that I thread Collect... well, except it's not
      because Cache clears it.  But in any case, I don't think I can get
      a second call to a track if I am only collecting signals for the
      toplevel block.
  scrolling through giant blocks is slow
    - drawing is stil slow, I'll have to look at the fltk layer
      It happens when the block is wide.  Use test_block to see if it's just
      fltk.
      . It's fltk.  Not alpha draw though.
      Scrolling is weirdly chunky near the top when fl_scroll() is on.
      Curiously it doesn't seem to help at all.
    - Would it be faster to call fl_scroll once for all the tracks?  I could
      also theoretically call find_events all at once too, though that
      shows up low on the profile, so maybe it's not a big deal.
    . The thing is, it seems like fl_scroll doesn't actually help scrolling
      speed at all.  Maybe all the time is spent elsewhere?
  - look into Debug.Trace.traceEventIO to see how long various things take as
    in http://www.yesodweb.com/blog/2012/10/future-work-warp
  - Store signal chunks in the Ui.Track so they can be directly emitted.
    This is only useful for large chunks of 'set' calls, probably recorded
    from MIDI.  So it's probably not pressing until that feature exists.
    . make Ui.Events into 'Map ScoreTime (Event | Chunk Signal)'
    . collapse chunks of adjacent 'set' calls into a Chunk
    . track_derive on a Chunk just returns the contents
    . fltk event render should detect too dense events and omit them, rely
      on the signal render
    . UI edits should see the Chunk expanded out as Events.  Inserting an
      event should modify the chunk or split it depending on if the inserted
      event is a set call or not.
  Cmd
    - If a msg aborts or doesn't run any cmds, don't bother to run diff.
      Except that hardly ever happens if I do shortcut thru.
    - cache track cmds for each track, update when the track title or skeleton
      changes
  Derive
    - parallelize derivation
    AppendList / MergeList for Derive.Stream
      - switch to AppendList and try to get garbage down
        Avoid copying sublists returned by block calls and cache hits
      - play from cursor is a linear scan on all events from the beginning,
        seems like this would be faster if I could skip chunks.
      - see if a Merge constructor can reduce copying
      - can I cache length and range in AppendList?  does it matter?
      - insert parallelism?  maybe the evaluator can do that when it sees
        Merge?
    - lazy signals
      - check out 'at' and 'bsearch' occurrances and see if they can use tails
      - There are lots of lookups in the tempo map
    - see if making a version of Derive.local that's non-monadic in the
      modifier has any effect on performance
    derive cache
      - can I cache long blocks by slicing them if they're >n?
      - c_block should only cache if the block has > a certain number of
        events.
      - I won't rederive cached generators if they have control damage outside
        of the event range.  But there's nothing stopping a generator from
        reading ahead or behind... come up with some kind of solution for this.
    - fair amount of garbage generated by SignalBase.bsearch_above, I think
      this is because it has to box the values when it pulls them out.  But
      it's really just comparing to a Double, so I should be able to do the
      operation unboxed.  But decide about lazy signals before going nuts on
      this.  If I revert to linear search then none of this is necessary.
    - at_linear is called a lot by compose, by compose_warp, by d_warp
      can I make this more efficient?

fltk:
  - When multiple marks from different marklists are in the same place, their
    text collides.  The one from the first marklist should take precedence,
    as should its line.  This is visible when I add logical range markers.
  - If I wrap text, and there is then space available on the right, check if
    I can squeeze in ranked text.
  ? There's an extra axis of information in the width of the event body.  How
    could I use that?
  - Text in negative events doesn't wrap.
  / if I add a track and then undo, I get
    assertion: <assertion failed at fltk/TrackTile.cc:257 track_at(): '0 <=
    tracknum && tracknum < tracks()'>
    . can't reproduce this now, but I have a stack trace now
  - It would be nicer if WrappedText could take an always_wrap=true flag to
    make it wrap even when there's no space, for edit input.  However, this
    would complicate the wrapping algorithm and would mean I have to store
    breaks explicitly, instead of just replacing '\n' with ' '.
  - add edit and windows menu to all apps
    There must be special OS X support for these
    Apparently not?  iTerms is defined in English.lproj/MainMenu.xib
    https://developer.apple.com/library/mac/#documentation/Cocoa/Conceptual/WinPanel/Tasks/UsingWindowsMenu.html
    But it doesn't say how to add the Window menu.
  drawing artifacts on retina:
    . Some of this may be fltk bugs.
    - tops of tracks and the tops of track text boxes still get gunk, visible
      when scrolling horizontally
  - Should fltk collapse adjacent dividers?
  - bug: There's a focus bug, but I'm not sure how to reproduce it.
  - I could set certain Symbols to stretch to the length of their event, this
    would yield a nicer looking score.  But it would mess up the bounds
    detection.
    + gmail: subject:(scaling text)
      But it's OSX only.
  - figure out how to have a minimal title bar in os x (win.border(0) removes
    it altogether)
    I can set something like kUtilityWindowClass in Fl_mac.cxx:Fl_X::make, but
    it doesn't get any kbd input
    . can I get fltk to omit the jellybean buttons on the window?
      . Yes, but requires hacking fltk.
      . Completely disables resizing.  Apparently this is hardcoded.
  incremental redraw / scrolling
    . I don't like the current situation of incremental redraw and scrolling.
      It's also buggy, i.e. one pixel difference between scroll and redraw.
      Get rid of damage and redraw everything every time.  Then I have to make
      it fast to fetch the data for one screenful.  What makes that slow
      currently?
    . Entirely turned it off, speed seems acceptable.
  Track
    / dividers can have separate color for upper part, for collapsable tracks
  + Disable application persistence for fltk apps:
    http://oleb.net/blog/2011/07/whats-new-for-developers-in-lion-part-1/
    http://developer.apple.com/library/mac/#documentation/General/Conceptual/MOSXAppProgrammingGuide/CoreAppDesign/CoreAppDesign.html#//apple_ref/doc/uid/TP40010543-CH3-SW26
    Can then re-enable ~/Library/Saved Application State.
    . Did the objc call, but doesn't seem to have any effect.

  control track, render signal
    - render option: solid with color gradient
    - combine multiple signals, e.g. one controls xpos, one controls color
      I could combine pitch and dyn.  This is appropriate for the note track.
      . I'm pretty sure OS X can do this, as can cairo, so I would need to
        figure out how to get direct access to that API.  I could get rid of
        the awful alpha_draw.cc hack while I'm at it.
      . Or perhaps I should just switch to OpenGL?

logview:
  - use Fl_Help_View and HTML to display text
  / Adding new log msgs causes the status bar to shrink back to one line, even
    though it should be wrapped to two.
  + Logview got some kind of file locked error, presumably trying to track
    a rotated log.
    . It happens if the write handle is still open, for some reason
      Posix.getFileStatus then gets openFile: resource busy (file is locked)
    . But I also got:
      . logview: ./log/seq.log: openFile: resource busy (file is locked)
      . Apparently not caused by log rotation.  Maybe if it checks for
        rotation at the same time a new line is written?
  - can I get the standard edit menu and copy/paste?
  / haskell and c++ use the same machine readable format
  - tabs are not lining up properly
  - option to wrap lines or not?
  - hide or display various attrs: date, file, function, ...

Ui:
  Track
    dense sampled signals
      . efficient storage, preferably as a Signal so no conversion is necessary
      . display dense signals: omit text and trigger lines when zoomed out

test:
  - Integrate_test.test_block_integrate is flaky, sometimes I get:
    __-> Cmd/Integrate_test.hs:48 [test_block_integrate]
    ((bid "test/b2"),
     [(">s/i1", [(0.0, 1.0, ""), (1.0, 1.0, "")]),
      ("*", [(0.0, 0.0, "4d"), (1.0, 0.0, "4c")])])
      /=
    ((bid "test/b2"),
     [(">s/i1", [(0.0, 1.0, ""), (1.0, 1.0, ""), (2.0, 1.0, "")]),
      ("*", [(0.0, 0.0, "4e"), (1.0, 0.0, "4d"), (2.0, 0.0, "4c")])])
  - If I abandon ghc 7.8 compatibility, I can use ImplicitParams for call
    stack
    . Get rid of _srcpos variants and hspp for Util.Test and 'throws'
    . Extracters like 'expect_right' can use failure instead of throwing an
      exception.
    . This means I don't have function names, which is kind of useful for
      tests.  How can I get the name from the test runner to the equal
      function?
      . Another implicit parameter, but that would make calling the tests
        annoying.  I don't think I can make implicit parameters optional.  But
        perhaps I could put the 'let' in the .ghci?
      . Making tests 'ReaderT String IO' would also make calling tests
        annoying.
      . Mutable global variable?
      . However, if tests are not in IO, I can also make pure tests, e.g.
        TestT m ().  Now I can have them return their results instead of
        printing.  If I ensure it's lazy I can still see where any wedge
        happens.
        . What's the benefit of this?  I can parallelize without worrying.
        . Getting totals of tests and checks run becomes trivial, don't have
          to grep output.
        . But I need to separate IO-using tests, e.g. test_io_xyz, and they
          need liftIOs.
      . If I make tests have type (?stack :: CallStack) => IO (), then I can
        get the caller name from the next stack frame.  Unfortunately, all
        tests would then need explicit annotations, which seems error-prone.
    . Also all of those functions that have a 'caller' arg can use implicit
      params.
  criterion
    / it seems unreasonably fast, why is it so much faster than in seq?
      . 5us for 128 events, plus no_invert is slower than invert?
      . And shouldn't perform for invert and no_invert be the same?
      . Maybe I should force the track signals too?
      . 'seq' was being slowed down by startup overhead.
    - score from a file
    - parsing
  complete quickcheck derive testing
    I switched back to Double for RealTime, but this means the roundoff errors
    are back.  Use quickcheck to repro them.
    + make a simple deriver that creates event and midi output skeletons
    - integrate quickcheck with generate_run_tests.py
    - assert that the reduced deriver output equals the simple deriver output
    - basic pitches: If the score was created with notes aligned to note
      starts, then every NoteOn should have the appropriate key, there should
      be no pitch bends, and "same note" should be the only reason for
      a channel split
    - basic controls: Given randomly placed control events, notes have the
      correct control curves.  Don't worry about times or midi.
    - slicing: Given some simple note transformers (tuple, place, ...),
      pitches and controls are still associated with the right notes as above.
      Don't worry about times, just that the right notes and the right
      controls.
    - block call property: a couple levels of nesting for block calls, notes
      still have the expected pitches and controls as above
    - inversion: as 'basic pitches' and 'basic controls', but controls are
      below the note tracks, results should be the same
    - stack: generate nested events, check that stack is as expected
  - count number of tests in addition to checks within each test
  / use generics or Foldable or something to write a generic StructEqual
    Doesn't seem that appealing, since I'd have to deriving Generic on
    everything, and the diff oriented one seems to be ok.

midi record:
  - implement
  . Ideas for editing recorded MIDI:
    . control: realign attacks, smooth or sharpen attacks.
    . pitch: retune intervals, fix wrong note or add notes, change portamento
      speed.  Add, widen, or narrow vibrato.

REPL: repl:
  - bug: repl: SaveFileChanged
    repl: thread blocked indefinitely in an MVar operation
  / If there are ambiguous packages exposed, e.g. both
    regex-pcre-builtin (wrong) and regex-pcre (right), then the repl will
    show 'Exception: Cannot add module Cmd.Repl.Environ to context: not a home'
    Presumably it gets confused because I don't put the -package-id and
    -package flags into ghci-flags
    . Presumably using a sandbox would fix this.
  / Even though the shakefile tries to support multiple versions of packages
    via 'cabal configure', I think they can still cause problems with ghci
    loading.  This manifests as a long hang starting up while the repl
    bytecode compiles a bunch of modules.  Perhaps build/*/ghci-flags needs
    the full -package-id treatment.
    . Obsolete if I use a sandbox, I think.
  - only write history when the cmd succeeded
  - command to open the haddock for a module
  - haskeline sucks for long lines, add multiple line editing?
    really I'd prefer plan9 style esc then edit
  - is Cmd.Lang.Fast now obsolete?
  - can I get local variable bindings (let x = ...; y <- ...) to work in the
    REPL?
  - tab completion for symbols like in ghci
    I'll need a list symbols cmd which the repl automatically sends on tab
    completion.
  - :compile cmd that turns on compilation for everything except Environ
  - :browse to look in modules... can I use GHC.getBindings for this?
  - :module cmd to move evaluation context to a certain module, maybe I
    could also get rid of the need for Cmd.Lang.Environ to import everything.
  - functions to load string serialized tracks for event cut and paste
  - an aux data input for the lang socket might be useful, to paste in data
    without having to quote it

Cmd:
  - Figure out exactly what bad things could happen because of the
    Ui.fltk_event_loop race.  Also figure out what kind of cancelling I'd need
    to fix them.
  + Write a fancy tile like ViewConfig.horizontal_tile but guesses if you mean
    to tile vertically.
  - Create tempo by "stretching", i.e. select start and end, and create tempo
    mark that will cause the start point to be played where the end point used
    to be played.
  - give Cmd.ModifyEvents.Track the ability to change the track title?
    Cmd.Repl.LPitch.change_scale and to_relative could use this.
  meter / timestep
    - timestep 64*2 skips two 's', because 's' is the minimum match
      skip should be ignored when the match is a larger rank than exists, or
      maybe step should fail.
  - Can I give Cmds their own state without putting it in Cmd.State every time?
    At worst I can have 'Map.Map String Dynamic'.

    Use existentials:
      data forall a. Cmd = Cmd {
        cmd_func :: a -> CmdT (Status, Cmd)
        , cmd_state = a
      }
    This means that such cmds have to be able to be updated after they are run,
    so the cmd lists have to be kept in responder state.  If I'm going to do
    that, why not have cmds optionally return a continuation and handle state
    that way?

      cmd msg = do
        state <- stuff
        return $ continue $ \msg -> do
          more stuff

    Or if I can put it in the monad:
      cmd msg = do
        state <- stuff
        msg2 <- yield Cmd.Done
        more stuff

    For module level, each module of cmds would have to export a bunch of Cmds
    and the responder retrieves the state and passes in another layer of
    StateT, or directly.  I supposed Dynamic wouldn't be so bad for that.  What
    happens when the module is reloaded?

  ruler:
    - meter type and the construction functions should be integrated more
      tightly
    - LRuler.inject, opposite of extract, replaces sub-block rulers
  Cmd.Edit
    - alternate finale-like note entry: hold down step key to set step and
      turn on edit mode, but only while the key is down
      (merge will clip them to the next event)
  copy / paste / Clip
    - clip block should use the ruler, just to make it easier to look at
    - clip could also copy over the skeleton
      It could use it to make sure the paste is compatible, but that might
      be more of an annoyance than a convenience.

  Undo:
    - shift [ and ] undo and redo zooms.  or one key to toggle last zoom?
      . record view changes, at least zoom / scroll so it can be undone
        and redone separately
    - Suppressed undo for val edit is surprising since I tend to do a lot of
      edits without leaving val edit.  Maybe don't do it for pitch val edit.
      Try going back to using the name to suppress, but ignore cmds with no
      name.
    - Add a "revert within selection" that searches backward for the last
      change within the selection.
    - Along those lines, should each block have its own independent history?
      This is supported naturally by the git layout since each block has its own
      file.  Wait, actually it's track, and that would be awkward if I undo one
      block and it changes tracks on another.  How do a say what position
      a block is in the history in that case?
      . One appealing thing is that I don't necessarily want things like config
        changes to be included in undo.
    - Visual display of undo history, because stepping back one-by-one is
      a bit of a hassle.

local definitions .ky:
  - define functions with arguments in .ky?
    sd x y = from=$x | drop $y

Derive:
  sekaran
    How to apply sekaran?
      . >hang -> sekar abab -> notes
      . I want to change the pattern, so the problem is how to set an env
        var for a range on one track?
      . I can add a 'sekar-pattern = abc', but I need to repeat it whenever
        there is a gap.
  fancier randomization
    . How much a note differs depends on its neighbors, so it's not an even
      distribution.  Use brownian noise, or a fractal subdivision scheme.  But
      it's also constrained in how far it can wander from the base value.
      Regardless, I think this means I need history, so it can't be
      a stateless control function.
    . Divide on instrument and hand, so each part gets its own individuality.
    - randomization should be centered on a value, with variance as a signal,
      so I can turn accuracy up or down.
    - Randomness could have some hysteresis, so I can e.g. reduce omit chance,
      but not get isolated notes.  At the extreme setting, it means it turns
      on in a slightly random spot, but stays on after that.
      . Is there a simpler way to get this effect?
  tracklang: TrackLang:
    generalize sub-event calls
      - Generalize sub-event calls so that they can also take block names.  This
        is just another way to write sub-tracks, perhaps more convenient if
        I want them to be independent.
      - Also generalize them so if I put it as a transformer in a track title,
        the track is treated like a sub-event call.  This way I can apply a
        transformation to the whole track without needing to wrap it with an
        event.  Paired with the Sub.modify_notes macro feature, I can have
        a track with its own little language, e.g. pakhawaj bols.
        . Could do this by making 'ctx_sub_tracks' available in the track title
          call.
        . I think there were calls in Prelude.Lily that would be interested in
          a more defined distinction between track and note level transformers.
      - Could also do a block-level thing.
    - Perhaps I should have a separation between "" as called by Util.note by
      other calls, and "" as called from the track.  The problem is that it
      applies Flags.can_cancel at TrackTime 0, which is only appropriate for
      a direct call from the track.  This is the reason for
      Gangsa.realize_notes.remove.
      . Flags.can_cancel is now obsolete, but maybe the issue still stands?
    - I was confused because I wrote '%just-base = (nn (c3))' instead of
      '%just-base = (hz (nn c3))'.  Can I use type tags to catch that sort of
      thing?
      . Hz doesn't have its own type, so it winds up being Untyped.  But any
        type can coerce to Untyped, so it can't complain if you passed NN.
        I could make Typecheck Double require Untyped, but that would break all
        the stuff that doesn't care about types.
      . Ultimately, this is because pitches take a PitchConfig, which takes
        ControlValMap, which is untyped.  I started a branch making it typed,
        but eventually lost interest since it seemed overly complicated.
    - Rethink if I really want track event calls in TrackTime, rather than
      normalized time.
      . Implementing c_sequence I was confused how stretch was applied twice,
        since Eval.eval_quoted doesn't normalize the event duration.  Same
        problem is in Gamakam2.  It's error prone that you can place the note
        via both Derive.place and via the Derive.info_event.
      . On the other hand, working in TrackTime is convenient, e.g. in gangsa
        norot I can place notes based on the passed-in dur.  If it were
        normalized, I'd have to unwarp back to TrackTime... can I even do that?
      . Details are also in "Derive.EvalTrack".
      . Adding the repeat call was unintuitive because deriver placement is
        unintuitive.
        . Ideally I could just say (0, 2), (2, 2) and it would work.
          Instead, I get (0, 8) and (2, 8)
          This is because the block isn't normalized, so stretch by 2 makes it
          4, then the stretch by 2 for the event goes to 8.
        . This is so that just 'deriver' by itself gets it right.  If I instead
          made deriver always normalized, then the above would work, but
          I would have to do 'Derive.place (Args.start args) (Args.duration
          args) deriver' to avoid it always showing up at 0-1.  And actually,
          I couldn't do that from a transformer, because what about the next
          transformer?  I should instead have each transformer be in
          normalized time.  'repeat' becomes
            [Derive.place start (1/times) | start <- Seq.range_ 0 (1/times)]
        . For blocks, it's actually almost that, except I have to translate
          back by the start time first.  This is because blocks are already
          normalized to the event duration.  I think?
    Typecheck coerces to TypedFunction as a common signal type
      - It turns out this is not so useful because a default TypedFunction
        doesn't have a default control name like a Sig.typed_control does.
        The documentation is also worse.  The way to fix this would be to
        let the default be any coercible type.  But to do that and be type safe
        I'd want a separate class for pairs of types that can definitely be
        converted.
        . Possibly a way around is to include ControlFunction in ControlRef...
          but why do I want so much to pass control functions?  Especially since
          I can already pass a concrete signal as a ControlSignal.
    - if I had a boolean type, I could generalize calls in Conditional:
      . when-e key -> when (env key)
        when-e key val -> when (= (env key) val)
      . when-c 1 cont -> when (= %cont 1)
      . if-c< cont 1 a b -> cond (< %cont 1) a b
      . However, they get more wordy, so maybe I don't want it.  E.g. for
        cond I'd actually want a 'switch %cont' and then I need either
        partially applied functions, or just write 'switch<'.
    - replace VAttributes with a general purpose VSet.
    - maybe use {} for quoted, it's a bit shorter than "()
    - there should be a character that triggers a parse failure, which is used
      by invalid ShowVal instances like ShowVal Pitch
    - it's confusing how some calls expect env vals like 'x = 1' and some
      expect controls like '%x = 1'.
      . The obvious way to solve this would be to merge env vals and controls,
        but that's a big change.
    - Track caching is too fragile, if I add a track with scope over everything
      then I get no caching.  Instead I should cache the bottom note track, or
      perhaps every note track.  But that doesn't work because they're all
      sliced up.
  Derive.Sig:
    - Support pairs, e.g. a list of pairs of arguments.
      . many_pairs :: (Typecheck a, Typecheck b) => Text -> Parser [(a, b)]
      . Can I generalize to triplets etc. without a separate function for
        each?  Also, could I reuse many / many1?
      . Can I have a Typecheck instance for (,)?  No, becaues it comes from
        a single Val.
      . I would have to turn Sig into a real parser.
    - Try writing a new Typecheck / Sig which is a real parser.  It can have
      backtracking and nested parsers.
    - if I add an Alternative instance to Sig.Parser I can write arg parsers
      like 'Sig.many xs <|> Sig.many ys'.  I think.  If I wind up with something
      else like Derive.Call.Val.num_or_pitch it would be worth trying out.
      . E.g. Conditional.c_if_c takes: Symbol (Number, Quoted)* Quoted
      . Implement empty as pure (), then (<|>) should try left and if it fails,
        try right.  Doc is (x | y).  'some' and 'many' are like Sig.many1 and
        Sig.many, except they have to backtrack.
      . But derivation may evaluate expressions and check the type after that.
        Do I really want to do that with backtracking?
  postproc
    performance details / humanization
      - irregularize runs based on fingering patterns, e.g. groups of 3
    - retune a note depending on the previous interval (e.g. sloppy pitches
      when playing quickly)

  - consider track calls and block calls:
    note_track :: TrackTree.EventsNode -> Derive.EventDeriver
    derive_tree :: ScoreTime -> TrackTree.EventsTree -> Derive.EventDeriver
    I could use this to implement is-ly and no-ly, and also totally custom
    track types and block types.

  tempo track:
    - Nested tempo tracks at the toplevel block should normalize like they do
      when called.
    - Nested tempo tracks are probably broken for hybrid and absolute tempo.
    - Nested tempo tracks are probably also broken with a logical start.
  note calls:
    - retune call: differences based on speed should be more obvious, so that
      should also be on a curve.
    + chord calls, with automatic dyns for the notes.
      Originally I intended each note to go in its own track, with the idea
      that it takes about the same space but is more powerful and flexible.
      But it's not quite true, because the extra track is there for the whole
      block, though perhaps that's a side-effect of having blocks which are
      too large.  More compellingly, chords can automatically fiddle with dyn
      and start time, and can also interpret chord symbols.
    mridangam:
      - Perhaps mridangam should automatically transpose the octave to be within
        its range.
      - tha is too loud... I can compensate by using -, but maybe the scale is
        off.  Velocity should be logical, so if you play all at the same
        velocity it's like the same dynamic for all strokes.
        . Or I could make + be 0.5, and * be full volume.
      - perhaps only pitched notes should change with the tuning?
      kanakku:
        . I could come up with a notation for various transformations, but it
          would have to be its own little language, due to the time aspect.  Or
          just write haskell.  Furthermore, they're only useful so far as they
          allow me to easily experiment, otherwise I might as well write them
          out by hand.
        . There should also be performance rules for variations, e.g. tk can be
          played kk.  These can also apply to pitch instruments to make a pitch
          contour more natural.
        . If I realize a pattern in score, it should retain the structure, e.g.
          [p5 p5 p5] 2 [p5 p5 p5] 2 [p5 p5 p5] can emit each p5 as a sub-block.
          If it uses a standard name, it can reuse an existing one.
        . Conditional derivation that depends on position in the tala, e.g.
          thali / khali.
        . reduction / augmentation: repeat a pattern, clipping either a constant
          time or one note from the beginning or end.
          . It could be a transformer, but it seems like conceptually it seems
            like it wants to be a score level transform that takes 'p' to 'p'
            'Clip p' etc.
        . multiplication: internal section repeats
        . shell game: take time from one place and add to another
      . I can write them down in a specialized language in the source, and then
        they become a module with call names.  If I want to edit them, I can run
        a cmd to materialize as a block.
      Higher level notation that uses durations.
        . Then a layer maps them to patterns in a specific instrument.  This way
          I can also map to different instruments.
        . This seems too vague to be useful.  Just duration is not enough to
          capture much interesting about the pattern, but solkattu doesn't have
          a predictable mapping.
        . On the other hand, I could give duration, and then the actual
          pattern is random.  But I'd still want a way to restrict to the same
          pattern, e.g. use a variable, so all 'a's get the same pattern.
    pakhawaj bols
      . Score integrate to convert bols to low level calls
        . Actually score integrate doesn't work like that, it just copies the
          input.  It would have to be derive integration.
      . Or maybe just interpret the bols directly, but due to context
        sensitivity they need to be all processed together, not as separate
        calls.
        . In general I don't have a way to interpret a track as a whole.  This
          is the "track call" thing I was thinking about a long time ago.
      * Implement pakhawaj bol realization as a sub event call to make sure it
        works.
      - Add an input mode for bols.
    bali:
      - add isep to *legong
      If I put pemero notes in legong, then I can play them when needed.
        But what should they be called?  i o e e# u a a#
        - pick better nns for 4 and 7
        / add 'lebeng' key with 1234567 cipher notation
          . This is a bit tricky because the PCs per octave changes.
        - dotted cipher notation should use 4 and 7 instead of 3# and 6#.
      kotekan
        - negative events are convenient for the pitch, but sometimes I still
          want to control the final note.  Maybe I could still use positive
          durations, but take pitch from the end?
          . That doesn't work because slicing uses a negative event to include
            the end.
          . Maybe I could include control calls if they are -0?
          . Actually I don't understand why the negative event gets the next
            control.
            . It's because slice goes from start--next_start, which happens
              to be correct for negative events.
          . I would need Control.trim_signal to include the sample at the end,
            buts its whole job is to trim that one off.  So I think I need the
            negative duration on the event as a way to signal that I want the
            controls after the event, not during it.
          . If I did the thing where negative events are edited at their end,
            I could have a positive note at the end of a negative one.
            Negative becomes more of a flag on a note to tell it to draw and
            slice differently.  The tradeoff is that I can no longer put a
            positive note at the start of a negative one.  Even if I did, it
            would have to be zero duration and have its duration inferred.
          . The other option is to just use the "next pitch" feature to make
            kotekan calls depend on the next pitch instead of the current one.
            . This doesn't work because next pitch only works in a pitch
              track.  To make it work in a note track I'd have to evaluate the
              whole next note, or have an entirely separate way to get the
              next pitch.
            . Actually I now have this, via NotePitchQuery.
        kotekan kernel:
          - generate all possible kernels following some playability rules,
            e.g. no more than 2 notes in a row, only one rest
            . I could then use that to automatically select a pattern for
              a given destination, with some constraints like playability from
              the previous pattern (no fast jumps), above vs. below, telu vs.
              empat.
        - in Gangsa.realize_kotekan_pattern, pass Nothing as the start to not
          limit the start
        - inst postproc can interpret +mute as either just a mute, or open, or
          in between depending on %mute.
          . Then I don't need a configurable mute for
            Gangsa.gangsa_norot_arrival.
        - control for noltol +mute dyn
        - gender norot: control for polos 234- vs. 434-
        - an optional special pattern which switching between kotekan and back,
          e.g. 112-2-2-
      wayang in octaves
        . pemade: >p=>p-umbang | >s=>p-isep
          kantilan: >p=>k-umbang | >s=>k-isep | %t-diatonic=5
        . I could do it with >wayang-both that emits >wayang-p and >wayang-k. Or
          just call the score twice, once with transpose +1 oct.
        . I definitely want two calls because then kantilan randomizes
          differently.
        . Or I could create the kantilan as a integration of the pemade, so it
          can still be modified. I think this would want a "score integration"
          which just copies and merges the events directly, and doesn't do
          the intermediate derivation.
        . I could add inst aliases, e.g. >umbang = >p-umbang, etc.
          Or a note-track call: '>umbang = "(>p-umbang)'
          This can't be done with call aliasing because it's actually
          'note-title >inst', and anyway wouldn't help with 'inst = >x'.
        . The intended way to do this is have > instrument, and then set it in
          the caller.  But then you can't put >1 inst on the same block.
        . But this way doesn't work if I want differences in the kantilan
          version.  I would have to do correspondingly more copy and paste to
          replace the bit I want to change.
        . Ideally I'd like something like integration: everything is
          duplicated with no extra work, but an integration is available to
          edit.  But it would be a kind of "deep integration", where
          I duplicate the entire structure, from score on down.  Score
          integration could theoretically do that.
      trompong / reyong:
        reyong patch
          * pitch map
          * keyswitches
          * release-vel support
        reyong protocol
          * to damp, set %damp, which the inst postproc moves to %release-vel
          - also in postproc, +mute note gets dur=0, %dyn=0, %damp=dyn
          - How to set open or closed mute?  I need to send the ks from the
            attr map.  It's ok to send before NoteOn, so I think I can treat
            it as a normal keyswitch, but maybe I have to send +open too.
            . Actually I think this doesn't work because it can't be
              distinguished from a muted stroke.  So maybe I need separate
              configuration for +open+loose-damp vs. +open+tight-damp.
              I can also add a couple extra keyswitches for just +mute.
        - dit-thom call
        - two handed +cek call
        - general %damp inference, e.g. two notes with the same pitch
          shouldn't damp.
          . Also %damp gets louder when notes are closer, or faster.
        * reyong-damp emits notes with +mute.  So I have a stream of notes
          where starts and stops are explicit, and each note rings until a
          +mute of the same pitch.  If the instrument uses NoteOffs, I have to
          translate that to merged notes.
          . Or could I emit a more easy form?  E.g. give notes a duration,
            a possible +damped attr, and a note-off-velocity.
          . If I have +tight and +loose damping and switch with a keyswitch
            then this is a new form of keyswitch.
          . On the other hand, if I can make it a non-interfering keyswitch
            then I think I don't have any of these problems.  But that would
            have to be poly at.
          . Transform: reyong-damp adds a %release-vel control instead of
            +mute.  If it doesn't have one, extend the duration until the next
            note with the same pitch.  Or emit release vel of 0 and have KSP
            not stop the sample on release vel 0.  I can use release vel 1 for
            damp, but without a sample.
          . A problem with using NoteOff is that I want to be able to do
            multiple NoteOns without damping.  If Kontakt were flexible
            I could just emit unbalanced NoteOn and NoteOff but I have to
            figure out if KSP can replace the usual note allocation stuff.
            . Track the last note for each pitch.  If I see a NoteOff with
              non-zero velocity then play the damp sample and cut off the
              sounding note.
        - split to ngembat, e.g.  λ 人 hmm, is there a reverse lambda?  Can
          I draw symbols reversed? 入 兩
          . There are several ngembat variations: fast:
              5 61    35 61
                 1        1
            slow:
              561   53561
               21      21
        - various numpuk
        kilitan
          - pickups can mute
          - kilitan patterns change over a speed threshold
          - variant patterns, e.g. p1 on dong
          - write an alternate style of kilitan, e.g. with a 6 note scale in
            tisram
      gender:
        - rambat damping emulation: notes ring on by default until they can be
          damped.  Damp at the first opportunity, where opportunity is defined
          as a break with no notes for a certain amount of time.  Can only damp
          two neighboring notes at a time.

  pitch calls:
    - 'smooth' pitch transformer

  control calls:
    - signal transformations: +, *, max, min
    - saturation limit, e.g. flatten sine wave but without clipping
    - continuous tempo warping for signals
      tempo: "2" -> "1", "2", cont: "2" -> "i, 1", should emit a bent line

  control functions:
    - Could use rank to modify dyn and emphasize or deemphasize notes on
      important beats.
    . With 'real' and 'score' and the signal conversion functions, I gradually
      rewrite more and more functions from Deriver to functions with a
      TrackLang.Dynamic argument.  Also they're going to start to want an
      exception, and why not logging too, and I'm right back to Deriver.
    . Why can't I make ControlFunction into a Deriver?
      ControlFunction moves to Deriver.Monad, so Val must also.
      Now control function stuff must be exported from Deriver, not TrackLang
      and Score.  But also Val can't be exported from TrackLang, and there are
      tons of users for TrackLang.Val.  Maybe I can split TrackLang into a low
      level version.  In fact I already have, everything Deriver uses
      TrackLang for can come from BaseTypes, except Typecheck.  Monad.val_call
      must move to Lib.
    . Environ, Pitch, and Val all move into Derive.  And Score.Event.
      This is getting to be pretty much everything.
    . Another option is to make Derivers polymorphic.  I can put the
      fields in TrackLang.Dynamic in a typeclass.
    + Abstract 'state' and 'err' to a DeriveM, and implement
      type ControlFunctionM a = DeriveM.Deriver Dynamic Text a
      . I can't reuse Deriver, but at least I get logging and errors.

pitch: scales: scale:
  scales / Derive.Scale:
    * Implement staff-notation style accidentals, where accidentals in the
      key signature are implicit, but you need explicit naturals.
      . This is just the same as an absolute scale, except the display is
        different, and needs to the key.
      * I need to differentiate no accidentals from a natural.  I think that
        means Pitch.degree_accidentals has to be Maybe.
        . This seems to have a big effect because now everyone who deals with
          Pitches needs to understand about the scale and key.  Instead,
          Pitches should continue to be non-ambiguous, but the parsing should
          figure out the Pitch based on the scale.
    - I think the symbolic pitch_note functions should use RelativePitch,
      otherwise the symbolic pitch they produce can't be parsed back in to
      produce the same pitch.
      . Demonstrate with some tests and fix if necessary.
      . For ChromaticScales and JustScales
    - TheoryFormat.make_relative_format is a confusing name because it makes
      a Format from a RelativeFormat.
    * TheoryFormat functions have zillions of arguments, can I package some up
      more?  I guess RelativeFormat is already such a package...
    - It's confusing how the default_key is built-in to parse_key but also
      passed separately... maybe it should take a flag to say whether an error
      should become the default?
    - Strip type prefixes from Pitch.Pitch and Pitch.Degree?  Add lenses?
    * Put Controls.octave in Scales.standard_transposers.
      . I would have to make Scales.note_to_call handle it, but then I'd need
        a version that doesn't for WendyCarlos.
      . Not sure if the complexity is worth it, wait until I need it.
    * overtone series
    - add ratio transpose signal, that multiplies hz
    support scales that are different ascending vs. descending
      . Scales have two versions of each degree.
      . scale_input_to_note takes a previous Note arg, which it can use to
        guess the appropriate variant.
      . Variants have to have unambiguous names though, maybe 4n^ and 4n_
      . Use scale_alternate to switch a note between alternates, bind to the
        same key as enharmonic.  If there are no enharmonics, then fall back
        on alternate.
    Raga
      - Support arohana and avarohana by treating them as enharmonics
        Is this really a good idea, since they aren't anything like
        enharmonics?  Maybe I should just use the flip-enharmonic key, but
        keep the concept separate.
        . I could keep it at the Cmd level by remembering the last entered
          pitch and defaulting this one based on it, or I could try to put it
          at the Derive level too by having the pitch itself be based on the
          previous one.
        . Putting it at the derive level seems really hard and unreliable, so
          I should have separate symbols, e.g. 4r^ and 4r_ for up and down
          variants.  For western modes this isn't necessary since the notation
          is already absolute.

    - letter and jianpu but with implicit accidentals based on the key
  intonation: think about how to do e.g. meantone melody, with just harmony
    . Do a postproc to analyze simultaneous notes.  If I use an attr to
      tag the melody, I can tune everyone else to it.  But how do I retune
      notes with non-trivial pitch curves?  Well, I could use a transpose
      signal to tell the pitch calls what's going on.  I think I might just
      need the frequency of the melody note.
    . Do an analysis pass, and insert environment that says what the harmony
      is.  Then pitch calls use that to tune.  Doing the analysis might be
      tricky since I have to extract a "principle pitch" from each event,
      but it might be useful in general to have an analysis framework.

signal: PSignal:
  / The Signal / PSignal divide can be annoying.  If I put them in
    a TimeVector class then I should be able to directly apply TimeVector
    functions to them.  Then, make all TimeVector functions polymorphic, and
    Signal and PSignal can just re-export them.
    . But it seems weird that Signal functions work on PitchSignals, so maybe
      I should specialize them before re-exporting... but that winds up being
      not much less work than unwrapping the newtype.  The advantage is that
      I can write functions generic on the signal, but in practice there are
      few of those.  So maybe I don't actually care that much.

Perform:
  - Overlapping notes with different ControlSwitch cc numbers should share
    a channel.  Of course it'll work anyway if only one channel is
    allocated.
    . Currently they definitely won't, because the performer assumes that
      all controls affect the sound, and so you can't share with any control.
  - Pick the best channel instead of the first one.
    . An event can share a channel if it has different controls but the events
      don't overlap.  This is required so that a sequence of notes that each
      set a different control will go on the same channel.  But since it always
      picks the first usable channel, you can have controls trade channels,
      depending on how the coincident events are sorted:
        [(0, 1, c1), (0, 1, c2), (1, 1, c2), (1, 1, c1)]
      This should put the c1s together, but they will trade channels if they
      come in that order.
    . I think to fix this I'd have to have can_share_chan return
      Left fail_reason or Right priority, and pick the highest priority.
      It would have to give a lower priority to events that could share, but
      have incompatible controls just out of the event range.
    . let f = Perform.shareable_chan
      let mkevent start controls pitch =
              Perform.Event inst1 start 0.33 controls
                  (Signal.signal [(0, pitch)]) DeriveTest.fake_stack
      let pedal = Map.fromList [("pedal", Signal.signal [(0, 1), (6, 0)])]
      pprint (f [(mkevent 3.33 pedal 45, 0)] (mkevent 3.66 mempty 72))

  - I can work around the pianoteq tuning bug by not stripping redundant
    conrol changes.  This also means that recorded MIDI can be played from any
    point.  If bandwidth isn't a concern then why not?
  - damper pedal causes all notes to extend until the pedal comes up, should
    the performer know about that?  Is there anything that this breaks?
    I don't think so, it affects channel allotment so notes could be
    improperly joined, but mixing pedal and multiplexing seems rare enough.
  - Perform.Midi.Perform: should be possible to lead keyswitches as long as
    they don't precede the previous NoteOn, since I think samplers will only
    switch on the next NoteOn
  Instrument
    - some basic midi instrument defs for generic midi (dev, patch)

Instrument DB / browser:
  - Fl_Help_View supports limited HTML, use it to display formatted help
  - browser has lots of empty space on the bottom
  - z1/virus-bass has UnknownMessage for initialization?
  - patch files could go in the Local/Instrument dir with the source?
    at least it should go in source control
  - colorize the info_pane so tags are easier to read
  - search lang supports quotes
  sysex
    z1
      - convert patches to larger pitch bend and send them back
      - I need control over which program and bank the patches go when they
        are initialized.  I can use the card as scratch space.
      - I also need to initialize a new multiset, and give the score
        a multiset config, or derive one from the midi config.
    vl1
      - test sending sysexes back
      - move patches to new format
      - figure out how to set category for builtin patches
        . *word shorthand for category=word?
        but I want to use the inst name, not the score name...

OSC backend
  in doc/dev_notes/sythesizer
  - Write a simple supercollider instrument and try controlling that with OSC.
  - Even if reaktor and supercollider don't understand bundles, I could write
    a scheduler server that takes bundles and emits their msgs at the correct
    time.

jack: JACK: linux midi:
  bugs
    - something is still wrong, I get "no space in output port" and then
      corrupted output
    ? jack1 doesn't work at all: other clients don't see writes, until I quit,
      and then they get continuously spammed.  Apparently the jack_port_t*
      from the registration and the lookup are different.
      - Try stashing port from port_by_name port instead of jack_register_port.
  - does jack not support sysex at all?  Maybe I can't use it at all then.
  - Ensure that shutdown stuff is being called correctly.  I don't care but
    maybe JACK does?
  use jack transport
    I don't think I need to be the master.
    - When starting a play, call jack_transport_locate,
      then jack_transport_start().  The play then blocks on a lock which is
      released by JackSyncCallback when it gets a JackRolling state.
    - Register with jack_set_sync_callback.  JackSyncCallback sets a syncing
      flag, emits a Msg that forces the needed bits of performance, then that
      cmd must call back and reset the flag, at which point the sync function
      can return true.
    Then the next step is to test, and then figure out a way to get ardour to
    automatically set up a bunch of instruments and make MIDI in ports for
    them.

misc ideas:
  . What would a generalized staged evaluation system look like?
    E.g. evaluate note (start, dur) and first pitch track.  Then go through
    again and evaluate the rest of the tracks.  The second time the
    neighbors are now incomplete Score.Events with timing and pitch.
    I would also flatten out the block structure and cancel weak notes so
    I have access to true next and prev.  This implies some way to stash the
    unevaluated tracks in the Score.Event.  Then a postproc pass would go
    through and evaluate again, providing new context to the unevaluated bits.
    . I already have something vaguely like this in the Inversion dynamic
      state.  I can provide new context with Dynamic... though it would be an
      essentially untyped way to do it since there's no type difference
      between the first and second evaluation.
    . At the moment I don't need a generalized solution, so I could just
      hardcode:
      event_stage2 :: Maybe (([Score.Event], [Score.Event]) -> NoteDeriver)
      Then at conversion time, any event with an event_stage2 is replaced by
      its evaluation.
    . Conversion isn't quite right, because I still want next event on track
      etc... but actually no, I've been here before.
    . Then I need some way to specify notation that wants to wait until
      conversion.  I guess it would go by track, so maybe a magic symbol in
      the track title.  Then slicing separately returns slices from those
      tracks.  These still have to be evaluated in their original environment,
      so I then wrap in a derive_tracks and store as a NoteDeriver.
    . So I think this could work... but is it really worth it?  It seems like
      it introduces a whole new level of complexity.  And, if I go the
      typesafe route, a whole new type of calls, which a new accompanying
      namespace.
  . Import or trace curve from a pitch tracker into the pitch track.
  . Staff notation represents chords well, but tracks don't.  Think of a more
    compact notation.
  . Why can't I write a 'tr' that generates pitch signal in some cases, and
    adds an attribute in others?  It would be redesigning control tracks so
    they are just note tracks that slice their children and apply
    a transformer to them.  I'm not sure that will coexist with the curve
    description language that control tracks currently implement.
    It would be interesting to get rid of track types entirely though.
  darcs to git:
    . https://github.com/purcell/darcs-to-git
    . http://darcs.net/DarcsBridgeUsage

planning / research
  text oriented score:
    . This is a pure-text score notation.  It renders down to tracklang, but
      because it's just text there has to be more complicated mechanism for
      rhythm.
    . It should also support sub-languages, e.g. pakhawaj bols.
    . There could be a text based interface that either uses a REPL or a text
      file.  This would be basically just 'seq' without any open windows.
    . Scores in this notation should be fully compatible with tracklang, and
      it should be possible to integrate into a block.
    . However, it can represent things that are awkward in the gui score,
      such as truly per-note controls and lots of use of parent tracks.
    . Syntax examples: lilypond, https://github.com/alda-lang/alda
      MML: http://www.nullsleep.com/treasure/mck_guide/
    . Mridangam: http://korvai.org/notation/notation-html/index.html
  cmj:
    - bezier-spline-modeling-of-pitch-continuous-melodic-expression.pdf
      Contact Bret Battey about PICACS: http://www.mti.dmu.ac.uk/~bbattey/
    - Wendy Carlos' tuning article: "Tuning at the crossroads", CMJ 11/1
  things for expressive music
    There needs to be some way for notes to affect surrounding notes.  For
    example
      . A trill might want to push the next note back a bit so it can complete
        its cycle.
      . Portamento might want to put controls points on a curve, so the speed
        a distance between pitches affects how quickly they approach, and
        quick notes will have less accurate pitch.
      . Gender tick affects the damping of the previous note.
      . If I control uses bezier curves, the curve is determined by the last
        control point of the previous and the first point of the current call.
    Other ideas:
      . Switch samples when played quickly.
      . Drum thing where successive strokes lose some energy.
    . Randomization is a first step, but true variation in playing is not
      random.  Things to study:
      . Tempo variation.  This is related to intentional tempo variation, but
        there should be slight tempo variations all the time.  This also has
        to do with higher level controls like rushing or lagging, and slight
        amounts of swing.
        E.g. some instruments may tend to rush when they want to be more
        prominent, or get louder.
      . Start / duration variation.  Related to tempo but at a lower level and
        less systematic.  Interpretation of staccato depends on surrounding
        tempo.
      . Dynamic variation.  Many instruments tend to get louder at higher
        pitches.  Tempo speed up tends to increase volume.
      . Pitch variation.  Some instruments tend to attack inaccurately and
        then correct.  Higher dynamics and tempo could make pitch less
        accurate.
    Modelling notation as a set of constraints:
      Notation specifies parameters along with how "fixed" they are.  For
      example, specified pitches are usually immovable, but onset time might
      be variable, depending on how important the beat is.  Higher level
      notation then assembles components and combines the constraints, and
      results in either conflicts, or a set of more specific constraints.

      . Example: janta attacks from below, normally one diatonic step, but
        avoids repeating the previous note.  A trill can end on either low
        or high, but if followed by janta, will change to avoid making janta
        repeat a note.  If trill speed is unfixed, it can change that,
        otherwise change attack time of the following note.  If the trill end
        is fixed, then the grace note must adapt by picking another higher
        note.
      . Carnatic ornaments change when time is reduced.

  think about grammar for ornaments
    . Notes have a syntax: there are ornaments or articulations only valid at
      the attack time, ones that apply to the sustain, and ones that serve as
      transitions to the next note.  Also, the shapes of ornaments vary based on
      the note or absence of a note preceding and following, in addition to the
      speed.  It makes me think of cursive Arabic, where letters change shape
      and placement based on the previous letter, along with rules about which
      letters go where in the word (I'm sure linguists have a name for this,
      e.g. English has "ng", but won't start a word with it).  I've noticed
      there's a tension between specifying exact times via a timeline or
      whatever, and the kind of higher level flexibility implied by a syntactic
      approach.  E.g. if you say "attack X, sustain Y, end with Z", you are not
      saying exactly when X, Y, and Z start and end, and they are free to
      arrange themselves according to context.  But you do need a certain amount
      of precise control over times, at least in some cases.
    . This is similar to the "constraints" idea, at least with regard to some
      aspects being flexible, while others are fixed.  For instance, if
      I write ornaments with no specific times: 'A; B; C' then the start times
      and durations are flexible, and its up to the interpreting code to
      arrange them, but if I make separate events for A, B, and C, then the
      times are fixed.  Of course I also want to be able to fix A and C, but
      leave B's position flexible.
    . How to represent this as events?  I think I need a "macro" facility,
      where a call can interpret following events as a separate mini-language.
      I used to have this, and could probably get it back, by re-introducing
      the "skip following events" return value.  In that case, some notation
      like a leading '=' would indicate that the start time is fixed.
      Otherwise, the event_start is irrelevant except that it's in between
      the previous and next events.
    . Or maybe I do it as sub-notes, that way the one on the left specifies
      the extent of the "note DSL", and I don't need a "skip following" hack.

  . Composition of score fragments.  Similar to the note grammar thing, this
    is a sublanguage, so I can sequence movements or sections without worrying
    about their timing.  It simply derives each one and concatenates them.
    I could implement it as a "sequence" note transformer call.

  . Give a visual indication of the events emitted by a call.  This is the
    note level version of the track signal render.  The underlying problem is
    that textual call names are not necessarily very clear about what the
    notes are, especially if it's a relatively ad-hoc call.  But I think
    I need a fancier GUI for this, since I'd have to have some way of turning
    a bunch of events into a distinctive looking graphic, e.g. a scaled down
    image of the block or something.
  - spline curve interpolator: evoral/Curve.cpp, www.korf.co.uk/spline.pdf

  - If I implement a VST host or patch a DAW to accept VST controls like MIDI
    controls can I get low latency high res controls?
