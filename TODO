LEGEND
  - todo; + in progress; * done; / obsolete, do not want, or can't repro
  ? open question; . note; bug: marks bugs.
  Use indent folding with indent=2.

STATUS
  . infer gender damping:
  . text score: tscore:
    . Thinking about how to do negative durations.
  - make kendang sampler instrument
    . Make thru work for it, and refactor thru in general.
    . refactor thru:
  + I should set up organized profiling, especially so I can profile before
    and after warp as function, and linear segments.
    . Mostly done, but I think I want to use criterion on some smaller
      examples, since full scores still seems to be really noisy.
    . I have this in the 'criterion' branch.  I investigated using 'guage',
      which has fewer dependencies, but it seems one of those is JSON export,
      which I need.
  - Track down 8.4.1 performance regression.
    . In general I should know what the expensive things in derivation are.
    . It seems like compiles are taking a long time on a certain file.
      . Cmd.GlobalKeymap was 33s, was that true on 8.0.2 as well?
      . Can I get shake to not record 'compilation is NOT required' runs?
      . Or maybe the laptop was overheating.
  - Find out why MemoryLeak latency: went up.

external:
  Can I write a dep-analyzer to answer questions about the module graph?
    . What's the max depth of the tree?  Depth from a starting module?
    . What are a module's transitive deps, and by how many paths does it reach
      them?  The ones with a low count could be trimmed.
    . What are the paths from module A to B?
    . For any of these, do a diff between two git commits.
    questions:
      . If I remove Perform.Signal from Derive.ScoreT, does anyone now have
        fewer deps?  Since I just use it for Signal.Y
      . Or if I add some import, what do I now depend on that I didn't before?
      . For each import, print the number of transitive things it imports.
    can hiedb do this?
      . Not clear, what is reachable and unreachable?
      . What is the schema for the db?
    I can do it with tags?
      . No, it just registers module names, not imports.
    Shake.HsDeps creates an import graph.
      . So does ghc -M, but it doesn't understand .hsc.
        ghc -dep-suffix '' -dep-makefile deps -M App/Main.hs

  record screencast of using karya:
    . show just-r, tuning=limit-5, limit-7
    . sekar, with track integration
    . interpolation, docs with LBlock.doc_equal "i>"
    . show MIDI, im, sc backends
    . using tscore, especially standalone

UNSORTED
  - lrange collided with random range, awkward
  - bug: space right as play gets to the end leads to unstoppable playback line
  - "can't play it's playing" is annoying, how about on play stop the previous
    play and start a new one?
  - bug: things go haywire if I have a vim open when the app quits,
    vim stays running, repl dies of SIGPIPE, terminal state is messed up
  - save/bali is all messed up apparently due to some instrument change
    . add "r" for my reyong to bali.inst
    . gabor has old norots?
    . then put some of them into verify so it doesn't happen again!
  - t-dia doesn't apply to all instruments in
    `multiple set-pemade set-kantilan`
    . visible in save/complete/wayang/zach-angkatan
  * why is kontakt/sc-pemade not getting inst-top inst-bottom env?
    . Because I only inherit the environ if it's Nothing, I don't merge env.
    . But I did it on purpose, I even switched from not having it.  I guess it
      was so I could delete keys, but I think I should do that explicitly,
      I guess via a separate delete_environ?
    . I have a vague recollection that allocate was supposed to copy the
      instrument environ so it would be replaced... maybe I had saved
      bali.inst before that?
    . Commit 4e31d7dd92908e9658d3cca06e0a88d19fad4c64 says:
      The idea is that it's a hassle when a patch change makes a bunch of
      scores out of date, when they just want the default, but it turns out
      the main culprit, patch tuning, is often only in the allocation after
      all.
    . That seems to be an argument to merge though?
  - have LInst.list show settings from the instrument
    . Maybe in a different way to show they are inherited?
  - shouldn't Id.clean do validation and return Nothing?
  - Meters are complicated, hard to understand, and error prone.
    . See ruler-performance:
    . I spent ages trying to figure out why 'make_labeled 1' didn't work in
      Derive.TSCore.Check.
    . How can I simplify things?  But still support meter / tala / gongs?
    . The whole renumber fiasco is a fiasco.  Maybe marklist is too low
      level, can I save the structure in the Ui.Ruler?
  - upgrade to ghc-8.10 on hobbes.
  - upgrade to ghc-9.2.1
    . 9.0 is pretty buggy, wait for 9.2.
    - 9.2.1 has no profiling, wait for 9.2.2:
      https://gitlab.haskell.org/ghc/ghc/-/issues/20707
    + upgrade modules
      - easier to wait for 9.2 in nixpkgs?
      - fclabels, once again it's th, look into th-compat?
        . or maybe switch to microlens, or optics
      - but meanwhile tons of basic things won't build, wait a while
    + cryptohash-md5 doesn't build
      . It's hvr-controlled :(
      . Built it locally.
    . Reverted to 8.10, let's wait for 9.0.2.
  - I want to do vibrato and vibrato depth, but it's a pain to add new tracks.
    . But it should be in pitch, do I have vibrato settings there?
    . Maybe I should use the provided ways though, or at least be able to.
      This is into that problem of control tracks that generate >1 control.
    . Long ago there was a splice idea to change control track titles in the
      middle, but for multiple values, that's what ControlMod is for.
    . What if I have a vib call that emits vib and vib-speed?  This is uneasy,
      like all ControlMods, since it's independent from the control track,
      instead just being a generic control.  If I pursued this to its
      conclusion, then we would just have one kind of generic control track,
      and use names for all the controls.
  - Make Derive.parse_expr invertible
    . I do partial parsing to modify expressions.  Actually I think it's ok
      to parse all the way to Expr Val, since the Vals parsed in here are all
      reversible, but I need to preserve the whitespace.  Or maybe I don't
      even need to do that, I don't mind having a syntax "normal form".
      I think the only questions are spaces around "=" and a trailing comment.
      I could actually preserve spaces in the parsed form, and have an
      explicit value for comments, and then I should have fully reversible
      syntax, which means structural editing has access to the final parsed
      form.
    . This way I can get rid of Parse.split_pipeline, Parse.lex, etc.  I can
      also get rid of the special rules in PitchTrack.PitchCall, buggy
      whitespace fiddling, and structural editing can have a fully parsed
      expression.
    . Maybe I can get rid of ControlTrack.Partial entirely, just use
      DeriveT.Expr!  Or maybe RestrictedEnviron.Val?
    - include comment
      . Comments are special in that they only happen at the end, so I think I
        can change lexeme to be only spaces, and then do an optional comment
        at the end.  This should be more efficient too!
      . This doesn't apply to ky though!
      . Since spaces used to check for --, I now need to explicitly not match
        that everywhere...
    - include spaces on =.
      . This pushes me toward separate Call | Equal constructors, but that
        means I don't have to do the awkward special case with the operator,
        so maybe it's for the best.
    - Verify roundtrip for expressions.
      . Maybe I could clean up parse/unparse.  Unparse could be
        non-overloaded, just invert Derive.parse, with the usual caveats for
        Vals without literals.  Then show_val is Typecheck.ToVal a => ShowVal a.
      . What of MiniVal and RestrictedEnviron.Val?  I guess they'd need their
        own show_val... or just ToVal!
      . I could maybe resolve the toplevel thing by keeping the Toplevel type.
      . Also fix the quotes-or-not?  Str gets them via Text, Symbol doesn't
        get any.
      . Do I still want Symbol/Str distinction though?  Was it due to
        toplevel?
  - Remove duplication between PitchTrack.modify_note and PitchTrack.parse
    . Do "Make Derive.parse_expr invertible" first.
  - rename Pitch.Note to Pitch.Symbolic?
    . Then the problem is that 'sym' or 'symbolic' variable names are generic
      without the pitch qualification.
    . Maybe psym or symp?  Or just call it pitch.
    . What about swaram? Swar?
  - copy paste that understands track types
  green-mold, if I replace "i " "" for "inst=b", derive takes forever
    . Is it possible to get progress so I can see what it's doing?
    . It was because b1 etc. were block names, so it substituted those and got
      too many events.
    . In this case, I wonder if I can show progress, or cancel.  Play will get
      stuck on derive, but be cancelled by the timeout.
    - If I can show a progress bar with number of events / time derived, it
      would give the clue that something is wrong.
      . Also, should I abort if derive takes too long?
  / is there a Factor to glue together two blocks?
    . How about split a block?  Yes, Factor.split_time.  But no join.
    . It would have to match up tracks, which seems complicated.
    . I don't really need it though.
  - bug: logview: error parsing "": can't decode json
    . It should say where in the file this happens.
  - consider switching TrackTime to rational
    . Reason why is if I multiply events by say (2/3) I easily wind up with
      start+dur just barely not lining up to the start of the next event.
      And then since Events are rounded but selections aren't, I get confusing
      behaviour when edit wants to make a new event that nonetheless
      overwrites an existing one.
    . If I had a TrackTime / ScoreTime distinction I could do a conversion
      there, but why not make all of ScoreTime rational?  I don't know any
      cases where they're truly at complicated times.
  - sorted Derive.Stream:
    . Implement the Sorted flag in Derive.Stream
    . I could have calls that can move note starts register by flipping a flag
      in Collect, then the track will set Unsorted.
    . Or just sort it... The Sorted flag is only worth it if I can elide sorts
      because intermediate postprocs don't care.  I might not have that many
      to matter, and List.sort should be efficient anyway on almost-sorted
      inputs.
    . Either that or check for order on each call?  But at that point
      shouldn't I just sort it?  Maybe the most reasonable is to just sort
      each track always.
    . Then MergeList by track?
  - have kbd entry on a control track let numbers through
    . I do a fallthrough, does it get stopped?
    . NoteEntry.cmds_with_input catches the keydown msg, and replaces it
      with an Input.
    . I would have to say if it ended with Continue, then try again with
      the original key.  Would that have confusing side-effects?  I would
      prefer if I could have ControlTrack.edit_normalized explicitly signal
      to retry with the Msg.
    . I think commands would fall through in addition to playing a note,
      e.g. jk will do a thru and still move the cursor, which I don't want.
    . I don't want this that much, so leave it be for now.
  - it would be nice if I could coerce VPitch to NoteNumber
    . Implementation is in the 'typecheck-instances' branch, but it leads
      to awkward orphans, so I'm not sure I like it.
    . Then I can simplify Synth.Faust.Code.c_initialize.
    . That requires pushing Derive.resolve_pitch into Internal so Typecheck
      can use it, which in turn brings controls_at.
    . The other option is to move the Tyepcheck instance out.
      Or maybe I should move the bits needed by Deriver.Lib to TypecheckT:
      class Typecheck, ToVal, from_val_simple
    . But I need Typecheck instances for ScoreT.Instrument Signal.Y Expr.Str
      DeriveT.Val.
    . Or, a less disruptive change might be to move some instances to
      TypecheckI, like Pitch.NoteNumber.  But then they're orphans, and it
      would be awkward to remember to import TypecheckI.  I suppose Derive.Sig
      could import it, under the assumption that it's the main user of
      typecheck, but it's not the only one!
    . I could move down the instances for those specific things.  It's pretty
      ad-hoc.
  - Typecheck PSignal.Pitch instance for NoteNumber could use Twelve.nn_pitch.
    . Except it can't because of circular dependencies.  Maybe instead
      Twelve.nn_pitch should replace the one in PSignal.
  - can I tweak individual scale degrees?
    . E.g. ma + 0.25nn, ri + 0.2nn.
    . Maybe just an env var for scale degree would do it.
  - convert save/bali/legong/semara-dana to im
    . sampler-im versions of gong, jegog, calung
    . notation and damping inference for gender rambat
    . It would be nice to have the high level part, then double click to open
      the derived parts, and possibly edit.
  - do I ever get negative Score.Events?
    . It would simplify to rule that out.  E.g. Score.events_overlap
    . Score.event_min implies I do, but only Derive.Note uses it so maybe no?
    . I think the main opportunity to get them is if default note makes them.
    . It does!  Negative notes make negative Score.Events... then what?
    . Midi perform doesn't understand them, they wind up with minimal
      durations.
    . I guess I rely on postproc to flip them around, but which one?
    . Postproc.make_cancel seems like it should do it, but I don't see
      anything about negative duration, just weak and strong cancellation.
  + rhythmic interpolation
    . Match notes in two derivers, then interpolate rhythms:
      '%pos=.5 | r-interpolate b1 b2'
    . What to do if the notes don't match?  If it's pitches I could also
      interpolate the pitches.
    . The use is something like chatusram -> tisram transition.
    . I already have an interpolate call, but it goes by score event.
    . Uses:
      1. transition from rhythm to another, e.g. chatusram -> tisram
      2. modified pattern as an effect, e.g. p6 evened out halfway to p5
      3. consistent warp on all notes, ala microrhythm
    . For 1 and 2 I think both arg form 'interp b1 b2' and parent form would
      be useful.
    . For 3, I would want to apply to a whole track, and loop the model
      rhythm.  I would also want it to work even when the source is missing
      a note.  So this is more of a warp, where I map each timestep of the
      source to a different place, then apply that as a continuous warp.
      . This is a way to make a local warp map, then apply that to a child
        deriver.
      . Derive the model in linear time, then how to infer its time step?
    . Can I do this as a interpolation between two derivers?  Then use 'tile'
      or 'loop'.
    . In fact, can I use the existing interpolate for this?
    . Here's how it could look in tscore:
      top = [
        e-interpolate/6
        // "loop | b1"/6
        // "loop | b2"/6
      ]
      b1 = [ k t k n o ]
      b2 = [ k t _ k n o ]
        =>
      top = [
        e-interpolate/6 // loop[k t k n o]/6 // loop[k t _ k n o]/6
      ]
    . Can I provide (loop | b1) as an arg?
        e-interpolate "(loop | b1) "(loop | b2)
    . Then tscore could be:
      top = [
        "e-interpolate loop[k t k n o] loop[k t _ k n o]"/6
      ]
      but it would need to look inside ""s for [] interpolation.
    . The problem is that deriver is not first class, so calls with multiple
      deriver arguments actually take strings.  This gets back to the very
      old idea of unifying 'a | b | c' with 'a (b (c))'.
    . The problem I am solving is that it's redundant to make a whole track
      and have to set the event duration to be the same, so subtracks are too
      flexible.
    . "(loop | b) works because with "() deriver does in fact become first
      class?  Well, only sort of... Sig.eval_quoted returns a Val, so it can't
      be a deriver, but e-interpolate uses Eval.eval_quoted, which is only
      derivers.
    . It seems I could still put Deriver in Typecheck, since it doesn't have
      to go through Val.

  swam: strings
    - notes get stuck on
      . Midi.AllNotesOff kills it, but space doesn't emit that.  Why not?
      . If I always emit AllNotesOff, then im stops as soon as it starts, why?
      . AllNotesOff shows up as Control 1 123.
    - simulate hand position and shifts
      . This won't work well because swam also wants to do that, and even with
        the hand position setting I think I can't get it to use the string
        I want.
    techniques:
      - trompong tumpuk, double strokes, noltol
      - Experiment with increased or decreased pressure or position for damped
        stroke.
      - staccato with short stroke and bow-lift=t
        +spiccato
      - randomization in pitch, pressure, bow pos, open string tuning
      - trill at 1.5nn?
    - polyphony
      . I'll need at least mono, double, and double-hold, and to set the
        strings.  It should be possible to infer from the score, but try it
        manually first and see how it goes.
  - What to do with dummy-only instruments like kontakt/wayang-pemade?
    . They're confusing because kontakt/wayang-pemade is not actually
      a playable instrument.
    . Actually, it is, it's the version without the scale, so it would work
      for any tuning.
  - track integration should possibly be indexed by TrackId, so I don't have
    the possibility of overlapping ones.
    . I also want to be able to match on TrackId for the manual integration
      in TScore.  I should refactor on the integration stuff to account for
      all the variants in a less ad-hoc way.
    . Wait actually tscore shouldn't use TrackId.
  - MemoryLeak latency:
    . getting above the limit of 0.05
    . I don't know what the historical values have been, maybe I should be
      saving those.
    ? It's the first cmd only, what is it doing that's more work?
    . Try with 8.0.2.  Yes, still happens there.
  - prettyprint:
    . Check out pretty-show or pretty-simple or ghci-pretty
    . https://www.reddit.com/r/haskell/comments/8ilw75/there_are_too_many_prettyprinting_libraries/
    . http://teh.id.au/posts/2017/02/13/interactive-print/index.html
    . https://www.reddit.com/r/haskell/comments/76fvsq/replacing_ghcis_prettyprinter/
    . https://github.com/cdepillabout/pretty-simple
    . Maybe I can use this to get rid of the haskell-src dep.
    . Also this is maybe an up to date variant:
      https://hackage.haskell.org/package/prettyprinter

    . pretty-simple takes up too much vertical space, and I think I don't want
      the colors.
    pretty-show:
      . pretty-show still takes more space than HughsPJ Pretty.pprint, but
        seems ok?  It's like Util.Format, but doesn't pack horizontally.
      . Actually pretty-show dispatches to HughsPJ under the surface.
        But it works by parsing and reifying to a Value type.  It also has
        a PrettyVal which is a GHC.Generic implementation to convert to Value.
      . It also renders to HTML, from the Value.
        It's kind of interesting, but I don't like it.  Takes a lot of space,
        has confusing 2d layout.  Can collapse though, but you have to click
        on it.  I'd want to collapse everything at a certain level, like zm.
      . It uses haskell-lexer instead of haskell-src, so I can remove that
        dep, which seems old.
  track down 8.4.1 performance regression:
    . performance regression notes: http://ghc.haskell.org/trac/ghc/ticket/14964
    - try with 8.0.2
    - try without RTS flags
    . Also it seems to really only be OS X, it's only sligtly worse on linux,
      or even slightly better for cerucuk-punyah.
    . It correlates with the productivity decrease, so maybe GC related.
    - maybe I could help with compile time regressions by exporting shake's
      report.html and noticing when files change time.
    compile time mehitabel:
      . 8.0.2:
        RunTests      549.10s user 118.45s system 343% cpu 3:14.53 total
        RunTests      548.71s user 117.10s system 347% cpu 3:11.78 total
        debug/seq     284.47s user 55.95s system 345% cpu 1:38.58 total
        debug/seq     283.33s user 55.27s system 343% cpu 1:38.53 total
        opt/seq       732.63s user 70.86s system 338% cpu 3:57.30 total
        opt/seq       735.21s user 71.48s system 327% cpu 4:06.31 total

      . 8.4.2:
        RunTests      450.92s user 109.63s system 343% cpu 2:43.13 total
        RunTests      445.48s user 107.99s system 341% cpu 2:42.19 total
        debug/seq     220.92s user 50.21s system 337% cpu 1:20.32 total
        debug/seq     218.39s user 49.20s system 345% cpu 1:17.47 total
        opt/seq       785.12s user 65.42s system 327% cpu 4:19.84 total
        opt/seq       765.52s user 64.01s system 321% cpu 4:18.29 total
    compile time tammananny:
      . 8.0.2:
        . RunTests    781.31s user 58.21s system 363% cpu 3:50.70 total
        . debug/seq   429.44s user 31.34s system 362% cpu 2:07.03 total
        . opt/seq     1277.20s user 45.85s system 358% cpu 6:08.68 total
      . 8.4.1:
        . RunTests    613.11s user 49.84s system 357% cpu 3:05.52 total
        . debug/seq   329.67s user 23.86s system 352% cpu 1:40.38 total
        . opt/seq     1339.73s user 39.87s system 341% cpu 6:43.50 total
  - extend gliss so I can gliss on harmonics
    . Why does eval_quoted give opposite pitches?
    note = Eval.eval_one_call True $ Expr.call0 Symbols.null_note
  - Since gliss uses a 'n' parameter for note transform, I should use it
    consistently, e.g. in grace and roll.
  - It's awkward to rearrange tracks and then redo the skeleton.  Since
    I never really want tangled skeleton anyway, can't I make that implicit?
    . I could say the skeleton always goes left to right, and only branches,
      never merges.  So the control is the tree structure and the ordering of
      the toplevel tracks, and I think the rest can be inferred.
    . Write infer_order_from_skeleton, and infer_skeleton_from_order.  I can
      invoke the first after modifying the skeleton, and the second after
      moving a track.
    . Actually, how can the second work, if I don't have the tree structure?
      If I just have the first I would have to move tracks by modifying the
      skeleton, but that seems pretty awkward.
    . The restricted skeleton is like that which is used by integration and
      ModifyNotes: [(Note, [Control])].  Except I have a tree of controls on
      top: [TopControl] where
        data TopControl = TopControl Title [TopControl]
          | TopNote Note
        data Note = Note Title [Control]
        data Control = Control Title
    . Or maybe I could address it directly by making track move work on the
      whole note track.  I can already do this by just selecting all the
      children, but this would make it automatic.
    . But I originally added this entry because I was swapping a control from
      below to above.
    . I guess I could have a move variant that keeps the skeleton the same.
    . The other annoying thing is having to manually add e.g. the tempo track
      to all new note tracks.  I sort of get around this with the insert-above
      etc. cmds, maybe I just need to make those smarter, or understand them
      better?
  . What would I actually need to have a useful TrackTime?
    . TrackTimes come from Events, and they are absolute measures.  Addition
      and subtraction yields ScoreTimes:
        (+) :: RelativeTime -> TrackTime -> ScoreTime
    . Ui.Event has to be polymorphic on the time type, because I synthesize
      fake Ui.Events or translate real ones (do I really do that? where?).
      . An alternative is to put all calls in normalized time, and then have
        some organized way to get TrackTimes for when I need them.  Or rather,
        make the things that require them not accept ScoreTime.  I'd need to
        go review why I made calls non-normalized in the first place, and see
        how much those reasons still hold.
  Unify Environ and ControlMap:
    . I can get most of the benefit by unifying the syntax: x=y becomes set
      a control or env depending on the type of the rhs.
    . However, they're still separate which means I can make an "invisible"
      numeric env in haskell.
    . Also, I would need Derive.Sig to default from numeric controls.
    . I guess it would then be better to have a single
      Map Key (NumSignal | ValSignal | PitchSignal)
    . This means I can also get rid of the separate pitch and named pitches,
      and just have a signal named "pitch".
  cleanup from linear:
    - rename RealTime.seconds to from_seconds etc.
      . I'm kind of reluctant because RealTime.seconds reads nicely and
        there are a lot of places to change and they all get longer.
    - Deriver.Lib.with_control_mods
  - Look for TODO(polymorphic-signals) for places where a signal typeclass
    would help.
  - what if I added a 'default-interpolator' argument so Control.c_set and
    Pitch.c_set could make curves by default?
    . '*PITCH = xyz' does this for pitch calls, but this is a special
      behaviour for Derive.val_to_pitch, and wouldn't work for controls.
  - pnovla @pno1 32.25t mordent broken, probably too much note overlap
  - string_idiom should ignore notes that already have a string.
  - Let synth defs log warnings
    . So e.g. MidiInst.compile_library can report shadows.
    . I should be able to incorporate Faust.PatchDb.warnings too.
  - Generic Show and Pretty instances for ScopesT and Scope.
  - Maybe 'set' should be the default merger, not mul.  It seems less
    confusing.
    . I could still have 'dyn' default to mul, if that's not confusing too.
  - decide if the ( call is called slur or legato, not half and half.
    . I already have something called slur in Rearticulate, so let's go back
      to legato.  Slur is just how it happens to be realized in lilypond.
  - Use EnvKey.string for string selection in vsl, not attributes.
    . It would be nice to be able to select by name instead of NN, but the
      calls like NNs.  Maybe val calls that emit the right NNs.
    . I'm using pitches with e.g. '60nn' for names.  g, d, a e are still
      a better UI though.
  - if 'roll' were a transformer I could do 'roll | some-note'.  This is the
    same problem as extending 'grace' to be able to put stuff on the main
    note.
  - Pitch bend doesn't work right on a MIDI instrument with patch scale.
    . Likely because the pitch gamut is not linear, but pitch bend is.
    . I would need to warp the pitch bend by the patch scale... but don't I do
      that?
  - It seems too complicated to set up patch scales, how can I make that
    easier?
  - Highlight for block calls which are 1:1, or not 1:1.
    . Use event width for this?  But this is a different mechanism from
      highlights, which uses selections.
    . Or use event color.  Effectively the highlight does that though.
    . How to get the highlight?  Other highlights are postprocs that attach
      the highlight, but I think I can get the block call itself to do that.
    . But highlights go on Score.Events, and this is a UI event.  I could
      extend LEvent.Log with a general Metadata kind of thing, or I could
      also attach a highlight to the first event from the block.
    . The latter means highlight needs to support a time range, and of course
      it won't work if the block produces 0 events.  But in that case it
      doesn't matter if it's 1:1 or not.
    . The problem with LEvent.Metadata is that I don't want to rewrite all the
      LEvent stuff to also deal with logs, but I don't want to pay another
      indirection.  But if I put UNPACK it should solve that:
        data LEvent = Event a | Log {-# UNPACK #-} Log
        data Log = Metadata X | Msg Log.Msg
      Does that work?
    . What other things could I put in Metadata?
      . Highlights for one, I think a ScoreTime range is more appropriate than
        taking RealTime from the events, since the latter is wrong if the note
        extent doesn't match the score extent.
      . What about integrate?  I currently have a special spot in
        Derive.Results, but I could also emit it as a meta-event.
      . But for that matter, why not put highlights in Derive.Result?  It
        seems more elegant to favor the explicit Stream return value over
        implicit Collect results, but the logical conclusion of that is to get
        rid of Collect entirely.  I think I don't want to do that, because
        I take advantage of monoid merge to discard data.  But on the other
        hand, if the output stream is lazy, then it's just the same to do the
        same collection while iterating over the result.  This would make it
        explicit that to get collected data I have to iterate over the events,
        instead of how implicitly touching some fields actually implies
        evaluating the score.  Also I could evaluate Collect only up to
        a certain point, though I don't think I ever want to do that.  And
        then it separates result collection from the deriver, so maybe more
        modular.  Could it be more efficient?  I might spend a lot of time
        combining memptys. and a final fold might get rid of that.  Presumably
        I'd use an ADT for the metadata instead of a record.  On the other
        hand, it's more cons cells for the stream, which maybe means more junk
        to skip when sorting and merging.  Maybe I could mitigate that by
        collecting Metadata together into short vectors, which can be skipped
        as a unit.  It's only a win if they tend to clump together.
      . What would the metadata be?
      . Also I should profile to make sure about Collect usage and of course
        to see a difference if I switch.
      PLAN
        - profile current status, look for Collect allocation
        - enumerate the things that go in Metadata
        - verify UNPACK can flatten Log event
        - estimate work to switch
        - sketch out where and how the collect fold would happen at the end
        - ensure Streams are lazy... I think transforms might actually destroy
          laziness.  But would getting rid of Collect be able to restore it?
          I'd have to do something about exceptions, maybe put it in as
          a Metadata too.  If I can make the whole derivation fully streaming
          then this might be a big win.
  tabuh gari:
    - octaves notation for trompong
    - octaves for gender rambat
    - I get the wrong pitch on too-high trompong notes
      . It shouldn't try to emit pitches above its range.
      . I should extend the samples up a couple pitches anyway.
    - how can I write angsels?  E.g. same as template, but with bits replaced.
      Score derive?
    - It's inconvenient to have two roots, because play-from-root stops
      working right as soon as I change it.  But it does have a definite
      single caller, so shouldn't it be able to figure out a root all the
      same?
  - It's really tempting to put a '>inst = %dyn=.5', but that just forces it
    to always have that dyn.  How can I set a per-instrument default dynamic
    which I can still override?
    . First define exactly what I want.
    . I want to set a baseline dyn per instrument, but I want to be able to
      override it.
    . It should be as if I set a global %dyn, so specific ones can override
      it, but only for that instrument.  So each 'dyn' affects all dyn-*
      signals, and then each instrument can pick out its dyn-me.
    . And of course this should generalize for all controls... well, I don't
      have a use for non-dyn, so I don't really need to generalize.
    . If I always set dyn absolute, I could just set when the instrument comes
      into scope.
    . Wait, why does '>inst=...' not work?  Wouldn't it set at the note track,
      and then the child dyn track would be able to override?
  - Figure out how to control vsl legato transition volume mismatches.
    . slur call has a legato-dyn arg to try to address this.
    . Look into http://www.beat-kaufmann.com/vitutorials/index.php
  - (Sig.typed_control "tr-neighbor" 1 Score.Diatonic) when given 1 returns
    an untyped ControlRef.  Can I make it default to Diatonic?
  - ^o should ignore orientation on child control tracks.
    . Otherwise, it would confusingly not delete +0 controls on a negative
      note.
  - LRuler's sections*per_section is awkward when I'm really thinking in
    measures.
  - I had a bug due to using 'Derive.real dur' instead of
    'Call.real_duration start dur'.
    . Separate types for {Score,Real}Time and {Score,Real}Duration would fix
      this, but how much hassle would it be?
  - An 'accent' call on squart/6 @b4 causes a very distant %breath sample to
    go >1.  Why is the note including such distant samples anyway?  Isn't it
    inefficient to scale samples which are clearly not in the note bounds?
  - I often want to see where I am in the parent, e.g. like parent->child
    selection but the other way.
    . I can get this by playing from the point, but why not do it
      automatically?
  - I'd like to use Ui.allocation lens for modification, but I need to be able
    to put it in the monad.  Research once and for all how to do that with
    either fclabels or van-laarhoven lenses.
    . Looks like fclabels can do it, but I need separate monadic lenses, since
      monadic and non-monadic lenses can't be composed.
    . I should be able to write a function to promote a pure one though.
    . Actually I can't figure out how to get lenses to do this.  Lenses can't
      include the Ui.modify, since they have to be composable, which in turn
      they have to be used with Ui.modify, which is the thing I'm trying to
      not use all the time.
    . So maybe just get rid of Ui.allocations.
  - generalize zheng 'gliss'
    . It would use scale instead of open strings.
    . If I wanted to be fancy for harps I could do gliss on whole note or
      diminished minor sevenths that repeat strings tuned to unison.
  - >kontakt/kendang-bali-pasang doesn't work as a dummy instrument because
    those can't have the Patch.Triggered flag, or any flag.  I could move some
    flags to Instrument.Common, but what's wrong with having a MIDI instrument
    with no allocation?
    . Triggered is duplicated in Im.Patch, so I could get rid of that.
  - can I have a block template kind of thing, with a standard set of
    instruments?  Maybe REPL cmds.
    . E.g. for a standard orchestral template.
    . I could also add a track for each allocated instrument, but I'd need an
      order.
  - Also cmds to re-order tracks by instrument.
  - How to add grace notes to a non-null call note?  Also what if I want
    non-null grace notes?
    . I can make a 'g' transformer for the first: 'g 0 1 | x'
    . For all maybe a grace-transform env arg.
  - squart/6 has some jumpy dynamics due to sets in dyn with a scope over them
    e.g. end of @b3, vln2
  load octamed files
    - implement set tempo and set frames cmds
  selection-orientation branch cleanup:
    - set_duration: If I have ><---|, I can't set the negative event back to the
      zero dur event because it sets the previous positive event, regardless of
      selection orientation.
    - Slice range should be Events.Range so it can remember the orientation.
      Otherwise I think -0 note slices don't work.
    - I think Slice.events_in_range should get an orientation, which in turn
      means checked_slice_notes needs one.  Otherwise don't negative notes
      not get the end event?  But Sekar maybe relies on include_end.
    - Perhaps related, I removed include_end since negative should work for
      that, but Sekar used it.  Can I use Sekar with negative events to get
      end bias back?

  - QuickCheck for Midi.Encode_test just for practice
    . Ui.Events_test.test_from_list_qc is an example.
  - Will TimeVectorStorable.Sample Double have both fields unpacked?
  - Add 'angklung' and 'beleganjur' scales.
  - BaliScales should have a default ombak, depending on laras.
    - Also there should be a way to randomize per instrument, so it's not too
      perfect.
  - TSymbol could have a descriptive arg with e.g. instrument, scale, etc.
    . This would get back the documentation I lost when I got rid of
      VInstrument.
  - OutOfRange pitch error should show the pre-transposition pitch.
    . In fact, all the errors from e.g. Pitches.pitch_nn should be annotated
      with information about the pitch.
  - Cmd.Ky: Keep the defining file in a special slot in the call doc, so I can
    print it out in shadowed msgs.
  - Cmd.Backend's Midi.Patch is redundant, since the Inst already has it
    . Not quite, since Backend encodes that alloc and patch backends are
      equal, but is it really necessary?
  - do a renaming pass on all the prev/next pitch function names in Derive.Args.
    . Should Prelude.Pitch.approach use the lookup pitch style?

  - it looks like special kajar calls like 'oo' mess up track signal.
    . I can fix 'oo' by making DUtil.doubled_call inverting, but that doesn't
      work for 'o..'.
    . DUtil.multiple_call doesn't need inverting because it dispatches to
      call that do invert, right?
    . Actually it's pretty pernicious, because without inverting, doubled_call
      will still appear to work because the underlying call inverts.  But
      TrackSignal gets messed up, and if it did anything based on controls
      then they would not take child controls into account.
    . Why is TrackSignal messed up though?
  - do nruk with a static macro
    alias 'o..' 'nruk | o'
    . I could modify c_nruk to have a generator version that takes a deriver,
      but then I have to copy paste it.
    . How can I inherit args?  StaticMacro is no good because I want the
      generator to be late bound.  But 'nruk' should be static bound because
      it's in another module and I want to inherit its args.
    . What I really want is to inherit args and docs from the transformer, and
      apply to the generator dynamically.  So something like a static macro
      where I give all args to one transformer, and the generator is dynamic.
      I think I can do the former with a special arg, and the latter with an
      eval "static call".
    . But what happens with StaticMacro when it hits a Sig.many?  I think it's
      broken.
    . To support this, Sig.required_vals needs to support 'many' parsers.
      I could infer from ArgParser but it seems like it's getting too
      complicated.  I think at that point I had better just be able to copy
      the parser over.  Can't I just reapply to the callee?
  save/sketch/16-04-10-charukesi:
    - fltk/EventTrack.cc:109 sample time didn't increase: 37.2 <= 37.2
    - Use kotekan for >wy with sargam scale.
  - I should collapse adjacent Collapsed tracks so they don't turn into
    a giant blue block.
    . If I do it at the fltk draw level, then I don't have to worry about diff
      complications or tweaking indices, but I still have to model as fewer
      widgets so the index tweaking just happens lower down.
    . If I do it at the haskell level, hopefully I can reuse the existing
      Track / DisplayTrack distinction used for collapsed tracks in the first
      place.
    - I have to also collapse the skeleton, which means I need
      a Block.display_skeleton and Block.display_integrate_skeleton.
    . However, I'm not sure it's worth it.
  vsl:
    - figure out how to do tuning
      . I think it needs to be pitch bend, since it doesn't seem to respond to
        MTS.  But VSL ensemble should be able to load multiple copies of the
        patch and share sample data.
      . Figure this out before doing too many more patches, because I'll have
        to update them all with global control config, unless there's a way
        to copy paste that.
      . However, it apparently can be used with hermode, so not sure how that
        happens.  Maybe I can just ask VSL support.
      . Scala files are not very good because I'd have to go manually load
        them every time, and they're static.
    . Legato attack scale control affects the crossfade level of interval
      samples, experiment with that.
      . Wait, where did this go?
    . figure out how perf reps work, and how I should handle them
    - make sure perf_upbeat_repetitions are consistent
    - make sure grace vs. grace.updown is correct
    attribute groups:
      . bass clarinet has nv without vib
    - rename +sec# to +s#?
  - Perf.lookup_instrument on a pitch track could look at its note track.
  - I forgot to add Sub.inverting to mridangam.p1 and mridangam.pn calls.  Can
    I have a warning for when a non-inverting call has a note track below it?
  - empty track doesn't get an Environ, which causes Cmd.Track to not be able
    to find the instrument.
    . It was because the kendang tracks were below >pno, not "tempo".  So, two
      problems:
      . It's too hard to see that the skeleton is wrong.
      . Note track children should have dynamics too.
  - Do I need Perform.perform_control_msgs.trim or not?  Figure it out and
    write a test if I do need it.
  - fix control scope in parent events that cover up an orphan, as
    demonstrated in Sub_test.test_overlapping_parent_control_scope
  - Better solution for the "sample at end of block" problem, as demonstrated
    by Block_test.test_trim_controls_problem
  wayang:
    - Infer late damping.  E.g., if there is a jump wider than 2 notes, then
      wait until the hand is free for long enough to damp it.
    - Automatically fill in weak notes?
      . This also applies to reyongan, even more so.
      . In fact this is similar to noltol.
    - many double strikes or ngoret tones land a bit ahead of the beat
    - I want some optional ngoret to happen the same way in both hands.
      I could make it apply to a parallel kempyung or octave.
      . I'd need a fancier ngoret that understands 'inst-top' so it can go
        down if necessary.
  - thru on *legong notes is wrong the first time
    can see this editing rehearsal/kendang-legong
  - %sus-abs=-.x is not quite right for detached, because it should scale
    a bit for shorter notes.  E.g. it's absolute but scales down to 0 below
    a certain threshold.
  - I have a feeling like FM8 doesn't obey ResetAllControls
    Maybe I should extend Midi.Interface.note_tracker to keep track of
    used CCs to issue resets for them.  Some reset to 1, e.g. cc2 and cc7,
    the rest reset to 0.

IN PROGRESS / branch: branches:
  . This has longer term projects, which are partially complete.
  - ControlFunctions are still super confusing. NOTE [fix-control-functions]
    . Yet another confusing thing is that they don't work for arbitrary
      signals given to notes.  I think it would be better to override '' to
      get e.g. %location as %location + rnd ...
    . E.g.  '%strength=.5 | %strength=(cf-rnd ...)' means it looks like
      %strength is .5, but it's actually not, and the only way to get rid of
      the CF is %strength=_.
    . Also the whole implementation is a mess.  Isn't there some other way to
      randomize signals?
    . I could pass a Quoted, and then control functions are val calls that
      return Quoteds: (cf-rnd control 0 1)
    . Then I want to be able to treat those as signals, or coerce them both
      to the same thing.  Really that's a SignalFunction, or maybe just
      RealTime -> Deriver Y.  So this turns into the problem of how to coerce
      various types into SignalFunction, but not have to have an opaque
      SignalFunction for all the defaults.
    . I could have a Convert typeclass.  In fact maybe it would be cleaner to
      split Typecheck and Convert?
      Typecheck: Val -> Maybe a, Convert: a -> b
      Convert would be: Int -> SignalFunction.
    . I think this won't work because the intermediate 'a' will be
      ambiguous.
    . I can always have a Default class that is used only for Sig defaults,
      and provides both ShowVal and the coercion.  It would mean I have to
      duplicate everything in Typecheck, unless I use an overlapping
      typeclass.  Or I could default to... what exactly?
    . The problem with `Convert a b` is that 'a' needs a type annotation,
      which would make signatures annoying to write.  Normally I don't need
      them because they are the Typecheck val, which already needs to be
      fixed.
    . Or I could have defaults be either a Typecheck val, or
      (Doc, Typecheck val), and then have an explicit constructor for Function
      which promotes various types to (Doc, Function).
    . Give hs-boot another try, but maybe wait for 9.2, this may help:
      https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5661
      . Not in 9.2, probably have to wait for 9.4
  Support for adding or removing time in the middle of a score:
    . Status: this is implemented manually via Cmd.BlockResize, and
      specifically LBlock.add_time and remove_time.  It seems to work, but I
      haven't used it extensively.
    - Add a variant of ^z that moves events below and track children.
    . This has overlap with the idea to have a track as a read-only view of an
      expression.  E.g., the expression would be b1, b2, b3, ..., and the
      view would be to get the CallDuration of each and sequence them.  The
      trick is that it would have to re-integrate whenever the callees changed
      CallDuration.  In this approach, I'd have a separate expression with the
      sequence of calls.  That would then be bound to a track, which would
      then become read-only.  I'd have to edit the original expression.
      . The cmds that change a block ruler could trigger re-integration in the
        same way they would have to trigger the caller resize.
      . Even in this case, I need something to put in for ruler.  I guess I'd
        use 'extract'.
      . It may be more awkward to edit the expression instead of directly
        editing the track.
      Advantages:
        . It would be a specific case of a generalized integrate-expression
          feature, which I'm pretty sure I'll eventually add anyway.  Actually
          I can just add an optional read-only option, otherwise it could be
          integrated as normal.
        . If I lock a whole track, then I don't need some special "time locked
          event", I have a whole locked track.  That seems simpler because it
          doesn't have to coexist with normal events.
        . I don't have to scan blocks for calls, since they are explicitly
          listed in an expression.  Presumably the expression is data, not
          code, so I don't have to do any evaluation.  But maybe I have to
          evaluate anyway to get CallDuration?  But it seems clearer to update
          specific expressions, rather than just scan the entire score for all
          calless and try to mess with their durations.  Also, mixing block
          call events and normal events is not necessarily something I want to
          support... even though I have done it in the past.
      Disadvantages:
        . Another language.  If it's just linear sequence then it's trivial,
          but surely that won't be enough.
        . The whole point of the track is that I can line things up in time,
          and I still want to do that with score blocks.  Why should I wind up
          with a whole new language for that?  E.g. initially it's just
          sequence.  But then I want 'clip', so I need explicit durations.
          Then I want time gaps, so I need start times too.  Then I want to
          express alignment, so I don't have to calculate start times... and
          in any case, those times will be invalid when the callee changes, so
          I need alignment anyway.
        . But the clip problem is something I need to express anyway.  In
          a language I could say "Clip | awak" dur=-1gong, but how would
          I tell a track version that?  I guess it would just not update the
          duration of clipped calls.  In fact 'clip' and 'Clip' could express
          that by setting the CallDuration to the event duration.
      . But in fact I don't need a locked event at all, I can just update it
        on demand, but have no particular requirement that it stay that way.
        I could do a universal thing where block calls get a subtle hue that
        indicates they are 1:1.  Or use event width?
    older notes:
    . I want add a measure, and then automatically:
      . Extend the ruler of this block.
      . Extend or contract the duration of the caller in the parent, moving
        all its events as necessary.
      . Also extend or contract the caller's ruler, if necessary.
      . Renumber the ruler in other callees as necessary, e.g. inverse
        LRuler.extract aka LRuler.inject.

      . All of this ruler resizing would not be necessary if I used
        Ui.event_end instead of Ui.ruler_end for the logical block end.  But
        then I'd need a -- event to mark the explicit end.  And it's just
        putting off the inevitable... I'd still need to extend the ruler, so
        why not make it easy, so now I don't mind doing it frequently.
    . If I have a way to mark a call as "unstretchy" it can try to move events
      below it, or at least highlight if it's not 1:1.
      . Or maybe it should even default to unstretchy, and you have to mark
        stretchy.
      . I could do it with special metadata in the event that could cause it
        to render differently, or by prefixing with a magic character, say '='.
      . The advantage of the magic character is that it's visible and I don't
        need any special editing support, but the disadvantage it that it's
        metadata interfering in notation.
      . Presumably it only has an effect on events with CallDuration, and
        maybe even an error on ones without... but I can't find that out
        syntactically.
      . Maybe the first step is to implement the move later events part,
        triggered by a keystroke (like cmd-z for events), and worry about
        doing it automatically later.
  solkattu integrate:
    . Status: I think it just barely works, via LSol.edit_new, and
      reintegrate, but not tested and not hooked up to the editor.
    - validate Block.ManualDestinations from Ui.set_integrated_manual
    - If I put a TrackTime offset into the ManualDestination, I could have
      multiple destinations on a single track.  But then I'd have to also
      know to move things around if they change size, and it seems
      complicated.  Maybe it would be better to put them in their own
      block, and then implement a way to nudge calls when one changes
      size.
    - If I put the destination on its own block, I could automatically
      adjust the ruler.
    - make block version of LSol.integrate_track, where integrate also adjusts
      the block ruler to the right length.
      . I need to understand the tala, not just for the ruler, but to know
        if there's a final stroke.
    - Solkattu realize with an alignment error should still realize, just
      emit a warning.
    - On vim 'gs', output from 'send' messes up the draw.  Maybe bring it
      back to vi and do :echo?
    - Get rid of Korvai index, it gets more annoying as time goes on.  Just
      have separate korvais, and I can tie them together with variable_name if
      necessary.  But I still need a way to distinguish for SourceKey, so
      maybe I still need it but as another tag, added by 'korvais'.
    notes:
      . I'd like to be able to edit e.g. solkattu dsl, then save triggers
        a score integrate.
      . This is also the way to get text score: to integrate in general.
      . Also it's visualization for text score:.
      . StateConfig can have 'dsl_integrate :: Map Symbol Code', then repl cmds
        to edit them.  This is then haskell, which means I need some way to get
        it into the REPL, and some standard environment in which it is executed.
      . I can actually do this currently but I have to run a repl cmd, e.g.
        LSol.integrate Score.xyz
      . So simpler way would be to hook the editor so it does 'send ...' on
        save.  I should do that first, and think about a more automatic way
        if it's too awkward.
      . The common building block is a manual score integrate like
        integrate :: Symbol -> Track [Ui.Event] | Block Ruler [Ui.Event]
      . Dsl integration won't have a source track or block.  Instead it needs
        another ID which can link it with the source.  So for code it would be
        defining file or expression.  I also need identifying stacks for the
        generated events.
      . I have to load the module with the dsl.  If that's supposed to be
        per-score then I need to get that into an .hs file and get the repl to
        add that to the targets.  The file should be .hs and loadable anyway so
        I can use ghci on it.
      . But I'll likely have multiple DSLs, so it needs some configurable
        boilderplate, i.e. imports.
      . Two cases: EDSL means it's haskell with a special "prelude", like
        solkattu.  DSL means text with a parser, e.g. Derive.Text.TScore.
      Make this work for solkattu:
        . Make solkattu set Event.stack.  It should have the sollu and position
          as a TrackTime.
        . The score has a link to a module name, e.g. Local.Score.Xyz.  If it
          doesn't exist, create one with the standard set of imports.
        . On refresh, have the REPL load that module, and pull out every symbol
          with the right name, e.g. _xyz.  Each of those should be of Block
          type, and will be used to create score integrate to a block of the
          same name.  I do the integrate for everything, since it will detect
          if there were changes.
        . Figure out how to make the GHC API load a specific module and find
          symbols.  I need to verify their types too.  Trigger like :dsl X.Y.Z
        . Make a Block type, and hook it up with score itegrate, and :dsl.
        . Make solkattu realization retain the original sollu.
        . Add the "dsl modules" score field.
        . Make a REPL cmd to open vi with the file and bind save to the :dsl
          cmd.
  - track calls / track macros:
    . Status: lost motivation after I figured out another solution for
      gamakam, which now uses a t-nn track.  It's implemented all the way
      up to having a spot in Derive.Scopes and special control track syntax,
      but there are no implemented track calls.
      . See also signal-discontinuities.
    - More general and descriptive names for Derive.Scopes and Scope.
    - Implement calling TrackCalls.
      . Overloading 'x' to mean a call to x or a control %x might cause some
        problems.  E.g. title_to_control can't know unless it looks
      . If I just use a symbol there's no way to tell if it's a control,
        pitch, or note track.  So I need to keep the syntactic clues.
      . Maybe control: '!call', note: '> !call', pitch '*xyz !call'?
      . I'd like to be able to abstract control, e.g. '!gamakam', and the t-nn
        is an implementation detail.  But I can't have track calls return
        (Control, d), because that's only control tracks.
      . I could have it set a control with the same name as the track call,
        and then some way to rename it.  But what is that way?
      . Or I could just fake it by returning Score.Control, and pitch tracks
        just use Score.Control, and note tracks just ignore it.
      . It seems awkward that this is simultaneously giving a way to abstract
        syntax and control name, and they don't seem naturally related.  Can't
        I have an orthogonal way to make 'gamak' an alias to t-nn?
    - Write a TrackCall for gamakam4.  ! calls quote the argument and pass
      to gamakam call.  Or I could invert it and use ! for non-gamakam calls.
      Copy pitch calls over.
    . Maybe this is how to do macros: track title is a lookup in
      a track-macros namespace.  If 'name' isn't found, then it defaults
      to '%name' ala LookupPattern.  Track call namespace should also be
      in the CallMaps and Library so it can be imported with modules.
      Also I think it needs note, pitch, and control variants in the same
      way.
    . As long as I'm doing this I can go back to using pitches for
      gamakam, and just copy over from the pitch track.  Not sure if
      I should though.
    . old notes:
      . consider track calls and block calls:
        note_track :: TrackTree.EventsNode -> Derive.EventDeriver
        derive_tree :: ScoreTime -> TrackTree.EventsTree -> Derive.EventDeriver
      . I could use this to implement is-ly and no-ly, and also totally custom
        track types and block types.
  - draw-text-lines
    . I think it's a bit of an improvement for code simplicity, but still has
      an annoying redraw bug.  So it's almost done but not merged.
  - Sortedness tracking for Stream and Post functions.
    . Track down usage of Stream.from_sorted_list, probably most uses are
      bogus.  Stream.from_list and Stream.from_events have to take
      Score.Events so they can sort them.
    . Sorting vensions of Post functions also have to return Score.Events to
      be able to sort them.  They could take another event_of, but it seems
      like there should be a way to compose the mapped functions instead of
      the maps.
    . I should also come up with a plan for deforesting the intermediate
      lists.
    . Order is easy to check with quickcheck.  I could come up with some ways to
      do quickchecks on certain score fragments.  Or alternately, apply
      a standard set of checks: start =0, >0, in callee block, etc.
  - Make BaliScales which are not saih pitu be fundamentally diatonic, not
    just degenerate chromatic.  Or figure out how to simplify the whole scales
    mess.
    - Disallow 4e# in selisir.  And generally accidentals.
      . Validating the absolute pitch is broken for *legong, because I want to
        make sure the relative pitch is in the key's intervals.
      . I could make validation more complicated, but I think not using
        ChromaticScales would also fix this.
      . I don't get an error because the pitch is created, but will evaluate to
        UnparseableNote, which makes an error only on conversion.
      . It's because ChromaticScales reads a relative pitch, and only checks
        for validity once it's absolute, at which point it already created
        a ScaleDegree.  I could either also validate relative, or get rid of
        the fancy ChromaticScales use for scales without modes.
      . Or maybe UnparseableNote should have a msg arg to show what it was?
      . The thing is, I don't want the whole accidental parsing mechanism,
        I just want 7 symbols, and a relative pitch system.
      . So I could have a simplified ChromaticScales which dispenses with letter
        + accidental, and instead just has a unique name for each scale degree.
      . Then I could use 1234567 for javanese-style notation.
      . I'd basically replace the show/read pitch stuff with a hardcoded map to
        RelativePitches.
      - I can't have different pc_per_octave based on key, without parsing
        the key in input_to_note.
    - It would be nice to have a no-keys version of BaliScales so I don't have
      to mess with a fake key in *selisir and *wayang.
      . I guess it's not a big deal, but at least it means it ignores key.
      . Actually it seems like it might be a pain, because then I can't use
        the same Config.
    Why are scales so complicated?
      - Can I make it simpler?  If I were to rewrite it knowing all this stuff,
        what would it look like?
      . twelve: Keys have mode and tonic, so each key has a signature that
        influences enharmonic spelling.  Has accidentals with enharmonic
        spelling, and a layout which says which pitches are skipped, also based
        on the key.  Both the pitches and accidentals are absolute and so
        independent of the key.
      . twelve-k: Like 'twelve', but while pitches are still absolute,
        accidentals are relative to the scale.
      . twelve-r: like 'twelve', but both pitches and accidentals are relative
        from the key's tonic.
      . just: Keys have mode and tonic as with 'twelve', but they affect the
        tuning.  The layout is diatonic in that there are no skipped pitches,
        and hence no enharmonics and accidentals.  Accidentals are supported
        just as a constant ratio offset, so respelling enharmonics will change
        the frequency.  Since there's no per-key spelling, the key is much
        simpler, just a tonic pitch.
      . just-r: Like 'just', except that pitches and accidentals are relative to
        the tonic.
      . raga: Like 'just-r', except with a much larger selection of modes.
        Also, instead of accidentals, there are multiple candidates for
        certain pitches (e.g. ri1 ri2 ri3), where one will be default based on
        the key.  TODO the last bit is not implemented yet.
      . legong, pelog: These have keys, but like 'just-r', they are simply a
        starting note (tonic) and a layout to indicate skipped notes.  However,
        there are no accidentals, and instead each note has a unique name.
        'legong' (but not 'pelog') has a 'tuning' which indicates pengumbang or
        pengisep, and they also have a 'laras' value, which indicates the tuning
        variant.
      . legong-pemade, legong-kantilan, etc.: Like 'legong', but with octaves
        relative to the tessitura of a particular instrument.
      . selisir, wayang:
      . selisir, wayang -pemade etc.: Relative octave variants.
      . belaganjur, angklung:
      misc notes:
        . Simplest is an absolute scale with no key and no octave structure,
          just a mapping from symbol to pitch.
        . Then we have a relative diatonic scale.  This has a key which
          influences the note names, since they are relative to a certain
          pitch, but no other structure.
  - rewrite shakefile so I can disable features like 'im' and not require
    their dependencies for tests, haddock, etc.
    . I'd like to generalize this to a shake haskell build system, so I can
      use it with other projects.
  - Complete Util.PrettyGeneric so I don't have to hand-write Pretty
    instances.
    . Maybe I should fix the formatting bugs first.

TASKS:
  Performance
    . Solve input lagginess when the score is large.
      . Notes for this in ghc-events:
    . Reduce GHC-API memory usage: NOTE [reduce-repl-memory]
    . Look for memory leaks.
    . Make transformers lazy so they can interleave, aka
      map f . map g -> map (f.g)
  Music / design / language:
    . Clean up tracklang type checking with subtypes: e.g. ValType.types_match.
    . Solve how timing changes bubble up.  Text score can do it, or maybe
      integrate from DSL (either text score: or haskell) or have a purely
      read-only block or track.
    . Simplify scale implementation 'Why are scales so complicated'
    . Something better than ControlFunctions for randomized signals.
      . See NOTE [fix-control-functions]
    . Im
  Tests:
    . Quickcheck for derivation.
      . Or Midi.Encode_test.test_encode
      . Or Ui.Diff
    . Test Ui.Diff and Ui.Sync.
    . Properly parallelize tests.  Maybe use a Test monad instead of IO and
      make tests pure.
  . fix bugs in Util.Pretty / Util.Format
    . Or use someone else's library... printcess?
      . Looks like it only has one level of indentation.  Also I think it
        doesn't have breaks, it just always breaks on space.  And uses String.
    . Other formatters:
      . https://ocaml.org/learn/tutorials/format.html
      . https://github.com/google/google-java-format
      . https://github.com/dart-lang/dart_style
        http://journal.stuffwithstuff.com/2015/09/08/the-hardest-program-ive-ever-written/
  GUI:
    . Prettier events, smooth scrolling etc.  OpenGL?
    . TrackSignals could use y position and color / transparency.
    . Window management: automatic tiling, window manager configuration.
      OS X: https://github.com/rxhanson/Rectangle
    . Switch logview and browser to Fl_Html_Display.
  Linux:
    - Increased scroll sensitivity for the scroll wheel.  Or is that an
      X config?

UNIFY:
  - default args and controls:
    . Instead of defaulting to a ControlRef with a different name, use
      a control with the same rules as argument defaulting.
  - controls and env:
    . something=4 should be the same as %something=4.  I can remove the
      % and # syntax.
    . Unless I want to remove the VNum, I'll need to ensure that VNums never
      go into Environ.
    . That seems like it could be awkward.  What about putting Val into
      a signal, so I can get rid of Environ entirely?
    . I would need to expose TimeVector a, since Segment and interpolation
      doesn't apply to arbitrary Vals.  If I still have VNum though, I'll
      still have the ambiguity.
  - signal arguments:
    . They should all coerce to SignalFunction, with no need for
      Call.to_function.
  - controls and ControlFunctions:
    . See NOTE [fix-control-functions]
  - controls and pitch controls
    . If I can have controls of different types, then I can get rid of the
      unnamed pitch control for a normal control named pitch, and the
      (almost unused) named pitch controls become normal controls.  The
      Control / PControl divide goes away.
  + deriver arguments, transformers, and parent calls:
    . unify deriver parents:
    . I should be able to take {Note,Control,Pitch}Deriver args, which
      then coerce from Str, Quoted, or a sub-track.  If the arg is
      the last one, I should also be able to get a corresponding
      transformer.
  + unify deriver parents:
    . Wasn't I going to unify block arg and child track somehow?
    . See Parent.c_event_interpolate for the awkwardness.
    . I could do it by having a "deriver" arg that has a special typecheck
      rule: if present, then take it as a symbol, if not present, then require
      a child track at that position and return it as a deriver.
    . I could almost do as a Maybe Symbol, then
        resolve_deriver :: Args -> Maybe Symbol -> NoteDeriver
      but how would it know which sub track to look at?
    . I would have to either keep an index, or modify.
    . I also want to unify with transformer, so I can say 'call a b' is the
      same as 'call a |'.
    . I can represent a Deriver as Quoted, but it's untyped, so I don't know
      if it's a ValCall or Deriver.  I could extend Val, which is effectively
      like putting Deriver in Val, except I can avoid the circular dep by
      putting it in Derive, at which point it's only used in a restricted
      context.
    plan:
      * Implement the typecheck rule for deriver arg.
        . I can't, because it works by converting from a Val.
        . But I could take it from Quoted.
        . But I need a Derive.Context.  Make Typecheck.Eval take Context?
        . Context is polymorphic, but it's just for cxt_prev_val, so I can
          just set that to Nothing.
        . Why not typecheck to a ctx -> deriver function?  Is that equivalent
          Eval?  I think not, Eval is when I need an extra arg to typecheck,
          this is when I can typecheck, but need an extra arg to get the
          value.
        . But making instance Typecheck (Context -> Deriver) is nice because
          then I can keep the right type on Context.  I think I just have to
          have Derive.Sig try this specially, which is ok because it already
          does that for Quoted, and besides it needs special support anyway
          to keep track of the child track.
      * Derive.Sig support for Quoted or Str.
        . If I ask for type 'a':
          . See if I can typecheck an 'a' directly (Val (Just a))
          . If it can coerce to Quoted (Quoted or Str), then try to typecheck
            as (Context d -> a) or as 'Deriver a'
        . The Typecheck (Context -> Deriver) thing doesn't work, because if
          I'm to use it for type inferring, I really need it to be the
          expected type, which is e.g. NoteDeriver.  If I do it as special
          Quoted evaluation in Sig, then it will be documented as Quoted... or
          actually, it won't work at all because I need to expect some type
          to trigger the evaluation as deriver.
        . So what I need is Typecheck NoteDeriver, which means from_val has to
          return a Deriver.  But can I just return a singleton?  E.g.:
          . call expects NoteDeriver
          . so Typecheck returns Checked Deriver.  Because it loses the type
            variable, it becomes dynamically typed.
          . Now Sig has to create a NoteDeriver, which it does by evaluating
            the quoted.
        . This doesn't work because Eval.eval_quoted doesn't return any old
          'a', but a specific one.  I need to prove that a Typecheck.Derive
          is only produced for the things eval_quoted can return.  Normally
          I do that by just calling eval_quoted, but of course I don't have
          the args yet.  Existential?
        . No, but I can just return a function that takes the Context, which
          was actually the original plan.
        . It seems to work, but to set a default arg I need ShowVal
          NoteGenerator.  I guess that's not a big deal, though it's an
          invalid instance.  If I can coerce for default values then I could
          fix this by coercing from some "manual doc" newtype.
      * Derive.Sig support for child tracks.
        . Use this to clean up Parent.c_event_interpolate.
        . Child tracks go as implicit arguments on the end of Sig.state_vals,
          where it's ok if they're unused.
        . No wait, I want to *only* look at children if I have a deriver.
      . I'm no longer sure this is actually a simplification, and not just
        yet another special case.  What is gained if transformer <-> child?
        . Things like 'loop' don't work because the child is always the same
          length as the parent.  Well, it's not actually... if I make the
          child have a CallDuration, I could have it end at the last event.
          Then I could write loops inline.
        . Could I make it so the call doesn't have access to children at all,
          and it all has to come through deriver args?  Then e.g. tuplet takes
          Sig.many deriver.
        . Then maybe I could restrict the presence of children to EvalTrack,
          and take it out of Context.  That would be a simplification I think.
        . But NoteDeriver is lacking details, I also need [Sub.Track].
          I would have to have a Typecheck instance for Sub.Track too.
        . How to define Typecheck Sub.Track?  It's a different kind of
          Typecheck because it's from Sub.Track, not Val.
      * Now I get an error: "inst" arg is Maybe Str, but got subtrack.
        * Why doesn't it say what the call was?
          . I would have to catch and rethrow the TypeError in eval.
          . Wait, isn't it in the Error Stack?  Maybe just the pretty function
            needs changing.
          . It's note-track.  I don't want transformers to get sub-track args.
          . This is because they already get a single deriver arg.
        . Is it enough?  Likely no:
      - I'm not happy with the idea of these being positional arguments,
        because what about previous optional arguments?
        . Maybe I should make it an explicit category, like environ.
          Sig.subtrack or Sig.subtracks.
      - Convert parent calls to use Sig.call_sub.
        . And e-interpolate, that was the whole reason to start all this.
      - Support subtrack args in Macro and StaticMacro.
      - See if this can replace the special child track support in Make.
      - Implement transformers as a call with deriver as final argument.
        . I still want them to be in their own namespace, effectively as
          a limited form of overloading.
        . Translate the pipeline syntax into that call.

----------------------------------------------------------------------

documentation:
  - strict markdown parser, and extensible:
    . with https://markkarpov.com/post/announcing-mmark.html
    . But not ready yet (no lists or block quotes).
  - Publish haddock with http://documentup.com/feuerbach/standalone-haddock
  - Can I have Util.Linkify check the validity of single-quote links?  Or
    maybe I could run a link checker against the final output.  Otherwise
    'Module.function' references get out of date.
  - mdbook: like sphinx, but a bit simpler?
    . https://rust-lang.github.io/mdBook/
    . hledger uses it: https://github.com/simonmichael/hledger_site
  calldoc: CallDoc:
    - collapse control for modules, option to collapse / expand all
      . Haddock:
        <span id=xyz class="module collapser"
          onclick="toggleSection('n.1')">Title</span>
        <ul id='section.n.1' class='show'> ...
    / put anchors on calls and make single quotes link to calls
      . It's not quite so simple because there is module, and then call type.
        So the linkifier would have to understand that structure and search
        for one, or have some javascript, and then it would have to choose
        if there is >1 match.  Too complicated.
    / For call doc, can I group calls with the same doc but different args,
      especially different defaults?
      . Would look like:
        doc doc doc generator
        bind -- name
          args
    - I could go look through arg docs for controls and list all the controls
      that have someone listening to them in a certain scope.

oriented signals
  . This is to get rid of the Derive.C.Prelude.Block.trim_controls hack
  old notes:
    / Block.trim_controls relies on samples, I don't think it can work with
      segments.
      . What exactly is it doing, and why does it work with samples?
      . According to the comment, it's so a block final note doesn't pick up
        controls from the start of the next block.  But it seems like for many
        controls it should.
      . I think the problem is that in an arrival context, a "transpose +1"
        for the whole block is meant to include the final note and exclude the
        first one.  But since controls are always t0<=t<t1, they can't make
        that distinction.
      . But can't I solve the problem more directly?  E.g. final notes are
        effectively -0 dur, so they should get controls from <t.
      . I might even be able to solve the t0<=t<t1 problem with segments:
        have negative duration calls generate negative segments.  Then 'at'
        defaults to before the discontinuity, rather than after.
      . It seems simpler to do a hack for final notes first:
        . Note call trim controls notices when it's block-final, and gets
          constant values from Signal.at_before.
        . Really I do want the controls following the block, but just not at
          t0, though the call may just sample at t0.  E.g. pitch for gangsa.
      . Could I replace ConstantPitch with a general notion of note-constant
        controls?  I already have this in DUtil.attack_sample_note.
      . For pitch I need this to apply to transpose as well, but the set of
        transpose signals depends on the pitch.
      . Ok, so the plan is
        * Augment controls_at with Orientation
        . Signal.at_before is actually wrong for old style signals.
          at_before 2 [(0, 0), (2, 2)] should be 0, not 2.
        . Also, some kind of slicing is happening with the pitches that's
          putting the previous pitch at the same X: [(1, 4c), (1, 5c)]
          . It's an artifact of TimeVector.set.  So isn't it intentional?
          . I guess with Negative I want pitch from Positive, but the
            controls are Negative.
          . Maybe the control points should themselves have orientation, so
            I would specify that the pitch sample is Negative, which means
            it's included in the Negative query.
          . What I really want is for the controls from this block to win
            over the ones from the caller, which is what Block.trim_controls
            achieved.
          . If the notes are all negative, then I don't need cancel, though
            I do need infer-duration.  But I'd still need to pick up pitch
            from at-after, and transpose from at-before.  In this case,
            though, pitch isn't a signal, it should be directly associated
            with each note.  Continuous signals just don't work with this.
            But discontinuous ones do, they are just a bunch of <n<= ranges,
            instead of <=n< ones.
          . What if the signal has orientation, not lookup?  Then pitches
            are positive, and I don't use orientation with
            constant_controls, but put it on t-dia.
          . Negative orientation for signals is only useful at
            discontinuities.
          . I guess that gets into how this worked with deleting samples:
            since samples were all discontinuous, it was assuming there was
            a discontinuity right there.  I could actually get the same hack
            with segments by saying "if there's a discontinuity exactly
            here, then trim the signal."
          . In fact, maybe I should do that, and then look into oriented
            signals later.
        / Add Flags.block_end, and use Negative when at block_end.
        . Can I replace ConstantPitch with this?

ControlFunction:
  . NOTE [fix-control-functions]
  examples:
    . Sig.defaulted "dur" (Sig.control "damp-dur" 0.15) "doc"
      . The arg then has Control.to_function called on it.
      . I would like to say 'Sig.defaulted "dur" (const 0.15)' and get a
        Typecheck.Function, which is defaulted from %call-damp.  If it infers
        as, say RealTime, then it's still defaulted from %call-damp at the
        start pos.
      . This way all numeric values can be signals uniformly.
      . Also I'd like to be able default RealTime functions or
        TransposeFunctions, e.g. see (unused)
        Typecheck.DefaultRealTimeFunction.
      . Also I'd like to default with ControlFunctions, so I can put
        randomization on it, without having to copy that into every score.
      . Also I want duration function.  Actually maybe duration is the
        default.  RealTime duration has to be converted.
  current thoughts:
    . I want to unify controls (and pitches) such that I can ask for
      a Typecheck.Function or a single value and all constants and signals are
      accounted for.
    . I might be able to solve this if I can figure how to get literals in
      Sig.Parser defaults to work.  If I coerce to Typecheck.Function from
      signal or a val call, then I can replace ControlFunction with a val
      call.  The problem is that the default then becomes a Function, which
      means it loses ShowVal and hence documentation.
    . I still want to write e.g. a number literal for a default, so it should
      coerce from that.
    . How should it ideally be?
      . It should be part of control signals.  They display as a center-line
        plus the random range.  They can do math with other controls.  For
        this, I need: signal is a line segment, plus optional below and above
        segments.  Those are cosmetic, but are derived from the values used to
        create the signal.  The actual value is an object that supports
        'at :: RealTime -> Y', 'segments :: RealTime -> RealTime -> [Y]',
        along with the ones in Perform.Signal for transformation.
      . The implementation is Vector (Y, Y, Y), so it can sent to the UI
        efficiently.  However, transformations to that could happen lazily,
        since only some track signals are sent to the UI.  Then there's a
        'Y -> Y', or maybe 'Derive.Dynamic -> RealTime -> Y -> Y', which is
        used for 'at', and captures the randomization.  Actually I probably
        can't use the real Derive.Dynamic because due to circular imports, I'd
        have to put the Signal definition into Derive.Monad.  I could use
        a reduced Dynamic, but then I'm back to reinventing DeriveM.  If
        I really wanted to commit to that, I could make the various function
        polymorphic on a function / lens to get the specific field, like
        'zoom', but I think that's too much.
      . The "error bars" are purely cosmetic, so I can add those later (or
        not).  Then I change 'Monad.state_controls' to
        'Map Control Signal', where ControlFunction is
        (Vector Y, RealTime -> Deriver Y).  This is the like the current
        design, except I make it hard to accidentally look at the wrong
        control by putting the signal underneath.  That means they get
        replaced together, but that actually may be inconvenient, because
        I want to set the randomization (e.g. in global transform) before
        I set the control (in a track).  So maybe the current design is
        actually good.
      . In that case, I can still try to make the implementation Deriver, but
        the problem there is Val/Deriver.  What if I make Deriver a type
        argument for Val, and the complete Val type is in Derive?  In that
        case, a lot of things that depended on DeriveT now depend on
        Derive.Monad, but I don't know how bad that would be.
      . I think all these things are orthogonal to coerce/Typecheck.Function.
      . If I wanted to have "error bars", I could ask ControlFunction for
        (low, high) at each point, and if I had the graphics, even
        a distribution for a gradient.  I could memoize it in two other
        signals, if it's too inefficient.
    coerce:
      . Write Typecheck Function... I have it.  The issue is I can't use it
        without defaulting via e.g. const 4.

  control functions:
    I'm unhappy with control functions in general - NOTE [fix-control-functions]
      . More details in DeriveT NOTE [control-function]
      . They duplicate Deriver but can't use it.
      . They add another layer on top of controls that you have to take into
        account manually.
      . Also, depending on the pos means the signal is no longer a continuous
        function, and can't be displayed as a line.
      . Making calls all take Typecheck.Function was my attempt to abstract
        that away, but I wound up giving up on that because then the default of
        an optional arg would have to be a Function which is then unshowable.
        To solve this I would have to make a total 'coerce' for Typecheck.
      . Also, ControlFunctions are *not* functions, in that they don't
        describe a continuous function like a Signal does.  This is especially
        glaring if I do PitchFunction as the pitch equivalent of Function,
        but then ControlFunction and PitchFunction are completely different
        things.
      . Well, they are functions in that each input has a consistent output,
        so they can be represented by Typecheck.Function, they're just not
        continuous functions.  They have the weird property that they never
        become continuous, no matter how close you look.
      uses:
        . Randomization, with various ranges and distributions.
        . Some CFs like cf-swing could just be another signal, I only do it as
          a function for efficiency, which is due to my choice to make signals
          fully sampled.
        . A way to pass an interpolation function.  This is a disjoint use
          since it doesn't need any of the DeriveT.Dynamic state and isn't
          useful as a normal CF.
    - Could use rank to modify dyn and emphasize or de-emphasize notes on
      important beats.
    . With 'real' and 'score' and the signal conversion functions, I gradually
      rewrite more and more functions from Deriver to functions with a
      TrackLang.Dynamic argument.  Also they're going to start to want an
      exception, and why not logging too, and I'm right back to Deriver.
    . Why can't I make ControlFunction into a Deriver?
      ControlFunction moves to Deriver.Monad, so Val must also.
      Now control function stuff must be exported from Deriver, not TrackLang
      and Score.  But also Val can't be exported from TrackLang, and there are
      tons of users for TrackLang.Val.  Maybe I can split TrackLang into a low
      level version.  In fact I already have, everything Deriver uses
      TrackLang for can come from DeriveT, except Typecheck.  Monad.val_call
      must move to Lib.
      . Environ, Pitch, and Val all move into Derive.  And Score.Event.
        This is getting to be pretty much everything.
      . Another option is to make Derivers polymorphic.  I can put the
        fields in TrackLang.Dynamic in a typeclass.
  ControlFunctions are still super confusing. NOTE [fix-control-functions]
    . Yet another confusing thing is that they don't work for arbitrary
      signals given to notes.  I think it would be better to override '' to
      get e.g. %location as %location + rnd ...
    . E.g.  '%strength=.5 | %strength=(cf-rnd ...)' means it looks like
      %strength is .5, but it's actually not, and the only way to get rid of
      the CF is %strength=_.
    . Also the whole implementation is a mess.  Isn't there some other way to
      randomize signals?
    . I could pass a Quoted, and then control functions are val calls that
      return Quoteds: (cf-rnd control 0 1)
    . Then I want to be able to treat those as signals, or coerce them both
      to the same thing.  Really that's a SignalFunction, or maybe just
      RealTime -> Deriver Y.  So this turns into the problem of how to coerce
      various types into SignalFunction, but not have to have an opaque
      SignalFunction for all the defaults.
    . I could have a Convert typeclass.  In fact maybe it would be cleaner to
      split Typecheck and Convert?
      Typecheck: Val -> Maybe a, Convert: a -> b
      Convert would be: Int -> SignalFunction.
    . I think this won't work because the intermediate 'a' will be
      ambiguous.
    . I can always have a Default class that is used only for Sig defaults,
      and provides both ShowVal and the coercion.  It would mean I have to
      duplicate everything in Typecheck, unless I use an overlapping
      typeclass.  Or I could default to... what exactly?
    . The problem with `Convert a b` is that 'a' needs a type annotation,
      which would make signatures annoying to write.  Normally I don't need
      them because they are the Typecheck val, which already needs to be
      fixed.
    . Or I could have defaults be either a Typecheck val, or
      (Doc, Typecheck val), and then have an explicit constructor for Function
      which promotes various types to (Doc, Function).
    . I think this decouples the default type and the arg type... no it
      doesn't, it's only if I want to take a Function.  So maybe I have a
      constructor 'Typecheck.function :: Y -> DocFunction'
    . Or, maybe I can have Sig functions take a 'WithDoc a', and there's a
      'instance ShowVal a => ToWithDoc a', and an overlapping instance for
      something already WithDoc, for non ShowVal instances.  Actually
      I probably don't need this, put a method in Typecheck and leave it
      default if ShowVal?

    . The haskell side can have many types, whatever is most convenient.
      But the tracklang side should have just a numeric type, where literals
      and controls are the same.
  . ControlFunction should be renamed, but to what?  ControlMod is taken.

Util.Segment: linear: linear piecewise signal: signal-discontinuity:
  . Problems I'm trying to solve:
    . Need to remember to use Signal.set, and provide previous y.  Signals
      should be implicitly flat in both directions, and merging them should
      respect that.
    . Transpose signal resampling should "just work", without needing special
      'at_before' stuff.  Why does it require that now?
      . Because it gets raw samples, without treating them as segments.  So I
        could make unsignal return segments: [((X, Y), (X, Y)]
    . Awkward rules where the sample at 0 sets values before.  Or at least the
      part where it leads to errors when asking for the value at <0.
    . Include shift so I can get rid of Score.Event 'untransformed' nonsense.
      I think the problem before is having to use the shift on all signal
      operations even when it's 0 for everyone except Event seemed over
      complex.  Also that I just want a per-event offset, not one for each
      signal inside.  Though if I extend this to stretch as well, then I don't
      need a separate Warp type.  I don't think anyone except warp would use
      it though.
      . Ideally I could optionally layer it on a signal, but then I have to
        reproduce all the functions.  But I could try to make a minimal API
        in a typeclass, and have the functions be generic.
      . Could I use this to unify pitch and control signals?
    . How much would I solve just be changing (<>)?
  . If I want to replace Environ with Val signals, then I'm back to
    non-interpolated.
  . What would a typeclass + associated type actually look like?
    . It would be like Vector.Generic, only with more specialized access
      functions.
    . Maybe in general, I can give a Segment y type, and an interpolation
      function.
    . But a polymorphic interface is only as useful as the number of functions
      that can be polymorphic with it.  So what could be polymorphic?
  . If I can make signal a typeclass, I should be able to make offset (and
    maybe stretch) a wrapper.  This only works if I can reduce the interface
    to a few things like 'at'.  But I feel like all the various transformation
    functions won't allow that.  They are type specific too.

  Util.Segment:
    / I should put a final sample on for sampled curves too.  Maybe I do?
    invariants:
      / ensure that NumSignal omits redundant samples in a flat segment
        . Use or remove String_test.strip_flat
        . There's no strong reason to care about this, except to avoid writing
          redundant stuff in tests.  It's nice to not do more than necessary,
          but not worth making into an invariant.
      - Also ensure that MSignal.Signal can't get duplicate Xs.
    - Util.Segment winds up with _v vector variants.  Maybe I should make
      a whole new module with no offset, and then if I really need offset,
      make a wrapper for it.
    - Maybe rename Signal.from_sample to constant_from for a higher level
      emphasis.
  - Adding linear hurt performance
    . For cerucuk-punyah:
              max mb  total mb  derive     perform
      before: 142.58  8743.73   5.89~5.98  0.70~0.72
      after:  139.28  9827.79   6.77~6.83  1.18~1.22
    . It seems like the big jump as expected was at 'switch the signal
      implementation from piecewise-constant', but I have to go to 'linear:
      make Segment.drop_discontinuity_at insert an extra sample', since that
      fixes a serious bug.
    . Do a SCC profile to see where the time goes.  Maybe do one before to see
      if something new has come up?
    . Try to get that back.  Maybe the 'clip_before, clip_after' change above.
    . Or possibly look into optimizing vector operations.
    . It looks like the Warp change didn't have noticeable performance
      impact, so that's good.
  / optimize flat pitch segments in PitchUtil.segment
    . These would only show up in PitchUtil.breakpoints, and I only use that
      in a single val call, which I don't really use.

  reimplement:
    - Tempo.with_hybrid
      How it used to work:
        . Get RealTime for (0, 1), which is the desired duration.
        . Leave the warp signal as 0 in the stretchy spots, compose would do
          special handling.  I can't do that now that compose is just
          a function.
      who sholud be stretchy?
        1. Nonzero stretches, by ratio of its value, but 0 doesn't.
        2. Zero stretches while nonzero plays in realtime.

        Is there any difference in expressiveness?

        1, if I go 1 to 0, then it gets relatively slower within the limits of
        the block dur, until it snaps to 1:1 at 0.
        2, it gets relatively slower until it snaps to linear, but at whatever
        speed determined by the block dur.

        1, I can control the relative stretch of the stretchy bits, but
        unstretchy bits are always 1:1.
        2, I control relative speed of the unstretchy bits, like 'tempo abs',
        but stretchy bits always stretch the same amount.

        1, for grace notes, I put attack and release in as 0 tempo and have to
        place them with seconds.  Then sustain is 1 tempo.
        1, for karvai, then I put notes in as absolute time and karvai is
        1 tempo.  If I increase the the whole tempo, then karvai decreases,
        but the notes don't.

        2, for grace notes, I can put attack and release in as say 8th notes,
        but I can adjust them with tempo.  Sustain is 0.
        2, for karvai, I can adjust strokes absolute time with a tempo, and
        karvai is 0.  But the strokes are still in absolute time, so they
        don't follow the piece's timing.  Or actually they do, because I make
        the call duration appropriate.  So actually I think 1 and 2 are
        correct in the same way.

        1, I can make the stretchy bits stretch at different ratios but all
        absolute bits are in the same timing. I can't think of much use for
        it, over making the spaces twice as long.
        2, I can make the absolute bits have tempo, which is actually
        potentially usable because it becomes the same tempo "regime" as the
        toplevel.

        There is a whole other axis of difference:

        1. I coud be like abs tempo, and block tempo is still bounded by call
        dur, but not affected by tempo *changes* during its extent.

        2. Or I could say that unstretchy time is actually realtime.

        I think 1 is confusing, 2 is more useful.  Tempo changes during a call
        are just things like global accel.  I actually *do* want to let that
        through, say for karvai, it should affect the non-stretchy notes.
      . Tempo to warp: this is the same Signal.integrate_inverse, except first
        I have to patch 0 segments.
      . They become linear at a speed such that the block becomes the desired
        duration, while non-zero gets stretched such that it cancels out the
        surrounding warp.
      . That means that each block dur has to do a different warp, which is
        why it used to be in compose.
      . So I may need to add WarpHybrid to Warp.Warp.
      . Well, it needs to be a function to compose with other functions.
        The difference is that this one is

      . Called from Internal.warp from Tempo.with_tempo
    / SignalTransform.c_quantize.
      . It will have to find where segments intersect the quantize multiples.
      . Don't bother for now.

  / If I get rid of constant signals starting at 0, then Tempo.tempo_to_warp's
    constant_val doesn't work, because tracks start at 0.
    . I could move tempo track's first sample to -large, but no I can't
      because it makes integrate take forever.
    . However, with segments I probably could, but I would have to make all
      control tracks implicitly start at -large.
    . Fixed via Segment.constant_val_num from.
  ? Another way to make moving events cheap is to make event controls relative
    to event_start.
    . Surely I thought of that before, but I don't remember why I didn't do it.
    . People looking at controls presumably use Score.control_at, which can
      apply the offset for me.
    . Plain references to Score.event_controls could be error-prone though.
      I'd need a Score.event_absolute_controls, which is effectively
      event_transformed_controls.
    . I think the reason I added the offset optimization in the first place
      was that randomize moves every event.

gamakam:
  rethink gamakam:
    . Is it worth having a mouse oriented curve editor?
    . If strict division of each note duration is mechanical, can I have a way
      to push the inflection points around?  How about push them beyond
      the note boundaries?  But in what way?

  - can I bring back dynamics by having a dyn suffix to go to a certain dyn,
    maybe just at the end or beginning?  E.g.
    . !0=1>5 -- move to 1 and .5 dyn
    . !0<0== -- move to 1 from 0 dyn
    . ># is move to the dyn
    . <# is move from the dyn to 1.
  . Arvind Krishnaswamy did pitch tracking studies:
    https://ccrma.stanford.edu/~arvindh/cmt/
  . bezier-spline-modeling-of-pitch-continuous-melodic-expression.pdf
    Contact Bret Battey about PICACS: http://www.mti.dmu.ac.uk/~bbattey/
  Pich tracking with
    . tony: https://code.soundsoftware.ac.uk/projects/tony
    . praat
    - record some songs without tambura, e.g. Manasu Svadhinamaina
  gamakam6:
    - Implement suffixes for absolute time: : or ;
      . I want a move to current which is not dependent on the note length, so
        flat notes can be smoother.
      . In generality, this suggests a set of constant time movements.
    - port other tests from gamakam5 as necessary
    - When the pitch track is above, I don't hear midi thru.
      . MidiThru looks above for the instrument, if there is none above, then
        find the first one below.
    - It might be nice to collapse the sahitya track into notes.
      . Maybe just generalize collapse to take the track to the right if there
        is no pitch track below.
      . But I don't want to just merge any note track with the track to its
        right.  If I do that, collapse all will get confusing.
      . I could maybe exclude those from collapse all.
  understand the ragam:
    . I could attach code strings to raga swarams, e.g. (G, "=0").  Then
      automatically add a "default" alias per scale degree and direction.
    . How to make them scale with time?  Something like "=0" can become "=n=n".
      Actually that's incorrect, it should be an optional transition to the
      neighbor, then touch G.  E.g. N might be "=0a".
  - At least I could include gamakam notation for arohanam / avarohanam just
    as a reference.
  - I need some solution for when the beginning depends on the end of the
    previous section.
    . I could write notes after a logical stop, and say the replace whatever
      follows.
    . But this is no good if the section goes to different places.  Really
      it's the combination (A, B) that gives rise to the alternate notes.
    . Sometimes the end of A will be different depending on the following B.
  - promote a gamakam score to verify_performance
  prev pitch:
    . Originally somewhat broken, but broken in more cases by linear segments.
    . Why is prev pitch so hard?
    . Couldn't I solve all of the gamakam previous pitch problems by just
      putting the gamakam track above?  How about some cmd utils to help line up
      with notes?
      . No, because I need to get previous pitch from the previous swaram.
        Remember gamakam is now pitch + t-nn.
    . All I want is the last pitch as it sounds.
    . Why isn't that just the pitch of the previous note <now?
      Because it might actually be the pitch of the current note, just the
      previous swaram.
    . Could I simplify this by always using one note per gamakam, and then
      some other means to join them together?
      . What would that other means be though?  Event duration seems most
        natural since that's what everyone else uses.
    . Putting pitch above actually seems to solve these problems.
    . But it breaks the the until next note hack.  I can get it back by
      looking for the next pitch instead.

  - Integrate notes from the other gamakam: section in here, and unify it into
    one document describing the history with gamakam.
  notes due to linear segments:
    . This breaks '* interleave', which was always fragile anyway.
    . Can I save it with a hack?  It could get more clever, and move the
      end sample: [(0, y1), (n, y1)] -> [(0, y1), (x, y1), (x, y2), ...]
    . Or I could get rid of it entirely, if I can fill the same need another
      way.  That's where I want to have swarams and gamakam separately, so
      I interleave with the swaram track.
      . I could have the gamakams read from the swaram track, but then
        I want to get the pitch even when there is no gamakam, so I don't
        have to put a dummy call on each note.
      . The most direct way might be a track preprocessor that copies over
        swarams, or maybe adds a "!^".  I worry about how this obscures
        the usual rules of evaluation, but ! notation is already sort of
        its own language.  I'd need some special track-level macro call.
      . What if ! in a track call was a macro symbol.
        Control.d_control_track separates those out, and calls them from
        a special namespace.  I think they have to go at the front.
      . Why is gamakam not emitting a transpose signal?  I can transpose
        to another pitch with scale_read and scale_show.  But then what kind
        of transposition?  t-dia is obvious, but some gamakams are below
        diatonic.  Actually it can emit multiple signals via the
        ControlMod hack.  I can try to do everything with diatonic, but
        I do need absolute pitch deviations.
        . Speaking of ControlMod, what would it take to have a control track
          actually emit multiple control signals?
          . I guess it would have to be a new type of track, with a
            [(Control, Signal)] return value.  It's actually similar to
            ControlMod except without biased towards any particular Control.
        . So try a Gamakam5: build fragments of transpose signals.
      . But can I really use t-dia?  How do I represent alternate ga or
        something?  I think the most straightforward way is treat them as
        chromatic notes.  Then it become t-chrom.  But I think I can do
        t-dia for now, until I have that.
      . But now if I have different types of transposition, I can't go from
        one to the other, e.g. +1nn move to -2d.  I would have to flatten to
        an absolute measure like nn, but scales don't give me that.
      . I could get it though, by reducing to NN and doing a diff.
        I think I do need transposed pitches, though.
      . From would always be NN, to would be (Transposition, Step).
      . This all makes it dependent on the scale, it seems nicer to have
        all those functions just emit signals. I guess I can still do that
        if I supply a Transposition -> NN function.  The output gets kind of
        unreadable though, unless I want to emit (Transposition, Step)
        breakpoints, and assume everything will fit into that.  Might as
        well be (Transition, (Transposition, Step)), but now PCalls don't
        really do much.
      . I still need a value for discontinuities though.  It's code vs. data
        again.
      . Oh yes, and prev pitch doesn't work if I'm a control track.  But
        I can get the prev transpose.
      . Another problem is that I have to make it a t-nn track, which
        doesn't make much sense, and any other control calls wind up being
        in t-nn, which doesn't seem that useful.
      . If pitch gamakam is also in a cantrol track, I can't tell it from
        dyn controls.  Really what I want is to be able to write "gamakam"
        for the transpose, and it can set the interpretation of !.  Or even
        use a lookup so I don't need to use !.
      . Maybe this is how to do macros: track title is a lookup in
        a track-macros namespace.  If 'name' isn't found, then it defaults
        to '%name' ala LookupPattern.  Track call namespace should also be
        in the CallMaps and Library so it can be imported with modules.
        Also I think it needs note, pitch, and control variants in the same
        way.
      . As long as I'm doing this I can go back to using pitches for
        gamakam, and just copy over from the pitch track.  Not sure if
        I should though.

      . Which of these would be best for possible future kinds of notation,
        or further extension?

vector: performance:
  Is 'V.toList (V.cons x xs)' the same as 'x : V.toList xs'?
    . Not exactly, but the first one doesn't actually construct the vector.
    - If it is then I don't need Perform.Signal.clip_before_segments
  . fromList doesn't measure the list, it does exponential resizing
  Segment.to_samples:
    . Does 'V.toList . V.map f' fuse the map into toList?  It should, so
      'head . V.toList . V.map f' should be efficient.
    . Yes, it does.
  ? Do these have the same performance?
    . map TimeVector.to_pair . Vector.toList
        . Vector.filter out_of_range . Segment.to_vector
    . filter out_of_range . Segment.to_pairs
  . I should be able to get fusion if I keep things in vectors in Segment and
    TimeVector.  But to look in the future, I think I need zip, which means
    I need Storable (a, b).  The thing is, since I'm hoping the intermediate
    vectors are fused away, I shouldn't actually use the Storable instance.
    Except of course when compiling without optimization.
  . A Storable that throws an exception would be an interesting way to assert
    that fusion happens.  Surely there are more sophisticated ways though.

instruments:
  ? Follow references in tambura dafx paper.
    Wasn't there something about pluck modelling?
    . http://www.socasites.qub.ac.uk/mvanwalstijn/dafx16a/
  mesh2faust:
    . faust generates invalid C: 'inf.0f'
      . because of 7.27787e+32
    . generated nExPos is unused
    . The bells sound ok, but the marimba model is terrible.  Turning up t60,
      the spectrum sounds nothing like the right pitch.
    . Strike position changes the already-ringing instrument.  I guess I'll
      need a separate model for each position.  It's maybe ok since the model
      is linear.
    make models:
      . There are 3D scanning services, google "3d scanning services bay area"
      . Prices maybe $150 and up.
      . But maybe Stanford has this ability?  Ask JOS if CCRMA has done this
        for instruments before.
      . But I should be able to measure with calipers, then hand-draw
        a profile.
    + Try with reyong profile.
      . It has to be scaled, otherwise it's hopelessly low pitch.
      . Try resampling to a more regular mesh?
        Much better sound after resampling to 0.75, but faces are up to
        82732, taking 12:45.  Pitch too high.
      . Try with 142k, resample to 0.7 -> 94044 faces
        Took 14:40.  Pitch is much too low now, about an octave.
      . 100,000 - resample with 0.5, then Quadric Collapse Edge Decimation to
        100,000 faces
        . Took 15m
    - Try with gangsa profile.
    ? How can I get spectrogram of a real recording, to compare against
      computed modes?
      . Lots of software can do spectrograms, what's a good one?
    Ask Romain:
      . Output sound is nothing like what I expect.  Advice?
      . How to add decay times?  Each mode should have a different decay,
        time, so isn't setting one for them all inaccurate?
      . Changing the strike position affects the ringing sound because it
        reconfigures the resonators.  But I should be able to have that only
        affect how much energy goes into resonators, right?
      . Any examples of use other than those bells?
      . Did the faust output sound like the real bells?
      . Does faust use restrict / -fstrict-aliasing?
        https://cellperformance.beyond3d.com/articles/2006/05/demystifying-the-restrict-keyword.html
    How does the faust implementation work?
      . pm.modeFilter(freq, t60, gain)
      . For each modeFreq, make a pm.modeFilter with that frequency.
      . modeT60s is derived from the frequency divided by some constant,
        which is modesFreqs[highestModeIndex] / modesFreqs[lowestModeIndex].
      . modeGains is just a 2d array gains[pos][mode]
    build mesh2faust
      . /nix/store/3mz7af1vnpr0z3r8ssfiqvlchjll60s3-mesh2faust/bin/mesh2faust \
        --infile marimbaBar.obj --nsynthmodes 50 --nfemmodes 200 \
        --maxmode 15000 --expos 2831 3208 3624 3975 4403 --debug \
        --freqcontrol --material 1.3E9 0.33 720 \
        --name marimbaBarModel
      . Seems to link but then segfaults after:
        Starting the eigen solver
        200 modes will be computed for the FEM analysis
      . Try with non-nix build.
        Still segfaults.
      . Then do the usual segfault debugging.
      . It's in libarpack, I could try compiling my own for that too.
      . And now it's crashing with SIGSTOP, but it's still -11, which is
        SIGSEGV.
        . frame #0: 0x0000000113580d52 libopenblasp-r0.3.5.dylib`dlarnv_ + 338
          frame #1: 0x0000000106681722 libarpack.2.dylib`dgetv0_ + 1650
          frame #2: 0x000000010667c4a2 libarpack.2.dylib`dsaitr_ + 3602
          frame #3: 0x000000010667dde6 libarpack.2.dylib`dsaup2_ + 1622
          frame #4: 0x000000010667eaf6 libarpack.2.dylib`dsaupd_ + 358
          frame #5: 0x00000001065baada mesh2faust`ARPACKSolver::SolveGenEigShInv(SparseMatrix*, SparseMatrix*, int, double*, double*, double, int, int) + 1146
      . Or find the docs for that function and look for obvious mistakes.
      . Last flag is verbose, set to 1:
        Linear solver: PARDISO (1 threads).
        Converting matrix to Pardiso format...
        Reordering and symbolically factorizing the matrix...
        Factoring the 13548 x 13548 matrix (1 threads)...
        Factorization completed.
        Dimension of the system            : 13548
        Number of 'requested' eigenvalues  : 200
        Entering the ARPACK eigenvalue routine...
        <SEGFAULT>
      . That's the call to dsaupd_()
      won't compile on newer mac:
        error:
          In file included from vega/libraries/matrix/matrixProjection.cpp:31:
          In file included from vega/libraries/include/lapack-headers.h:7:
          In file included from /nix/store/s0kpwbrdhl0lhdi2prnxn670sgl3n097-apple-framework-Accelerate/Library/Frameworks/Accelerate.framework/Headers/Accelerate.h:24:
          In file included from /nix/store/s0kpwbrdhl0lhdi2prnxn670sgl3n097-apple-framework-Accelerate/Library/Frameworks/Accelerate.framework/Frameworks/vImage.framework/Headers/vImage.h:291:
          In file included from /nix/store/s0kpwbrdhl0lhdi2prnxn670sgl3n097-apple-framework-Accelerate/Library/Frameworks/Accelerate.framework/Frameworks/vImage.framework/Headers/vImage_CVUtilities.h:63:
          In file included from /nix/store/jwjfnk9vrvsqxnwrc1g6932fxhf03wc2-apple-framework-CoreVideo/Library/Frameworks/CoreVideo.framework/Headers/CVPixelBuffer.h:23:
          In file included from /nix/store/jwjfnk9vrvsqxnwrc1g6932fxhf03wc2-apple-framework-CoreVideo/Library/Frameworks/CoreVideo.framework/Headers/CVImageBuffer.h:27:
          In file included from /nix/store/llbk4v2v1qqj462qlkb4nf3lvm5lyxdd-apple-framework-ApplicationServices/Library/Frameworks/ApplicationServices.framework/Headers/ApplicationServices.h:23:
          In file included from /nix/store/apf2lhavmgsdh5lkk9shx1fkf6pkj0x3-apple-framework-CoreServices/Library/Frameworks/CoreServices.framework/Headers/CoreServices.h:39:
          In file included from /nix/store/apf2lhavmgsdh5lkk9shx1fkf6pkj0x3-apple-framework-CoreServices/Library/Frameworks/CoreServices.framework/Frameworks/LaunchServices.framework/Headers/LaunchServices.h:22:
          In file included from /nix/store/apf2lhavmgsdh5lkk9shx1fkf6pkj0x3-apple-framework-CoreServices/Library/Frameworks/CoreServices.framework/Frameworks/LaunchServices.framework/Headers/IconsCore.h:23:
          In file included from /nix/store/apf2lhavmgsdh5lkk9shx1fkf6pkj0x3-apple-framework-CoreServices/Library/Frameworks/CoreServices.framework/Frameworks/OSServices.framework/Headers/OSServices.h:27:
          In file included from /nix/store/apf2lhavmgsdh5lkk9shx1fkf6pkj0x3-apple-framework-CoreServices/Library/Frameworks/CoreServices.framework/Frameworks/OSServices.framework/Headers/CSIdentity.h:43:
          In file included from /nix/store/8c262vkjk333nvlwbxj3d6j7r0hj49kw-apple-framework-Security/Library/Frameworks/Security.framework/Headers/Security.h:28:
          /nix/store/8c262vkjk333nvlwbxj3d6j7r0hj49kw-apple-framework-Security/Library/Frameworks/Security.framework/Headers/SecCertificate.h:135:54: error: unknown type name 'SecCertificateRef'; did you mean 'SecCertificate'?
          CFDataRef SecCertificateCopyNormalizedIssuerSequence(SecCertificateRef certificate)
                                                               ^~~~~~~~~~~~~~~~~
                                                               SecCertificate
        . How does the header differ from the official Accelerate header?
        . But it works to include on its omn.  But that's the official one.
        . Accelerate.h is the same.  vImage.h is different.
          Except nix is older:
          < Copyright:  Copyright (c) 2000-2017 by Apple Inc. All rights reserved.
          > Copyright:  Copyright (c) 2000-2018 by Apple Inc. All rights reserved.
        . nix has links to /System/Libraries, why aren't the headers links?
        . This is clearly on purpose, see if I have old nixpkgs, or if there's
          reference to Accelerate not working on darwin.
        . Could I pass -F/System/Library/Frameworks to link impurely?
      also segfaults on linux:
        Intel MKL ERROR: Parameter 3 was incorrect on entry to DGEMV .
        #0  0x00007f261d541dd8 in dgetv0_ ()
         from /nix/store/0n2bwlvsyilsnf4k7nssvh2jmjpmzr9b-arpack-3.7.0/lib/libarpack.so.2
      . Try a totally non-nix build, with manually installed arpack and mkl.
        . mkl is just the same as downloaded from intel.
        . ==> Installing dependencies for arpack: eigen, isl, mpfr, gcc, hwloc,
          openssl@1.1, libevent, open-mpi and openblas
        . It works against brew arpack, so something is wrong with the nix one.
          . Is the brew one from arpack-ng?
          . Yes: https://github.com/opencollab/arpack-ng/archive/3.7.0.tar.gz
          . Nix is:
            version = "3.6.3"
            https://github.com/opencollab/arpack-ng/archive/${version}.tar.gz
          . Try making a derivation with the same version as in brew.
          . What other differences are there?  gcc vs clang maybe...  but no,
            I crash as long as I link to nix arpack.  Of course nix arpack might
            have been compiled with gcc?
      . I think it worked as soon as I used brew arpack.
      . This is alarming though:
        post-installation fixup
          patching script interpreter paths in /nix/store/sjy5zlnl0pgbzyniwsbrz398hf11xz74-mkl-2019.3.199
          error: install_name_tool: changing install names or rpaths can't be redone for: /nix/store/sjy5zlnl0pgbzyniwsbrz398hf11xz74-mkl-2019.3.199/lib/libmkl_cdft_core.dylib (for architecture x86_64) because larger updated load commands do not fit (the program must be relinked, and you may need to use -headerpad or -headerpad_max_install_names)
      . even if nix uses brew libarpack.a, I get:
        ld: warning: object file
          (/nix/store/d9i5jrymmbbrk40s0gp7jn98d4s0ia9c-libarpack.a(dstqrb.o))
          was built for newer OSX version (10.13) than being linked (10.12)
        Undefined symbols for architecture x86_64:
          "__gfortran_st_write", referenced from:
              _dsaupd_ in d9i5jrymmbbrk40s0gp7jn98d4s0ia9c-libarpack.a(dsaupd.o)
          etc.
      . turns out I have to link to arpack dynamically, who knows why static
        linking has that problem.
  faust:
    - https://github.com/resonantdsp/SwankyAmp
      https://www.resonantdsp.com/index.html
    - drone from https://puretones.sadharani.com/
      . Are they willing to share?
  fluid:
    . sf2 from https://github.com/FluidSynth/fluidsynth/wiki/SoundFont
    . fluidsynth -a coreaudio -m coremidi -o midi.portname=fluid FluidR3_GM.sf2
  zynsubaddfx:
    . The old binaries don't have VST.  The new ones do, but the UI seems
      buggy, most UI elements don't respond to the mouse.
    + First have to compile zynsubaddfx
      . It doesn't like fltk 1.4: have to add include <FL/platform.H>
      . It requires libmxml 2.12, not 3
      . It requires fftw3, brew wants gcc, so compile myself.
      . For some reason, I get HAS_X11, which is wrong.  This apparently is
        from fluid, and uses Pixmap, which is presumably X11-only.
        Who is setting that?
        . It's because some macs have /usr/X11.  Don't know how to get cmake
          to not latch on to that.
      ? The official build scripts want to compile with gcc.  Try without, to
        see what exactly is gcc-specific in there.
      . It doesn't need gcc.  I should do the compile with nix though.
  vsts that support mpe:
    . http://www.musicdevelopments.com/syne.html

synth: im:
  StreamAudio directly to remove DAW + VST requirement
    . I could do automatically if there's no play-cache instrument.
    ? Does the blocking API write enough in advance that I don't have to
      worry about mixing a lot of tracks?
  performance:
    -. event loop hiccups when editing im
      . use events to find who is causing it
      . Have to reproduce first.  Do some normal editing.
    - Make some profiles for memory use and time.
  + It seems like ImGc is too eager
    . If I disable an old track, it deletes it right away.
    . Shouldn't it have touched all the timestamps when it hit that track?
    . Make sure Lib.Checkpoint does that.
    . I think it still has this problem.  Have to get im_gc to log what it
      deleted and why.
  optimize low level sapmles: avx: simd:
    - use simd in play_cache
      . It's probbaly IO bound, so kind of pointless, but still good for
        learning.
    - use simd in Util.Audio
      . What do I do that could use it?  Multiplication and things?  Does
        vector already do those?  If not, surely there are array libraries
        that do?
      . Not vector: https://github.com/haskell/vector/issues/251
      . State of simd:
        https://www.reddit.com/r/haskell/comments/7wsb54/state_of_simd_support_for_ghc/
    . https://cellperformance.beyond3d.com/articles/2006/05/demystifying-the-restrict-keyword.html
    . https://ourmachinery.com/post/writing-a-low-level-sound-system/
    - compile with -fstrict-aliasing and -Wstrict-aliasing
      . Clang apparently doesn't implement -Wstrict-aliasing.  It could lead
        to undefined behaviour, so don't do it unless I have profiling.
      . I might be using type punning for libsamplerate and faust state
        restore.  Not sure if that violates strict aliasing.
  fix ugly and unsafe non-copying state:
    . NOTE [audio-state]
    . The problem is that state can be large.  For sampler and
      SincMediumQuality, around 230kb, which gets up to 2mb for 10 concurrent
      sounds.
    . This is exacerbated by the fact that I get state for every block, while
      I only use it for every chunk.
    . Also the IORef shennanigans are unclear and unsafe.
    solution:
      . Change Audio to 'Stream (Of (State, Block))', then IORef goes away.
        It has to be present always, so the audio functions are interoperable,
        but should be polymorphic, since most won't affect it.
      . But I actually need [State], and Audio.mix will have to merge them.
      . But I actually need [(Key, State)], where I can use Key to
        initialize a restart.
      . The state has to be a monoid at least, because I need to make empty
        ones when I split blocks.
      . Now I can have File.writeCheckpoints save the states.  Specify that
        they represent the state at the beginning of the chunk, not the end.
      . But not all state can just by ByteString, e.g. resample is actually
        two of them, or rather (ByteString, Ptr).
      . And I think I still need explicit [state], because I need the note
        hashes.
    unsafe bytestrings:
      . This is still unsafe if I'm using mutable memory.  I could at least
        reflect that in the type with a Ptr State or IORef State.
      . It sort of galls that I'm doing lots of work in Audio to preserve
        state across splits and things, but if I want to use shared memory
        I can't use any of that anyway.
      . Ideally I could have ownership, to enforce that downstream is done
        with it before upstream uses it again.  I could do that manually by
        making them MVars.
      . Or I could just do the copy.  Even 10mb of memory copies really quick.
        Once I have memory and time profiles, see if there's a significant
        difference between unsafe and safe.
  bug:
    - progress steps seem too small for sampler at least
      . Just make them bigger, or make faust and sampler different?
      . Why did I make them smaller than chunk size anyway?
    + error in PeakCache:
      . cc 0/27 chunks: im/cache/sketch/21-01-10-cengceng/untitled/b3/cc
        (0.05 cpu / 0.04s)
      . fltk/PeakCache.cc:161 opening
        im/cache/sketch/21-01-10-cengceng/untitled/b3/cc: File contains data in
        an unknown format.
      . Was it trying to open the directory?  The filename comes from
        im-sampler via karya... how did it get the wrong filename?
      . PeakCache load_file -> Track.WaveformChunk  ->
        PlayC.im_waveforms_completed -> Msg.ImWaveformsCompleted ->
        Performance.make_status
      . The only way I can see that it could happen is that the 000.wav
        symlink is created pointing to '.'.
      . Unfortunately I can no longer tell since presumably the next run
        replaced the symlinks.
      . Put logging in to try to catch this next time.
      . The first time Directory.getSymbolicLinkTarget returns "", the next
        time it's correct.  Checkpoint.linkOutput tries to avoid it by
        using rename, how could it ever have an invalid value?
      . It just dispatches to Posix.readSymbolicLink, which is just
        readlink(2).
      . Is getSymbolicLinkTarget really returning ""?  If Track._filname is
        always absolute, then that's the only option.  The log showed the
        result is absolute, so it must be so, unless the link was created
        with an absolute path.
      possibilities:
        . something else makes a bad link in there before it gets replaced
          . linkOutput is the only haskell call to createFileLink.
            And it has ("checkpoint"</>) hardcoded, so it can't make an absolute
            link.
          . ImGc is read-only for links.
        . Checkpoint.linkOutput makes a bad link, to "" or absolute.
          . Could fname be bugged due to unsafe?
          . Possible, but it doesn't explain how the link gets fixed...
          . Also it should have been forced by the previous writeState.
          . Also the symptom of state changing would be it has the wrong hash,
            not that it's "".
        . readlink fails somehow, and it turns into ""
          . Not sure how to debug this then.
        . rename is not atomic, there's an invalid symlink for a moment
          . It totally should be.
    - kendang wadon loud de makes reaper mute
      . What's the limit?
      . It's Prefs->Audio "Automatically mute any track"
      . But maybe I'm playing it too loud, why would it be at +18db?
    - also kendang dynamics are wonky:
      . ^ is too quiet
      . OSC thru plays normalized, lots of hiss
    + A no-op change to tempo rerenders everything, e.g. insert a ' somewhere.
      . Controls in general are causing previous notes to rerender.
      . It's because I don't trim the signals before doing the hash.
      . For faust, I can trim signals to the start of the next note, if I
        can assume they are not relying on previous state.  Well, next note
        with the same element... but this means notes rely on previous state.
      . For samples, I can trim signals past the end of the envelope.
    - starts are getting cut off again
      . Give more lead time to load the samples?
  merge faust-im and sampler-im:
    integrate faust processing into sampler:
      One way is per-sample, with an independent processor for each sample.
        . In this case it goes in RenderSample.render.  Each note has its own
          faust state.
        . Appropriate for effects I want to scope per-note: comb filter,
          individual reverb, etc.
        . It breaks duration calculation because a processor might extend the
          duration indefinitely!  I could get around by forcing each processor
          to export t60 decay value, and cutting off after that.  This means
          that a processor will extend each sample duration by some static
          amount.
        . Of course many processors are not so simple, but it's a performance
          tradeoff: longer decay means more rerendering, shorter decay means
          notes are cut off.  This is like MIDI decay, except stricter because
          it actually has to cut off the notes.
        . The faust state has to get integrated into the per-note state.
        . This way each note responds to independent faust controls.  The
          controls go into Sample, from convert.
      Another way is one processor for the instrument.
        . In this case, it goes on the output of Render.render.
        . The faust state is saved and restored along side the note states.
        . Controls are instrument-global, so they have to be extracted from
          each Sample and merged, like faust-im has to do.
      . Let's do one processor first.
      I'll need an Audio binding for faust as processor.
        . I want to reuse Patch.h
        . But PatchT is not quite right, I don't need _impulseGate and
          _inputControls, but input count should be 1 or 2.
      integrate into Sampler:
        - maybe rename effect controls to have the effect name as a prefix to
          avoid collisions?
        - How can I configure an effect onto an existing patch, apart from
          hardcoding?
          . I'd want to be able to apply it as a dynamic config.
          . Maybe I can use env val in the sample?  But it's per-instrument.
            I don't really have any per-instrument config that gets
            serialized.
          . I get that effect for faust with the "initialize" notes, I could
            do the same thing here.
          . Would it be better to move to explicitly serializing an instrument
            config?
        - Have a separate effect-gain, or wet/dry mix.
          . If it's 0 I can remove the effect entirely.
          . I guess this is only possible if it's 0 for the whole piece, and
            in that case I might as well use the dynamic config and remove it.
          . There could be a block-level optimization to just pass input to
            output.
          . I'd have to know which control correspods to true gain.  For
            traditional effects which are mixed in, that can just be the
            effect gain, which is controlled outside of faust.

  progress:
    waveform display:
      - percussion is too thin, tends to become invisible when quiet
        . Use log display instead of linear?
      - handle variable tempo
        . I can do this with speeds at regular ScoreTime, or breakpoints at
          regular RealTime.
        . Speeds seems nice because it's ScoreTime resolution, which is what
          I want.  Also it doesn't care how long the chunk is supposed to be.
        . On the other hand, ScoreTime is totally arbitrary.  If I choose
          0.25t, it will be too low if a note is shorter than that.  RealTime
          determines where I'm likely to have zoom set.
        . Can I detect constant tempo and only emit one point?
  cleanup:
    - put ScoreTypes.Instrument and ScoreTypes.Control in a Shared.Types so
      im and seq can use the same types.
      . On the other hand, maybe they should remain different.  Synth Control
        at least is different in that also includes pitch.  Also Instrument
        is a score-only.  Even though it winds up in Note.instrument, it's not
        really in its original context any more.
    - I can maybe also just replace unchecked_control with Control, and
      make both Instrument and Control have checked_* constructors.  I can't
      really enforce Id.valid rules, except at score parsing time.
  overview:
    . Overview: Karya has to emit damage ranges, and the synth has to
      rerender just those sections.  The cache becomes a sequence of wav
      files, which play_cache concatenates as it plays.
    . Propagate score damage up to the im perform step.
    . Instead of writing all notes as one big chunk, only replace the notes
      that changed.  I'll need some kind of time-indexed data store for
      this, possibly just a directory of files with timestamp names.  The
      main thing is that it supports delete and insert a time range of data.
    . Im synthesizers get (instrument, time_range) to rerender, and only
      read and render the Notes in that range.
    . Similarly, the wav cache also needs to be time-indexed to replace the
      specific chunks.
    . This means the synthesizer needs to be able to segment its output.
      . For faust-im, I can store the current state with each chunk, so it
        can restore that state when restarting at that time.
      . For sampler-im, I might want to take the same approach, only the
        state is the currently sounding samples and their offset.  If
        there are effects like reverb or filters then I save the state in
        the same way as the faust stuff.
    . I only did the first part with damage ranges, and then did the
      synthesizer output part, and it turned out to be fast enough.
  performance
    - Profiling for time and space.  It should take constant space.
    - fast serialize / deserialize
      If I'm going to serialize Notes, then serialize / deserialize should be
      fast.  But Data.Binary is not fast, at least according to dons CBOR talk.
      . I'd like to be able to directly write and read control signals, e.g.
        send the pointer to the OS write() call with no intermediate steps.
      . Or I can map directly with vector-mmap.  For that I need to record the
        offsets in the file.
      . On the other hand, if I'm doing incremental rerender, then it's not so
        critical.
  incremental rendering:
    hash and checkpoint based rendering?
      . I can skip rendering a block if the note hash and state are the
        same.
      . Compare Note hashes with checkpoints.
      . Later I can use track damage to narrow the range down to a block,
        but I'll need hashes to see what to rerender within the block.
      . Also, I need to compare states to render due to state, e.g. string
        energy.
      . For cheaper instruments, especially realtime ones, it might be
        cheaper to just rerender, than to check hash and state.
      . Also I may never get back to the original state, so it may be
        pointless comparing all those states and hashes, just rerender the
        rest of the score.  The problem is that I don't know when the state
        is "close enough".
      . This implies that any modification winds up rerendering the rest of
        the score.  So maybe I should take the MIDI backend approach, and
        render on demand, but ahead of the play point?
      . But this means I have to be real-time or greater, all it does is
        eliminate the latency problem.  And since I could start playing
        anywhere, I don't know where to render to.  MIDI doesn't have this
        problem since it's definitely faster than realtime, doesn't have the
        stateful thing where a change invalidates everything afterwards.
      . And while faust state may never sync up again, I think sampler
        should be able to, as long as I leave reverb and effects out of it.
        That means I have to do those realtime, or maybe just ignore their
        state, at the cost of discontinuities at the join points.
        . Actually as long as reverb and effects are deterministic, why
          shouldn't they line up again?
    - Propagate score damage up to the im perform step.
      . I have to change it from ScoreTime to RealTime though.
      . By the time I get to Performance.evaluate_im, perf_damage is empty.
        Maybe I have to stash the old damage?
      . Do I need to keep Derive.state_control_damage?
      . Then there is Derive.state_score_damage, from the caller.
      . Since ControlDamage is inferred during derivation, I think I need to
        collect it in Collect.  At that point I may already have RealTime.
      . I think I can do it in the note track deriver, store
        (TrackId, Ranges RealTime), which is the union of state_control_damage
        and state_score_damage.
      . Of course the fact that I'm evaluating the track at all means I missed
        the cache.  I can't just emit the track range though, because then I'd
        always just get everything from the top level.
      . I want to only emit damage for the ranges which are not above block
        calls, because the block call may have a tempo which modifies the
        range.  Control damage may also be expanded, but since it's always an
        expand, redundancy isn't such a problem.  Still, inefficient.
      . So, that's a problem.  Ultimately, it's the Score.Notes that matter,
        but if I just emit damage for rederived Score.Notes then I miss
        deleted ones.
      . Ok so since track is the lowest cache level, eventually I hit a track
        which is a complete miss.
      . If no damage, then hit, nothing is evaluated.
        If damaged, then evaluate, but that block or track in turn may hit
        other caches.  So maybe I want to damage the whole track range, but
        then subtract out the hit ranges.  Since I always rederive the root,
        actually the whole thing is subtractive, so I might as well just
        collect *undamaged* ranges, and then invert it.
      . This damage informs what note ranges I serialize and replace on disk.
        I also write them to a per-root file so the synth knows which have
        been replaced.  This also has to accumulate in case multiple edits
        happen before a synth completes successfully.
      . Damaged chunks will wind up being at the track level, which should be
        fine for just serializing Notes, but if synthesis is expensive I may
        want something more finely grained.  If I break the note serialization
        into time range chunks, I can store hashes of each file and the
        synthesizer can then skip ones whose hash hasn't changed.  This is
        kind of a time-based memoization.
      . I need synthesizer state in the per-chunk metadata anyway, so it would
        look like (InputHash, State).  Compare the InputHash to the current
        file contents, and if it differs, run the synth with the given state
        to make a new file.
      . At this point, it's likely that the State for the next chunk has also
        changed, so this might lead to evaluating the whole rest of the piece.
        I could either accept that (assuming most edits are at the end), or
        try to minimize it by allowing a "close enough" States to be
        considered equal.  What exactly this is requires internal synth
        knowledge, and it might be hard to figure out if the state is a bunch
        of faust-generated caches.  I could assume the values have a vaguely
        linear effect on the output and just do approx equal by eta.  It might
        be ok if there's a slight discontinuity at the transition just for
        auditing purposes.
      . If I'm rerendering asynchronously, especially if I do the "evaluate
        the rest" approach, I might want to preserve the work if the rerender
        is killed.  Instead of writing and updating the whole output cache,
        I would replace chunks atomically, and if the synth is killed, rely on
        the damage and memoization mechanism to notice that the bits I didn't
        get to are still dirty.
      . I should be able to play past the rerender point, presumably there
        would be a discontinuity and then all would be well.
      . In fact, if there will be a discontinuity for both this approach and
        the "close enough State" heuristic, and I want the effect of the
        heuristic without the fussy per-synth heuristic and "permanent"
        pollution in the output, I could just stop rerendering once I get
        sufficiently past the end of the damaged range.  If the problem is
        battery use, I could stop entirely, if it's interactive latency
        suffering due to contention, I could bump up the nice.  Unlike the GHC
        runtime though, the OS should be pretty good at prioritizing
        interactive processes over background ones.
      . All this is making me think I should remain with the single mutable
        output cache idea instead of writing a new one and atomically
        switching to it.
      . One thing is that the Derive.Cache is only down to track level.  But
        I'd like to know exactly where on the track is the damage.  That's
        basically the ScoreDamage.  The reason I can't just directly use
        ScoreDamage is that I also need to take ControlDamage into account.
        But I don't want ControlDamage directly, I want the ranges of notes
        invalidated by it.  Hence using the cache.
      . Maybe I can have the cache emit the exact range, even though it's just
        checking if it overlaps with the cache.
      . But that doesn't work if I'm doing the inverse thing, where I remember
        the hits and then invert it.  Why am I doing that again?
      . Actually, never mind all of the above.  This damage is just for
        re-emitting Notes.  I can do a separate per-block cache to do
        a minimal rerender.

      . Ok, so the plan is:
        * Derive.Cache marks that bits that hit the cache.
          . That's already in logs, but I should stick it in Collect.
          . Maybe as a side-effect I can get rid of the log parsing for cache
            stats.
          . For hits, I collect (BlockId | TrackId, Ranges RealTime).  I can
            collect just as a list and merge them later, or merge them
            in-place in Collect.  Eventually what I want is
            Map TrackId (Ranges RealTime) and count of hits (for logging).
            It would also be nice to have the cached event count, since
            current logging has that.
          . If I switch to putting Collect in LEvent, then I think this kind
            of question becomes moot.  Also I should be able to collect into
            a list via cons, rather than (++) on subtrees.  I think that's
            equivalent to the dlist transform, in some way.  Anyway, this is
            support for Collect in LEvent being worth doing.
        - Perform.Im.Convert inverts that and writes it as damage.
        - Write a disk-backed time indexed DB.
          . Implemented as a directory with time-stamped files.  For
            simplicity, put each note in its own file, but maybe I'll want to
            combine them later.
          . Not sure though, surely modern filesystems can handle this fine?
          . But if I'm not doing incremental write at the moment, then why do
            I need this?
        - Once this stuff works, add misses to CacheStats, and replace the
          log msg parsing hackery.
        . It turns out writing the whole score each time is pretty fast, so
          I haven't been motivated to complete the above.
        * But first: make render incremental.  I need to do the whole save
          states thing for this.
    - Restart skipping chunks if the state converges again.
      . How likely is this to happen?
      . Probably it will never happen if there are any IIR effects, though
        for the moment I don't have any of those.
  preview: thru:
    - why two "streamLoop wait" after samples run out?
    overview:
      . Im instruments should have a midi thru-like preview sound.
      . This doesn't have to be performance-level of low latency,
        probably < 100ms will do.  Still, the lower the better.
      ? Experiment with how various latencies feel, so I know my target.
      . If I do hybrid im and MIDI: below then I need to make play_cache into a
        little sampler, which just means streaming through libsamplerate.
    possible designs:
      parallel MIDI:
        . Assign a parallel MIDI instrument for thru.
        . All I get is the right pitch and possibly similar instrument sound.
        . Probably in practice I'd just have a single MIDI instrument with
          a neutral sound.
      hybrid im and MIDI:
        . A compromise would be a general mechanism to render samples, and
          then feed that into a realtime sampler.  Of course commercial
          samplers can do that but would insert a lot of manual work into
          the process.  So maybe I can write a minimal MIDI VST sampler.
        . All it needs to do is play a sample with a given pitch (pitch bend
          and pitch) and velocity.
        . For this, I need to prepare each instrument by rendering a set of
          example samples.
        . I don't want to have to encode notes as MIDI, so just have
          play_cache open a socket, which takes a filename and pitch and
          immediately plays whatever it gets.  All I have to do is teach
          play_cache to resample and maybe scale volume.
        . Maybe I just run the convert function, and then take only the
          Sample.filename, and send it to play_cache.
      pure im:
        . I have to give a single Note to the im synthesizer, which then has
          to stream to the VST, which has a socket to immediately play
          samples.
        . I might have to run im synthesizers persistently to avoid startup
          overhead.
        . Presumably I also have to ensure they use a sufficiently small
          block size to get that first block out quickly.  Since I'm not
          doing realtime control, I don't actually care about the rest of
          the blocks.
        . This is more complicated, but is accurate for the instrument:
          I get the right sounds so I can e.g. see how sampler-im picks
          samples in realtime-ish.  However, if I go this far, it might not
          be that much more work to go for the full realtime interface.
      realtime interface:
        . This is basically try to turn im into a realtime interface.
        . The difference with the previous is that I'd also support realtime
          control signals.
        . The reason to want this is that I could explore instruments
          interactively.
        . I would probably have to take MIDI or OSC, run the im synth
          persistently, and either stream to the VST or directly to audio
          out.
        . I'd have to plan out a general purpose interface.  Synthesizers
          that use knowledge of the future would have to be adapted to not
          having that.
    refactor thru:
      . Motivated by thru doesn't work in kendang-legong:
      . MidiThru does an eval, I should do the same for im thru.
      . The im version of that is eval to Score.Event, then convert.  Don't
        I already have to do that though?
      . No, it directly gets pitch, dynamic, attrs and makes a new Note for
        it.
      . I could continue down this path by having a special thru for kendang
        pasang that dispatches samples, but that seems less sustainable than
        evaluating the expression.
      . Does it evaluate?  I see scale_input_to_nn.  It's because it comes
        from attrs and pitch only, not a real event.  Then how does kendang
        pasang work?  Or rather, how should it work?
      . The instrument turns keys into attrs.
      . The eval isn't in MidiThru, it's in CUtil.expr_midi_thru!
      . Actually im thru already evals the expr, so the attrs should be
        correct, I just need the instrument.  MIDI works because it already
        has the instrument address in the MIDI channel.
      . Just having inst is not that helpful, because I need to map it to
        its thru function.
      . If the instrument has changed, then look it up and dispatch.
      . To do this like MIDI, I have to go to Score.Event, then to
        Note.Note, then somehow look up patch.  That's tricky because
        normally I do that through an entirely separate process.
      . Or, pass the Note to the thru function?  The key thing is I have
        PatchName, not InstrumentName.  That just comes from resolving the
        instrument.  I can do that in CUtil.
      . There's still a disconnect, because PatchName is still across the
        whole synth, and in fact I might get an entirely different synth.
      . For the kendang pasang case, I can stuff the tuning into the attrs,
        but this is specific to kendang pasang.  If I have a generic dummy
        instrument that's not part of any synth, it won't work.
      . To really eval, I need to have the thru function in the patch map.
        Which I actually do... so why not look up instrument, and get the
        thru function out of that?

      How does thru work?
        . I get an InputNote Msg, which goes to MidiThru.cmd_midi_thru
        . If the inst has a ThruFunction, it calls it directly.  Otherwise,
          it uses scale_input_to_nn to get a pitch and creates the pitch
          with MIDI.
        . For drums, instead a key generates an expr, which I evaluate to
          produce (nn, dyn, attrs).  For MIDI, I run Perform to get the MIDI
          and write it.  For im, I call a provided function to convert to
          OSC.
        . That means drums don't have a ThruFunction, since it comes by
          another route.  This is confusing, but it's a result of how I have
          a built-in default pitch-oriented MidiThru.
      How should thru work?
        . There are two kinds: pitch oriented keyboard, and Attributes
          oriented drums.  Then there are three backends, MIDI, im, sc (osc).
          It's all keyed off of an instrument.
        . So each patch can have a field for thru.  If it's pitch and MIDI or
          sc, then invoke the whole NoteEntry.cmds_with_input set.  Actually,
          this set is complicated, because it's pitched note entry, not just
          thru.  So actually each patch has a field for general note entry.
          But it's not keyed by instrument, but by track, since there are
          control tracks too.  So I only want Info.Note tracks with an
          instrument, the others continue to use the same Cmd.Track
          mechanism.
  / I think I want to switch from by-instrument muting to by-track, because
    that's what the UI is.
    . TrackId is not unique.  PlayUtil.filter_track_muted filters out any
      event that appears in the stack.  This is so mute on a track also mutes
      any children.
    . The problem is that tracks are hierarchical and I can mute at any
      level, but the im cache is flat, except the root block.
    . Or rather, tracks start and stop, while I currently divide
      per-instrument vertically.
    . This implies I would have to keep intermediate output of each track in
      each block, which is a pretty big change.
    . So maybe keep mute as instrument mute, and I can get just track via
      disable, at the cost of a rerender.  But if I keep a few previous
      renders in the cache, I can alternate quickly.
    notes:
      . And it's more flexible, I can put multiple instruments on one track,
        or split a single instrument across multiple tracks.
      . The track enforces non-overlapping notes, but the faust implementation
        assumes non-overlapping instrument notes.  To make faust line up with
        tracks, I'd have to allocate by (TrackId, Instrument), then mix together
        all the instruments on the track.
      . I think the sampler can go by-track without further hassle, since it
        doesn't have state across notes.
      . Also, I don't trust using namespace/ident as a unique name for a block.
        Lots of scores have the same namespace, and while it sort of defeats the
        purpose of the namespace, that's what happens.
      . If I use the filename, it has to be the complete path though.
      . Fixing namespace is another problem.  If it's not serving its purpose
        I should get rid of it.  See fix namespace:
      . Wait, how does this even work?  It's the bottom track for the note, but
        do I need block?  I think technically yes, because UI mutes are
        (block, track).  So render blocks are marked with both, and the midi
        mute msg has to include both.
      . Ultimately this is because note damage is per-track, which means the
        note storage should also be per-track. Of course that doesn't mean
        muting has to be per-track, so I guess this is sort of orthogonal.
        But it does seem more useful than per-instrument.  But since it's
        orthogonal, maybe I should put it on hold for now.
      . Also, is this overkill just to save time writing Notes?  That's not even
        the expensive thing.  The point is to make rendering audio incremental,
        and I don't need damage for that, I can just memoize.
      . Having explicit damaged ranges would let me skip serialization and
        checking for the majority of the score, so I think I will eventually
        want that.  But I can probably do without in the beginning, if I get
        incremental audio.
  audio:
    - integrate freeverb for reverb and filters
      . Or why not just use faust integration?  I think it has the same
        algorithm?
      . Yes it does, but for that matter, why not just use VSTs in realtime?
        I guess it would be easier if I wanted to make reverb part of an
        instrument.
      . I'd want to merge sampler and faust for this though.
  panner:
    - No apparent effect.
      . It's getting the MIDI.
      . Is it getting the samples?
      . It does get samples, but it can't stop audio.
      . What's the status of process replacing vs. not?
        vst2/interface.cc sets process_audio_inplace_function, and
        process_audio_function is nullptr.
      . What does that mean exactly?  The in and out ptrs differ:
        in 0x10adb8220 out 0x10adb9220
      . process() accumulates in the output, and is obsolete.
        processReplacing replaces the output.  It doesn't mean we overwrite
        the input!
      . This works for reaktor, so maybe it's the VST implementation.
      . What if I do a faust2vst?
      possibilities:
        / set_input_parameters - I do the same as faust.
        ? reaper is treating processReplacing like process
          . It shouldn't because process is nullptr.
          . make a separate process?
      . I definitely get output properly, and I get input properly, it's just
        that repear replaces out for reaktor but not for me.
      . It's probably due to IsSynth.  If I set it, then reaper always mixes
        in output, can't process.  If I don't set it, I don't get MIDI.
      ? Does reaktor get MIDI?  I can't tell because I can't get reaktor MIDI
        display to work at all.
      . But I think it did, because I got the tuned comb filter thing to work.
      . https://forum.cockos.com/archive/index.php/t-172871.html
      . There is probably some awkward workaround where I could explicitly
        route audio output.
    - expose separate left and right pans?  Or pan center and width?
  play_cache: PlayCache:
    - crash:
      . Application Specific Information:
        abort() called
        *** error for object 0x1062b3010: incorrect checksum for freed object
        - object was probably modified after being freed.
      .       Thread 7 Crashed:
        0   libsystem_kernel.dylib  0x00007fff6280ab66 __pthread_kill + 10
        1   libsystem_pthread.dylib 0x00007fff629d5080 pthread_kill + 333
        2   libsystem_c.dylib       0x00007fff627661ae abort + 127
        3   libsystem_malloc.dylib  0x00007fff6286fb58 szone_error + 596
        4   libsystem_malloc.dylib  0x00007fff6287116f small_free_list_remove_ptr_no_clear + 790
        5   libsystem_malloc.dylib  0x00007fff628650e5 small_malloc_from_free_list + 171
        6   libsystem_malloc.dylib  0x00007fff628638dd szone_malloc_should_clear + 1600
        7   libsystem_malloc.dylib  0x00007fff62864d00 malloc_zone_calloc + 87
        8   libsystem_malloc.dylib  0x00007fff62865612 calloc + 30
        9   libsndfile.1.dylib      0x0000000113b0f5cc psf_store_read_chunk + 110
        10  libsndfile.1.dylib      0x0000000113b0f543 psf_store_read_chunk_u32 + 95
        11  libsndfile.1.dylib      0x0000000113ae1378 wav_open + 444
        12  libsndfile.1.dylib      0x0000000113ac7f8d psf_open_file + 2213
        13  elaforge.seq.play_cache 0x000000011394861c open_sample(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, int, bool, int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, long long, int*) + 76
        14  elaforge.seq.play_cache 0x0000000113947e99 SampleDirectory::open(int, long long) + 233
        15  elaforge.seq.play_cache 0x000000011394836a SampleDirectory::read(int, long long, float**) + 874
        16  elaforge.seq.play_cache 0x000000011394e524 Tracks::read(int, long long, float**) + 228
        17  elaforge.seq.play_cache 0x000000011394ba57 Streamer::stream_loop() + 263
        18  elaforge.seq.play_cache 0x000000011394d32e void* std::__1::__thread_proxy<std::__1::tuple<std::__1::unique_ptr<std::__1::__thread_struct, std::__1::default_delete<std::__1::__thread_struct> >, void (Streamer::*)(), Streamer*> >(void*) + 62
        19  libsystem_pthread.dylib 0x00007fff629d2661 _pthread_body + 340
        20  libsystem_pthread.dylib 0x00007fff629d250d _pthread_start + 377
        21  libsystem_pthread.dylib 0x00007fff629d1bf9 thread_start + 13
      . Could be related to how libsndfile is not thread safe.

    gui ideas:
      . I don't really want to write a gui though, what a hassle.  How much
        can I do with the generic gui?
      - text output for logs
      - show play offset
      - graphical display for chunks and render progress
    - If I want to send to VST effects separately, I'll need multiple outputs.
      The other way would be to start multiple instances, and do some muting.
    - since the osc channel is global, if two play_caches are open, one will
      block thru for the other.
      . Could I get reaper to tell me when I'm not focused, and close the
        channel then?
    - reaper crash:
      . reports in ~/Library/Logs/DiagnosticReports/REAPER*, to ../crash
      . EXC_CRASH (SIGABRT), Thread 0 Crashed, weak_entry_insert()
      . EXC_BAD_ACCESS (SIGSEGV), Thread 4 Crashed, FxChain::GetLatency()
      . It seems to happen when rerendering while playing, maybe due to files
        being replaced during a read?
    - What about writing play_cache in rust?  Just for fun I guess, though if
      it gains semi-sampler features then I'll wind up with more logic.  But
      I do need to bind to libsamplerate and libsndfile.
      . https://github.com/RustAudio/vst-rs
      . https://areweaudioyet.com/
      . https://github.com/RustAudio
    / save cache as flac?  Since I use libsndfile I think it should Just Work.
      . probably afplay stops working though, because Apple.  But libsndfile
        maybe comes with a demo player?
      . flac doesn't support float samples, so nevermind
    - Log on a separate thread.
      . Ideally I would accumulate the msg in a static buffer, then copy it
        into a ring, and the logger would then pull it off the ring.
      . Maybe I don't actually care though.  LOG is for debugging, and
        eventually I should be able to turn it off.
    / The im/ directory is fundamentally global, since PlayCache hardcodes
      a single path.  It could theoretically be configured, but I'd probably
      have to do it manually via some kind of VST GUI, and save in the VST
      preset mechanism, and it sounds like a lot of hassle.
      . Or I could send it over via MIDI, but that kind of state always gets
        out of sync.
      . What's so bad about global though?
  sampler: sampler-im:
    - sometimes file not found is caught, sometimes uncaught:
      SystemError {errorString = "openFile
        \"data/sampler/sc-gamelan/gongs/Kempur-A106.flac\":
        No Error."}
      . Looks like yet another hsndfile bug... should I upstream my fixes?
    - even though I don't need a voice limit, it would still improve
      performance.  E.g. long cengceng tails add up to a lot of voices.
    ? anything to learn from HISE?
      . Uses HLAC, which is like flac, but less compression and supposed to
        decode faster:
        https://forum.hise.audio/topic/236/hise-lossless-audio-codec-is-ready
        . It's tangled up in juce stuff, so would need copying out.
        . Measure wav vs. flac performance first.  Also I can just decompress.
        . It also has a mmap reader, maybe I should do that, if disk IO is the
          main bottleneck.
      . Looks like resampler is just hold previous value, not even linear
        interpolate: StreamingSamplerVoice.cpp interpolateMonoSamples
    sampler-im/sample:
      - I'll want warp points, or at least realign points.  But at this point,
        shouldn't I be working in the DAW?
        . DAW advantages is UI designed for this, stretch, warp points, etc.
        . karya advantage is no MTC to sync, sample visible inline.  Those are
          not such big advantages.
        . It would definitely be better if I were doing lots of offsets, e.g.
          for drum sequences / break beats.
        . Also I can do per-sample effects, which is easier than awkward DAW
          style, but only if you go past standard  "reverb on everything".
      - support start offset, ratio adjust
      - support time stretch and pitch shift
        . Have to bind to rubberband first.
    - libresample is hard to use.  Alternatives?
      requirements:
        . required: Variable ratios, where it's interpolated per-sample.
        . required: Save and restore state.  Smaller state is better!
        . wanted: Smaller state.
        . wanted: Do the SampleNn -> Nn -> Ratio calculation per-sample, so
          I don't have to a resample in Sample.pitchToRatioSignal.
      . https://github.com/jniemann66/ReSampler
        No library, not clear if it supports variable sample rate.
      . https://kokkinizita.linuxaudio.org/linuxaudio/zita-resampler/resampler.html
        Supports variable, but only down by 0.95.  Also I don't think the
        ratio change interpolates.
      . http://audio-smarc.sourceforge.net/
        fixed rate converter
      . https://github.com/minorninth/libresample
        Can do variable ratio, but have to interpolate myself.
      . So actually libresample still looks pretty good, it supports multiple
        qualities and variable ratio, with per-sample interpolation.
        Mostly what it lacks are:
          . save and restore state - implemented, but hacky
          . readable source - matter of taste
          . configure per-sample ratio calculation
    -  AUtil.volume does dbToLinear per-sample, which is inefficient.
      . Do it to the Signal, before realizeSignal.
      . Use the same srate as DbSignal.from_signal.
    - it's too confusing to map dB to the -96 - 0 volume range.  Just make
      envelope be in dB.
      . That might be confusing too, since it's different from all other
        signals, and since signal is monomorphic, I can't easily make
        a newtype for it.
      . Also, I use envleope = 0 end the sample, and dB never goes to 0.  I'd
        have to say -96 is 0.
      . It would be nice if I could make Decibel a newtype, to remind myself
        to do the conversion.  But it goes into a Signal, which is untyped.
        . I could either use the signal phantom type, and have it optionally
          influence the Y value accepted by from_pairs.  I think I can do it
          with type families and coerce, where
            from_pairs :: Coercible (YOf kind) Y => [(X, YOf kind)]
              -> Signal kind
          . This would also be useful for Signal.NoteNumber, though I think
            I don't have the problem of not remembering it's NN, it's just
            that I have to coervert away from Pitch.NoteNumber.
        . Or I could just wrap the envelope Signal in a newtype.
          . But this means I have to duplicate the whole signal API.  If it
            gets to be more than a few functions, then evaluate the polymorphic
            signal.
      - dbToLinear is not linear, so RenderSample has to resample the envelope
        before multiplying.
    - Signal.sig_multiply is not a linear operator!  It's ok for a constant,
      but 0.5*0.5 is 0.25.
      . Does this mean all my uses of multiplying dyn are inaccurate?  And in
        what way?
    non-constant pitch:
      - predicted lengths tend to be off, sometimes by 2000+ frames.
        . I fixed a bunch of bugs with ratio placement, and they're still off,
          but not by so much.
      Notes:
        . I need to get sample duration after applying the pitch curve so I can
          accurately determine overlap.  I figured out the math to predict
          duration, but it turns out libsamplerate doesn't actually do that.
          But libsamplerate's algorithm for advancing samples seems to be the
          same for all quality levels, so I should be able to derive something
          from its loop.
        . Don't I have this same problem with the decay on faust instruments?
          How to test that?
        . For instance, dropUntil is wrong, because the samples might be still
          running.
        . I think this isn't a problem for faust, because the ringing note is
          captured in the state, but samples don't do that.  It's
          fundamentally a problem with samples, in that they are *all* state,
          and the state is very large, so it's simultaneously not practical to
          save it, and not necessary.
        . I can get the duration of a sample pretty easily if the resample
          ratio is constant, but if it's not then it's quite complicated,
          something like an integral of the ratio curve.  At that point
          I should just resample with ZOH and see how many samples.  That
          requires effectively running each sample twice, even though the
          resample is super cheap, I still have to stream the sample from
          disk.
          . Actually, I don't have to do that, since I don't need the samples
            themselves.  I could extract the ZOH notion of how many samples to
            skip or insert, and just simulate that.  Effectively this is just
            the integral, but based on libsamplerate's own code, to make sure
            I get the same answer.
        . But otherwise, I have to assume that any note could last forever,
          and that means none of the note overlap stuff with hashes works.
          So I think I really do have to figure out note length.
        . I could put an upper bound on sample length by using note duration,
          cutting it off if it goes beyond that.  I can build some knowledge
          of sample duration into the patch, e.g. I can start with the normal
          constant ratio.  Still, it will be awkward if any sample that bends
          down is cut off.
        . I do get to know the sample duration after I play it.  That means I
          can still do overlapping notes, but I have to use the Audio stream,
          not the Note duration.
      plan:
        . Figure out if it's theoretically possible to save the duration from
          the play through, and use those.
        . Otherwise, pursue figuring out duration via looking at sample file
          size and taking the integral of the ratio curve.  This should be
          fast for constant ratios.
        . Math approach:
          . integral x = nx^2 / 2 + kx
          where input size = 3
          f(x) = 2 ==>    integral 2x             solve 2x = 3, x = 1.5
          f(x) = 2x ==>   integral x^2            solve x^2 = 3, x = sqrt 3
          f(x) = 2x+1 ==> integral x^2 + x        solve x^2+x = 3, x = 1.30277
          f(x) = nx+k ==> integral nx^2/2 + kx    solve nx^2/2 + kx, x = ?
          . I should be able to use the quadratic equation:
              (-b + sqrt (b^2 - 4*a*c)) / 2*a
            x^2 + x - 3 = 0 ==> x = (-1 + sqrt (1^2 - 4*1*(-3))) / 2*1
                                    (-1 + sqrt 13) / 2
            [1.3027756377319946, -2.302775637731995]
      / Ok, first try to pull the duration from the play.
        . The first time play, I think I have to record the durations.
        . Then I have to use those in skipCheckpoints.
        . Actually this way sounds error-prone, look at libsamplerate for
          the sample-skipping algorithm.
        . will be in data->output_frames_gen
          priv->out_get / priv->channels
    optimizations:
      - Sample should stream the envelope.
      - RenderSample.applyEnvelope should be able to check for constant within
        the sample's duration.
      - if libsamplerate could handle the pitch curve directly, I wouldn't
        have to resample in Convert.makeSample, and it could be per-sample.
        . hz -> nn is nonlinear, and then hz -> ratio is nonlinear, so I have to
          have it take nn to nn breakpoints, and do that calculation internally.
    / An alternative to symbolic-pitch=t is that patches could export
      their native scales.  That way other instruments could use them too.
      . Another alternative is that the scale could take instrument into
        account.
    sampler tests:
      . There is more and more code in Sampler/Patch/*, but no tests for any
        of it.  How can I test it?
      . In general there's no tests for im, because audio is harder to check
        than MIDI.
      ? Can I emit something low level but not as low level as MIDI?
        . sampler-im dump does it!  Can I simplify and serialize those for
          verify tests?
      . I have a bit of this in Mridangam_test, but ad-hoc.
        I want to easily test properties, such as:
        . all samples reachable
        . For proper distribution, I think I just hand-test like in
          Mridangam_test and trust that if you're using the usual combinators
          then it works.
      - Also have it do a sampler dump to verify sampler convert.
    break:
      - make a 'bd' or 'sn' than randomly picks one
      . reason "recycle" looks like a commercial product that does something
        like this.
        . It seems more basic, except the gui and finding attacks
          automatically.  Not sure if that's any different from reaper's
          "dynamic splits".
      . what about tabla and mridangam?
        Can I find some recordings of a plain sarvalaghu / tekha sequence?
    rambat:
      - No thru for >ra.  I guess this is the same problem that caused me to
        want to refactor how thru is handled.  refactor thru:
        . Alternately as a short term fix, I could make a sampler/rambat dummy
          with the env vars and a thru that dispatches to one or both.
        . What about add a Common.Config thru that dispatches to some other
          instrument?
        . I guess that's what the MidiThru with evaluation does, but in a more
          general way, so I still want that, because it'll make kendang-legong
          work too.
    kendang-legong:
      - Thru doesn't work with pasang, see refactor thru:
    reyong:
      kilitan:
        . there are natural light accents, e.g. on beats
        - Compare automatic version to tabuh telu version.
      dynamic calibration:
        - I need a tool to quickly generate and play a sequence of notes.
          . It's too slow to recompile and rerun seq.  I should be able to
            set knobs without recompiling (e.g. volume tweaks for samples).
            Then rerender and play the audio.
          . Can I do the rerender from ghci?
          ? Is there a lightweight sample player that I can invoke from the
            commandline, and see the waveform and playback position, and
            click to play from a position?  Basically any sample editor,
            except start instantly and from the commandline, or be able to
            load the sample automatically.
            . Can I get reaper to refresh the sample from disk?
        . Alternate reference sample with the testee, adjust testee until they
          sound the same.  Record the negated number as the offset.  Reaktor
          should have a dB scale fader.
        . Consistency is most important across samples that will alternate:
          . Calibrate variations against v1.  They should already be close.
            (pitch, dyn, articulation), variation
          . Calibrate similar articulations: [open, mute+*], [cek+*]
            It's probably hard to calibrate dissimilar ones, but they should
            represent the same logical dynamic.
            variation=1, (pitch, dyn), articulation
          . Calibrate across pitches by articulation:
            variation=1, (dyn, articulation), pitch
        . The dynamic scale should be smooth.  Per (pitch, articulation) I
          play short clips from pp to ff and listen for jumps.  Then adjust
          the sensitivity to dyn, which is the slope of the scaling curve, or
          dB multiplier from the distance from the center point.
        . I'm assuming I divide the dyn signal into uniform sections where
          each dyn level is nominally at the center.  I could just do
          1/dynCount, or I could bias towards mp and mf, under the assumption
          that extreme dynamics are rarer and I want to save the timbral
          changes for that.
        . I still want to avoid sudden timbral transitions at regular
          dynamics.  I can ameliorate some of that by randomizing dyn, but
          that also should change perceptual dynamic.  So I can also have
          overlap between each dynamic range, and include them in the sample
          choice set with a weight according to the depth of overlap.

        Try absolute measurement?
          . The above is a complicated multi-step process, and since it's all
            relative I worry things could get off from each other depending on
            (arbitrary) choice of initial reference.
          . I still don't really trust automatic normalization, but maybe
            I could do perceptual normalization manually by picking a midrange
            sample and then adjust everything to that.
          . Or maybe automatic normalization was ok after all, just the
            instrument I put together had a mis-adjusted dynamic response
            curve.  The problem was that quiet samples were made too loud.
          . Or it could be that normalization linearizes the dynamic, when
            they're actually not.  Since I lose the original level, I could
            wind up with samples not ever overlapping their original level.
          . At least with the manual but absolute approach I can retain the
            original dynamic, and thus have a rule like only attenuate, never
            amplify samples.
          . Actually, that might be hard.  I'd have to pick the softest within
            each group and adjust everyone down to match.
      reyong dynamics:
        . Or normalize, it still seems like it shouldn't inherently cause any
          more hiss than not, if I have the scaling adjusted right.
        . Try normalizing first, then cycle variations to make sure they are
          self-consistent.
        . I need to be able to explicitly assign variations to do it from
          karya.
        . I can do it by just setting %variation.
    zheng:
      - harmonics are much softer
        . 67nn louder
      - Do bends per-string.  This means merge together the pitch curves.
        . I should do this post duration calculation, and only collect signal
          over the note duration.
        . Like pedal, this is less efficient than the traditional imperative
          way because I duplicate that work.  I could recover that by doing
          a single per-string merge up front, but I'd need to make the signal
          lazy.  Same goes with damp actually.
        . I would have to go through and assign strings, to come up with
          a single pitch curve per string.  This is the same as ness guitar,
          and I guess I'd want to do it the same way, by assigning the string
          at the score level.
        . MIDI could get this "for free" by putting each string on its own
          channel.  Of course if there are 21 or 200 then you run out.
        . So only do the pitch curve merge if Note.element is set, and look
          for equal Note.elements.
    gong bali:
      / Smooth out dynamics.
        . Kontakt version is smooth, but mine isn't.
        . I think dynRange just exacerbates jumps instead of smoothing them,
          because it's global across the whole range.  Instead, it should be
          for each sample.
        . How does kontakt do it?  Naturally it's not really documented, but
          I'd guess velocity -> volume response is per-group.
        . I need to know the dynamic bounds for each sample, so I can tell
          where I am in them.
        . Still a big jump from 9 to 10, and then 11 to 12
        . Maybe the problem is different vel ranges have different widths, so
          narrow ones get scaled too much.
        . How about if I do a constant dyn amount per vel?
        . It's still bumpy, I think I just need ad-hoc adjustments.  I don't
          know how kontakt does without.
        . Oh I see, each group also has a hand-tuned volume.  Ok, I guess this
          means it's all hand-adjusted.
        . I need a framework, see dynamic calibration:
    mridangam:
      - make kin and tan use y j like in mridangam?
      - o is too high pitched, I need to re-record
        . It would be nice to get a really low pitch long thom like pakhawaj.
      - sampler levels too sensitive, only the a0-ff range is really usable.
        . But the example ranges in save/test/sampler/mridangam seem ok, what
          gives?
      render from solkattu:
        . Convert to a score first, so I can apply ky transforms.
        . Then perform via im, and invoke sampler-im.
        . This way I can make use of the cache.
        . This non-interactive pipeline would be the same basis for all text
          score.
        - p is now too soft!  Where did I adjust that?
    - record mridangam sequences like kita and dikutarikitataka and use
      rubberband to fit them into shape
      . Compare with rendering via samples and see what's different.
      . Rubberband actually is pretty bad for percussion, maybe I have to use
        a 'break' approach.
    rubberband:
      - support set_key_frame_map(), for offline only
      - write streaming binding
        . This is likely faster, or at least more memory efficient, and
          I maybe don't need the quality increase, if there is one.
    - convolution
      . What are the options?  jconvolver,
        http://tomszilagyi.github.io/plugins/ir.lv2/
      . Since reverb is what you put on at the end, can I just do a realtime
        one on the play-cache output?
      . That won't work if I want to do fancy per-instrument variable reverb
        effects.
    - integrate faust effects for reverb and filters
    features for an actual sampler:
      . see doc/dev_notes/synthesizer
      . Intrinsic pitch independent of the pitch curve, which influences
        sample selection.
      . Intrinsic velocity for the same, independent of volume curve.
      . For a given pitch and velocity, generate a set of candidate samples.
        . Who decides on the sample?
          . I want this to be deterministic, so that it's driven entirely
            by EnvKey.seed, but not necessarily put the whole sample selection
            logic in karya.
          . On the other hand, why not?  Then the sampler has individually
            addressed samples, and I ask for each one by name.  Karya has access
            to higher level concepts like intrinsic pitch.
          . I can put the code physically in Synth.Sampler.PatchDb and still
            link it in to karya.
        . Each candidate has a goodness of match weight, so I can optionally
          borrow from a neighboring pitch or velocity, but with lesser
          likelihood.
      . Rules for automatic damping.
        . For drums I can use the existing mechanism: Samples are in groups,
          and each group is stopped by a set of groups.
        . For gangsa reyong etc., it's the same, where each
          (pitch, articulation) is a group.
        . For strings, I have a set of open strings, and I have to merge pitch
          signals on each open string, as with Ness.Guitar.  Damping the
          string when it's played again would be like plucking, not damping
          would be like striking.
      . Recognize sequences, e.g. nakatiku.  Then I'd also have a "speed" axis
        to pick the closest speed and use rubberband to fit.
      . I could also use rubberband pitch shifting instead of resampling.
      . Per-patch signal network so I can incorporate faust effects.
  faust:
    - I compile faust C by including build/faust_all.cc, which gets slower as
      I get more of them.  Instead I should compile the .c files individually
      and then link as usually.
      . I can't have a faust_all.cc with 'new Patch' calls, because faust
        doesn't generate a separate header.  It doesn't seem to have the
        feature at all.
      . In that case I have to generate a faust_all.cc for each one, and leave
        faust output as .h files.  Then I have to merge them.
        % cat build/faust/blow_bottle.cc
          #include "build/faust/blow_bottle.h"
          const Patch *blow_bottle = new Patch("blow_bottle", ...);

        % cat build/faust_all.cc
          extern Patch *blow_bottle;
          ...
          static const Patch *all_patches[] = { blow_bottle, ... };

        Then I have to keep the .o files for the link line.  Since I'm not
        just including the cc file anymore, I have to link separately.
        I guess I can add a faust.a, and then put faust.a in hsToCc along with
        driver.cc.
        . need ["build/opt/obj/build/faust/blow_bottle.cc.o", ...]
          Util.system "ar" $ ["-rs", "build/faust.a"] ++ objs
    - Once I have individual faust processors, can I load and reload them
      dynamically?  Then recompile either with C or use faust's LLVM backend.
    - per-instrument note range for render-preview
      . Or I could only render when loading a score with one as an instrument.
      . Or really lazy means I would only make when I did a MIDI thru, and
        then only for the note needed.
    - generate render-preview only when requesting that note
      . I know the filename from the OSC message, so I could just check for
        its existence, and if it doesn't exist yet, ask faust-im to generate
        it.
      . This would be high latency at the cost of maximum laziness.
      . Another compromise would be to wait for the OSC, and the render them
        all in parallel in the background.
      . Yet another would be to start the background render based on the
        instruments in a score on load.
    - support Control.pan
      . Or unify sampler and faust and get things like this along with.
      . Test volume, support pan.
    . Even though I can enforce the block size only at the final step of the
      pipeline, it's still more efficient to generate the right sized blocks
      in the first place.  This seems easy to get wrong though.
      . The runtime way would be to uncons in the render loop and assert the
        length.  I do this now.
      . The type-level way would be to put the block size into the type too.
        Then I can say synchronize or certain generators can create a known
        block size, but resample makes the block size unknown, so I have to do
        a synchronize afterwards.
      . An extra parameter for every single Audio sounds like a hassle though.
      . And the size is actually not that simple, because if the note starts
        at an offset, the first block may be smaller.
      . The true constraint is that blocks have to line up to multiples of
        chunkSize.  And if I want to avoid reallocation, they have to line up
        with each other.  That seems quite a bit more complicated to express
        though.
    ui controls:
    - create control signals more efficiently on a render resume
      . I used to drop notes until the one before start, but that's not safe,
        because they might have non-overlapping control sets, and an element
        can ring for arbitrarily long.  What I want to do is skip coming up
        with breakpoints that are before 'start', but without some sort of
        index into what notes have what controls, I have to look at all notes.
      . But I'd like to entirely avoid the concept of notes that don't set all
        controls and inherit from the past.  I inherited this from faust's
        control notion, which is the same thing in MIDI that's such an
        enormous hassle.
      . To get there, I'd have to have all controls in all notes, and all
        controls not set are explicitly 0.  With Audio.Constant optimization
        I could make it more efficient.
      . At that point I can simply drop notes until the last one with
        start <= now.  I'll need this if I want to avoid serializing all notes
        all the time, as was the original plan.
      . This also means I don't use faust's built-in default values, but have
        to export them out to karya so it can set them explicitly.
    tambura:
      - implement a tambura call that cycles strings, perhaps semi-randomly
      - It seems out of tune, and different strings have different tuning?
        . Tune against sine.
        . It gets out of tune the higher it goes, e.g. 6s is pretty out.
        . Maybe it's the c-4 pitch spread, since it's by hz and not
          logarithmic...
      - Perhaps bring back pitch from 0 as a buzzy attack effect.
        . Though using the pink noise attack is maybe about the same?
      - Can I get signals from other parts of the string?  It would be nice
        for stereo or multichannel.
      How to do damping?
        . I guess I turn up the string damping.
        . But I'll need to have a notation.
          . Explicit durations: where notes are damped after their duration.
          . Explicit damping: explicit notation for damping.  Maybe have one
            for per-string, and one for everything.
          . Infer: A note whose end touches the start of another isn't damped,
            otherwise damp at note end.
        . I could turn down decay, which turns down feedback.  But feedback is
          just a flat multiply, and it seems like a should have a frequency
          dependent damping.  'damp' under high-freq-loss affects this,
          experiment with it.
        . high-freq-loss has no audible effect.
        - Can I append a soft note with fuzzy material to simulate finger
          buzz?
        . So I want a postproc that will append a decay-down multiply.  So
          I'll want per-instrument code for faust, which I don't have yet.
        - Write to Oli Larkin about the damping bug.
          . Also bend_depth bug.
      / I won't need the autoplucker.
        But it's convenient for testing.
      - tambura variations should be able to share preview sounds.
        . It's pretty ad-hoc though.
      / It uses random for pluck pos and amp, I want deterministic.
        . How does no.noise work?  If not deterministic, I probably have to make
          it so.
        . It is deterministic.  I guess it has to be if it can't do any IO.
        . But I can also take out the random and use exact values.
      - Include the bridge IR?  It's in the original source but commented out
        for some reason.  Also the the github page references the
        unimplemented body IR, which might be different.
    - faust-stk/bowed.dsp?
    - adapt blow_bottle.dsp
    - Compare timing with pre-input signals.
      . In general I should set up performance tracking for faust-im and
        sampler-im.
      . I also want to check pre and post Audio.Block.
    - Don't render before the first note.
      . If I do the skip after the cache skip, I can get the effect of turning
        off rendering for silent sections... well, except I can't because
        I need to wait until isBasicallySilent.
      . I could also have a convention for a "all silent" chunk, say a
        broken symlink to "silence", which play_cache knows about.  When it
        sees one, it just does memset 0.
      . It has to actually be in the checkpoint directory though, so it could
        be just any broken symlink.
      . Other players like sox won't understand it though, which is a bit
        annoying.
      . Should I put Block back in Audio so I can keep track of 0s?
      . I could use constants for faust controls too.
      . Audio.Constant is implemented, now I need to prepend Audio.silence,
        and then make File.checkpoint write special const 0 files.
        . I could write these as normal files except with zero length, and
          since all chunks are the same size, play_cache can treat it
          specially, and bin/play won't trip over them.
      . I can only do this when state == Nothing, which is only going to be
        true for now=0.  Then I need to move the control breakpoints back by
        the amount of silence I prepended.  Or just increment 'now'.
      . Unfortunately the initialize notes defeat this!  I could just ignore
        dyn=0 notes, but will it affect initialization?
      . No more than the usual latency problem with controls, because the
        breakpoints extract starts from the beginning.
      . That works, but this still gets defeated when resuming, because the
        state is no longer Nothing!
      . I could ignore the state, and assume it will be not interesting before
        the first note.  But I want to make sure to not do this when I am
        resuming in the middle.
      . Even when taking that into account, I still get a crash due to:
        expects state size 2497792 but got 0.  Even if I could work around
        this, I still think I might get non-determinism because then things
        like noise will be initialized differently.
      . I guess unless I always suspend computation for silence, and don't
        emit any state either, then it's deterministic again.  But that's what
        I already do, it's just that I need to know to not load state if I'm
        starting after a silence, even if there is one available.
      . In any case, this got a lot harder than I thought.  I still want to do
        silence efficiently, but maybe I should wait for a full suspend.
    + Suspend instrument rendering if gate and signal goes to 0.
      . Maybe I need to bring back Audio.Chunk for this.  Or V.empty in the
        output NAudio?
      . If I have a quickly recognizable chunk, then I can turn that directly
        into the "silence" symlink above, and avoid writing entirely.
      . If I want to deactivate the dsp in the middle, I'd need to wait for
        silence, and then clear the state, which means I need to implement the
        stateless notes thing first.
    . https://ccrma.stanford.edu/~rmichon/faustDay2017/
    . http://faust.grame.fr/faustplayground/

  ideas for faust:
    audio debugging ideas:
      - attach an oscilliscope to any internal signal
        . Or export it as audio to listen or look at.
        . If I attach this to a waveguide delay line, do I get a picture of
          the string?  I'd want to sum all the lines.
      - get windows of values, e.g. control values right at note attacks
      - detect anomalies, like NaN or numbers in unexpected ranges.
    - Check function arity.  Also have explicit arity versions of <: and :>,
      e.g.
        point-free: process:2:1 = _, _ 2<:4 _ + _ + _ + _;
        point-full: process:2:1(a, b) = a + b;
      . The way point-free style interacts with pointed style combined with
        how <: implicitly duplicates the signal as many times as in necessary
        is error-prone.  E.g. an extra argument is not caught if a <: precedes
        it.
    - Access to memory, e.g. the values in a delay line, for visualization.
      . Actually hbargraph does this, but just for a single value.  I'd have
        to get a handle on the (@) call.
    - If faust cached a single previous input up to the point where it depends
      on another input, it seems like we then effectively get variable sample
      rate, just by holding one input constant.  It's probably not as good as
      a real variable rate, because it still has to check with the previous
      value on every sample.  But if we know the inputs that are likely to
      remain constant, we can memoize them all together.  Has this idea been
      implemented anywhere?
    - Provide access to input signal names so I can get rid of the awkward
      declare thing.
      . Talked with Yann about this, seemed receptive.  Probably have to
        remind him, or implement myself.
      . I should be able to use this to get rid of controls entirely.
    generated code:
      - Use const on const methods:
          getNumInputs(), getNumOutputs(), clone(), ...
        . I have a patch for this but it will likely be rejected because it will
          break subclasses that don't declare const.
      - const on inputs:
        compute(int count, const FAUSTFLOAT** input, FAUSTFLOAT** output)
        . Same deal, might break subclasses.
  csound:
    . Use csound-expression?
    . writeSnd "A.aiff" $ setDur 10 $ osc 440

  cache / incremental rerender:
    notes
      . I want the sequencer to only send the damaged range, but the synthesizer
        will have to rewind to the previous chunk boundary, since it can't just
        put every note in its own sample.  I suppose a sampler could actually do
        that, but presumably physical models couldn't.
      . Though actually a model would need to save its state at chunk
        boundaries, so if I go per-note, then I wind up with rendering each note
        separately, with a header with the model's state at start time.  But
        overlapping notes would influence each other, so it would have to be
        chunks of overlapping notes.  Of course it's not guaranteed there will
        be a gap, so it would have to break anyway over a threshold.
      . This is all to say that the cache chunks are synthesizer dependent, so
        it needs access to all the serialized notes and can rewind as much as it
        wants.  If notes are saved individually and indexed by time then I just
        need to re-save the damaged ones and either send the time range or infer
        from file timestamps.
    - Include DamageRange RealTime RealTime in the notes dump.
      . This is assuming I always serialize all notes, but I'd also want to do
        that in chunks.  But I would have to expand the damage range out to
        all overlapping notes, which is not great if there's a drone + control
        and you modify the control in the middle.
      . I should just have to emit the notes with overlapping damage, but only
        rerender the time range.
      . Say I make each note is its own file:
        <start-time>-<instrument>-<voice>, where voice is just a number for
        otherwise overlapping notes.  If there's damage from s to e, I get
        the set of overlapping notes.  I delete everything in the damaged
        range, all all (start, instrument) at the times of overlapping notes
        before the range, and then write overlapping notes.
            |----------->|--->
                |--->
                |--->
                XXXXXXX damage
        . This is like Ui.Diff, except that it's RealTime and for
          Score.Events.
        . I also need to turn ScoreDamage into RealTime.  Maybe not trivial?
      . Actually first let's not bother with incremental, and just rewrite the
        whole dump each time.  The real saving is in not rerendering audio.
  . If there is only one cache mutated by the synth, then a play in progress
    will be spoiled by a new render.  I can fix this by making a new cache
    each time, and hardlinking the unchanged entries.  I can remove the old
    one if the play is stopped and there is a newer one, so this could be done
    by the PlayCache vst.
  more efficient Perform.Im.Convert
    - Trim signals.
    - I can probably serialize more efficiently by just mmaping the signal
      pointers, or at least directly copying their contents.  But maybe not
      worth it if I can just write the changed bits.
  Is it possible to do physical modelling on GPU?
    . http://futhark-lang.org/index.html
    . http://halide-lang.org/
    . hackage accelerate
    . look for code from "gpu-accelerated modal processors and digital
      waveguides" paper.

shakefile: build:
  - fix the redefine error:
    . macro redefined warning when compiling hsc2hs generated file
      . Because hsc2hs embeds it in the file with -optc
      . Harmless but annoying.
    . error is:
      In file included from <built-in>:361:0: error:
      <command line>:12:9: error:
           warning: 'BUILD_DIR' macro redefined [-Wmacro-redefined]
      #define BUILD_DIR "build/opt"
      <command line>:8:9: error:  note: previous definition is here
      #define BUILD_DIR "build/debug"
  reduce dependencies:
    - haskell-src, use another pretty printer
    - QuickCheck, use hedgehog instead
    - for indirect deps I need some way to get the paths
      . e.g. whence goes js-jquery, js-flot?  Probably shake.
  / shakefile -v should print version, it doesn't
    . because it prints at Normal, and I'm at Quiet.
    . To avoid shake's internal output, '# ...' lines
    . Who is printing those?  It's Shake.traced.
    . It's easier to use Quiet, otherwise shake wants to print too much stuff.
  - run with --lint-fsatrace:
    . https://well-typed.com/blog/2019/08/exploring-cloud-builds-in-hadrian/
  / Use nix-style "v2" packages
    . https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/packages.html#package-environments
    . Either use -package-env flag or write .ghc.environment.arch-os-version
    . Then stop passing flags on the cmdline.
    . Install deps with: cabal build --only-dep
    . But it's broken, hlibgit2 fails on '#include <openssl/sha.h>', and
      --extra-include-dirs=/usr/local/opt/openssl/include
      --extra-lib-dirs=/usr/local/opt/openssl/lib
      has no effect, and I can't build it manually due to the cabal version
      mismatch.
    . How are you supposed to install deps in the v2 world?
  nix:
    . https://app.cachix.org/cache/elaforge
    - Look into 'tinc', it uses the cabal solver to decide on versions.
    - Broken with withEkg.
      . Because ansi-wl-pprint 0.6.9 doesn't compile, no profiling on
        ansi-terminal.
      . I assume this is because nixpkgs hackage gloms everything together,
        haskell.nix I think is meant to fix that.
      . Meanwhile, can I unprofile all of them?
      . I have no solution for adding a new package.  I want to use the cabal
        solver to find a version set, and then export that like a freeze file.
        I also want to have *only* the version pinned libraries.
      . But I don't think nixpkgs hackage likes this, it's one big tangled
        fixpoint.  I could make my own, but I'd have to recreate the scoped
        callPackage stuff.  I kind of think that stuff is awful, but something
        at least like it is probably required to resolve cabal2nix's
        undifferentiated list of dependencies.
      . Actually I think this is just cabal2nix's problem, it has separate
        libraryHaskellDepends and librarySystemDepends, just they all get
        mashed into one import namespace.
      ? Can I get cabal to take a list of packages with possible versions, and
        print out a solution?
      ? Look into haskell.nix.
    propagate deps to the shakefile:
      - use NIX_LDFLAGS instead of hardcoding paths for libsamplerate and
        rubberband
      - package paths for haddock
      . Env vars would be easier from nix, while Local/ShakeConfig.hs is
        easier without.  Nix could create a Local/ShakeConfig.hs though.
      . Create from $setup, and tools/nix-enter will have the shell run it.
      . But shouldn't it temporary replace the existing one, like PATH?
    / Is there a way to configure lilypond to not drag in a whole tex?
      . It should be only necessary to build lilypond, I should be able to
        download it if I use a supported nixpkgs.
    / make a build expression, which does mkmk, mk.
      . I would have to get all the source into nix, and move the build to
        $out instead of 'build'.
      . But it's maybe useless for karya, since I rely on having the source
        and .o files around at runtime.
      . It would be useful for CI though.
      . I have nix/run_ci instead.
  - ghc --make now supports -j, use that instead of each file
    . I'll still need to chase #includes though, I think?  Actually --make
      should be able to handle it, if it causes the source to change.
    . I also won't be able to build individual .hs.o files anymore
    . Use --make with a phony rule, or try to parse ghc output to find out
      what it compiled?
  - In HsDeps and CcDeps, use Text, not ByteString, files can be unicode
  + get rid of cppFlags and follow #includes in all hs
    . branch shake-includes
    . previously I would run CPP, which gets accurate imports, but I think
      it's just wrong for #includes because they get expanded out
    . I think it's ok to ignore #ifdef and chase all imports.
      . Will this cause non-imported modules like JackMidi.hsc to get
        compiled?
  - could I use -fno-code with mk typecheck?
  - Modular package system, where I can express the dependencies for each
    target individually.
    . Also as I depend on C libraries I need to add them to the ghci cmdline,
      e.g. -lsamplerate
      If I can get it to work with fltk, then I can get rid of the
      Ui.BlockCStub hackery.
    . enableIm = False is broken because someone is importing Util.Audio.
      It's always going to be hard to keep working unless I do CI in nix,
      or have a real package system.  I could also split Util.Audio into
      a separate cabal package, but those are so annoying to use.
    . I have one global link line, so all binaries link all C libraries, which
      has been harmless so far, but is messy at least, and maybe slow.
  - in HsDeps and CcDeps, if I need every intermediate file, then
    I think I don't need Generated.
  - determine Shakefile.cppFiles automatically.
  . To get a path between two rules:
    ancestorOf('Synth/Sampler/Main') && descendantOf('Cmd/Cmd')
  / use new system calls and logging levels
  automatic "All.hs" modules
    . I'm reluctant because it's simpler to have normal files, and it's not
      that hard to update them.
    - Derive.Call.All looks for (note|pitch|control)_calls from Derive/Call/,
      but could also take from Local/Call/*
    - Local.Instrument looks for 'load' from Local/Instrument/
  - once upon a time, the shakefile took .2s to discover the build is up to
    date.  Now it's up to .7s.  Where is the time going?
    . https://shakebuild.com/profiling
  . https://neilmitchell.blogspot.com/2019/06/shake-from-10000ft.html
  . https://well-typed.com/blog/2019/08/exploring-cloud-builds-in-hadrian/

incremental save: git:
  text save:
    . consider switching to a text format so delta compression and diff works
    . I just don't want to fuss with a lot of quoting.
    . Maybe I can store as null-separated values.
    . But I want to be line-oriented, so diffs work.  And maybe delta
      compression is also line-oriented.
    . Also I don't want to have a whole independent Serialize class for
      binary.
    . If I use CBOR, then maybe I could convert to CBOR records, which is
      JSON-like, and then have an automatic CBOR to text bijection.
    . Research how git deltas actually work first.
    . Actually it seems like they work with binary, so space efficiency is not
      a reason to use text.  The only thing left is visible diffs, but I don't
      know that there's much point to that.  They're likely to be completely
      unreadable, so if I want to see diffs I'd need a graphical version.
    . And actually it looks like I can diff binary too, but using dump for
      textconv, e.g.:
        [diff "jpg"]
        textconv = exif

  + try saving individual events for incremental save
    Seems to be just as slow as full save, probably most of the time is in
    the call to git.  Test again with larger tracks.
  - wrap operations in a lock file
  - make sure things are ok if it fails at any step
  - I don't think Ui.State needs to emit CmdTrackAllEvents for cases where
    diff will catch it.
  . Git docs: http://progit.org/book/ch9-2.html

integrate: integration:
  - LIntegrate.edits only works for Block.block_integrated
  score integrate:
    - adding a control track below doesn't integrate properly
      . See commented out part of Merge_test.test_score_integrate
    - cascading score integrates
      . Is there really a use for this, other than consistency?
      . Yes, I want to do this for generated parts.
  derive integrate:
    - I get redundant pitches on noltol mute notes.
      . Can I omit repeated pitches?
      . Or maybe omit the pitches in the noltol itself so they inherit the
        previous?
      . But shouldn't that not work?  I want notes to be self-contained, and
        not carry over state from other notes.
      . But I think I don't really want to omit all redundant pitches, because
        I like to see them for notes which just happen to have the same pitch.
      . It's because of the lack of cancel-kotekan, but now the norot prepare
        is incorrect.
    - deleting the '<' doesn't clear the destinations, and clearing them still
      doesn't clear the red lines.  What makes those?
      . From the destinations, but those don't get deleted unless explicitly.
      . To delete explicitly, I would have to clear dests that don't appear in
        the derive output.  But be careful about errors, maybe only clear if
        there are no >Log.Warn msgs, or have some more explicit signal.
      . It's not so simple though, because I don't get perf_integrated when
        there was no damage.  Ordinarily this is good!  I guess I would have
        to emit something that means integration is still alive, but
        unchanged.
    - bug: can't delete a derived track, it just gets regenerated
    - bug: can't undo past a integrate create, it just creates a new one
      Maybe I could not record the integrate step?
    / bug: create tracks, remove <, re-add <, does it work?
      Removing < should break the integrate links.
    - Ensure cascading track integration works.
    - If integrate is committing changes to a track, can that bite me if
      a "canceled" derivation comes through?  Think about this later.
  generated parts:
    . The idea is that I write a part, e.g. for rambat.  Then a score
      integration creates several tracks in a separate block.  I can still see
      the original high level events, but if I double click then I get to the
      integrated block.
    . Currently the closest I can get to this is to make a new block, put
      a track and then do a score integrate to other tracks, and mute the
      original track.
    . The difference is that I would have to create the block and not see it at
      all, and resize it etc.
    . Maybe I could build it by having a mode to show the leftmost track in the
      caller.
    . Or, do a score derive, but collapse the created tracks.  This way I get
      editing and I don't have to worry about the sub-block length.
    . If I still want to edit it as a block, I could have a command to make a
      block with the same tracks from another.
    . First remind myself how to do score integration (and document?)
      . LIntegrate.score_track, which does
        Ui.modify_integrated_tracks block_id
            ((track_id, Block.ScoreDestinations []) :)
    - Write score integrate transformers like octaves, and multiple
      instruments.
      . How can I do this in a compositional way?
      . I'd like to write them like transformers, but they're not really the
        same, since they transform UI events:
          >ra | t< "('> | hand=l' (oct -1)) "('> | hand=r' id)
          >ra | t< "(hands (oct -1) id)
          >ra | t< "(oct-hands)
          >ra | t< "(tracks ('>ra-u | t< (oct-hands)' id)
            ('>ra-i' | t< (oct-hands)' id))
          >ra | rambat-pasang
      . 't<' signals a score derivation, and mutes its track.  It stashes its
        Quoted args in a special return that triggers the score integration.
        Either add a Monad.collect_score_integrated or add another case to
        Monad.Integrated.
      . It evaluates the args in a special interpreter.  The final output is
        [(TrackTitle, Map Event.IndexKey Event.Event)]
        where IndexKey = TrackTime
      . So I need a score integration with transformation.  I guess this is
        manual integration, right?
      . So this is like tscore, except I put the code in a track title, and
        it gets the track events as input.
      . Isn't this what derive integrate is for?  I can already do these
        transformations and compose them with that.  It can also effectively
        mute the track by not emitting the transformed events.
    - Implement collapsing score-integrated sub-tracks.
  cleanup integration:
    . Document all of the variations.
    . Can I refactor to be less error-prone and easier to understand?
      E.g. index by TrackId.  This would also eliminate part of
      Ui.fix_integrated_tracks.
    score integrate:
      block:
        . Call LIntegrate.score_block
        . It creates a new block and does
          Ui.set_integrated_block bid (source_block, ScoreDestinations [])
        . Set Block.block_integrated
        . validate: source_block exists
        . Special hook in ResponderSync.sync calls Integrate.score_integrate
        . Integrate.score_integrate
        . score_integrate_block damaged_source_block_id
        . Merge.merge_score_block source_id dest_id [], and set the new
          TrackDestinations.
      track:
        . Call LIntegrate.score_track
        . Ui.modify_integrated_tracks bid ((track_id, ScoreDestinations []) :)
        . Add to Block.block_integrated_tracks
        . validate:
          . source TrackId and TrackDestinations are in the block
          . each track is only the destination of one source
        . Special hook in ResponderSync.sync calls Integrate.score_integrate
        . Integrate.score_integrate
        . score_integrate_tracks (source_block, source_track)
        . Get ScoreDestinations dests from source_block with the damaged
          source track.
        . Merge.score_merge_tracks block_id track_id dests for each.
          Since dests is [] the first time, it will not find any destination
          tracks, and create a new one.  Otherwise, it merges to all
          destinations, and update block_integrated_tracks.
        . I replace everything with that source track, since I just updated
          all of its destinations.
    manual integrate:
      tscore:
        . Call TScore.cmd_integrate
        . Looks up Block.block_integrated_manual by SourceKey "tscore" and
          calls Merge.merge_tracks block_id.
        . Ui.set_integrated_manual block_id source_key (Just new_dests)
        . Inserts (Block.SourceKey, dests) into Block.block_integrated_manual
        . Since this is manual, there's no responder hook.
    derive integrate:
      . Integrate.cmd_integrate
        . block_integrated = [(source_block, ScoreDestinations [])]
      . Derive.Integrated comes out of derivation:
        { integrated_source :: !(Either BlockId TrackId)
        , integrated_events :: !(Stream.Stream Score.Event)
        }
      . Convert.convert integrated_events -> Convert.Tracks [(Note, [Control])]
      track:
        . Get Block.block_integrated_tracks
        . Get DeriveDestinations whose source_id == integrated_source_id
        . Either create a new dest (merge with []) if dests == [], or merge
          to each of the dests.
        . Convert.Tracks -> Merge.merge_tracks [Block.NoteDestination]
      block:
        . Get blocks with Block.block_integrated source_id == derived_block
        . Either create a new block if [], or merge to each block.
        . Convert.Tracks -> Merge.merge_block dest_id tracks track_dests
    generated parts:
      . This is score integrate, but with a transformation.  So I think I
        augment score integrate with a transform step.
      . I need a place to stick that transform, and since a source can go to
        multiple destinations, I think it has to be on the source.
      . The other difference is that the transformation can make multiple
        tracks.  So it emits [[Event]] and tracks are matched by zipping, like
        with tscore.
      . I also want to trigger it from a derive call, which I think is
        orthogonal.
    how to simplify Block?
      kinds of integration:
        . derive: after each cmd, I get Derive.Integrated, convert to [Event].
          Keyed by source BlockId or TrackId.
        . score: after each cmd, I get damaged tracks, transform to [Event].
          Keyed by source BlockId or TrackId.
        . manual: on command, I get [Event]
          Keyed by arbitrary SourceKey.
      . Each one has a source: BlockId, TrackId, or manual, which is where the
        events come from.
      . Each has a key: BlockId, TrackId, SourceKey, which identifies the set
        of destinations that receive the integrate.
      . Each track can only be the destination of one source:
          block_destination_to_source :: Map TrackId Source
          data Source = Manual SourceKey
      . Or maybe it's more natural to go the other way.  Because if a source
        has multiple destinations, I lose the sharing of the sources.
          block_source_to_destination :: Map Source [Destination]
          data Source = Manual SourceKey | Track TrackId | Block BlockId
          data Destination =
      . A block can only be the destination of one source, and a track can
        only be the destination of one track, in the same block.

lilypond:
  - Lilypond complains about simultaneous tempo marks due to the ly-global
    distribution.
    . I guess I want just one after all.  But what about extracted parts?
    . I probably extract parts by succesively setting staff_display, so I'd
      need something to put ly-global or something in the top visible staff.
  yangqin-zheng-kendang/house-2014
    - xstaff notes are not appearing in the right places
    - Where do those double sharps come from?
  - write a ly function for that quarter = eighth stuff?  I have it in both
    huiyin-concert and squart/spawn
  fix viola-sonata
    - Looks like another lilypond change:
      . score.ly:663:63: warning: this Voice needs a \voiceXx or \shiftXx
        setting
        af8 \mf bf8 c'8 df'8 d'8 a'16 ^( d'16 \change Staff = "down"
        ><
        a16 \change Staff = "up" gf'16 d'16 \change Staff = "down" d16 ) |
        % viola-sonata/pno3-2 viola-sonata/pno3-2.t15 62.75-63; 52
  - It's really confusing how transformer and generators work for ly calls.
    . E.g. I assign ly-span in ky to generator, then doesn't work as
      a transformer.  But if I make it a transformer and add |, then I get the
      bogus 0 dur empty event implied.
  - Similarly, it's awkward to have transformer + generators just so I can put
    multiple bits of code on one event.  I wonder if it's worth adding a ';'
    separator that allows multiple expressions?
  ties: rhythmic spelling:
    - I prefer the old 3/4 spelling: 2~ 8 8 | to the new spelling 4~4. 8
      . Beaming should at least be 3/4, but that's lilypond.
      . Shouldn't I be able to write 16 8. instead of 16 16~8?  Both old and
        new do the latter.
      . The new way spells 16 8 16~16 8 16~16 etc.  Why not 16 8 8 8 8 ?
      . Could I put in ad-hoc spelling rules?
    - I could do manual rhythm spelling with a special directive to turn off the
      meter, and then use a tracklang-level tie to join notes.
      . Or if I could annotate individual notes with tie directions.  That way
        I could apply a pattern to a whole section.
    - Staff notation has a notion of rhythmic spelling, which, being
      proportional, karya lacks.  In most cases I want to automatically infer
      it, but would it make sense to spell it explicitly in some cases, and
      how would that look?
      . I guess I could add a tie annotation, which merges duration with the
        next event, and a lilypond mode that ignores the meter and puts down
        each duration explicitly.
  / add 'ly-~' to add a lilypond-only tie for e.g. trill -> non trill
    transitions
    . Actually I'd want this to delete the following note and extend this one.
      Are there any complications?
    . Yes, of course, I want this to happen at the track level but of course
      that's lost by the time it gets to ly.  I can already do this though,
      with a if-ly type refactor.
  - Can I get it to print time signature on each line?
    . There's no built-in support, I'd have to hook into clef display code to
      add the time signature.
  trill:
    . http://lilypond.org/doc/v2.18/Documentation/internals/trillpitchaccidental
    - It doesn't like my ^\trFlat variants on notes within a chord, while
      \trill is fine with it.
      . This might work:
        trFlat = \once \override TrillSpanner.bound-details.left.text = \markup{
          \concat {
            \musicglyph #"scripts.trill"
            \translate #'(-0.5 . 1.9)
            \fontsize #-7
            \with-dimensions #'(0 . 0) #'(0 . 0)
            \flat
          }
        }
      . Nope, but maybe I have to use that with \trill.
    - Wavy line should extend to the end of the note, not stop at the
      beginning.  Lilypond seems to stop too early.
      . It wants \stopTrillSpan to go after the note *after* it ends.
      . Maybe I can do a AppendNext, which goes after the next note, but
        before any of its other appends.
    - Also the example pitch has an extraneous natural, but this seems to be
      built in to \pitchedTrill.

  - Warn about free code events that don't line up with a note.
    . Test in Process_test.test_note_code
  - add subdivision tests to Process_test
    . Make sure per-voice subdivision changes also work.
  - ly^ is confusing, it seems like it should be ly-^
    . Either that or get rid of the hyphen for everyone.
  - harmonic string arg is hard to use if I have to give nn.  How about
    strings export (g) (d) etc. calls which emit the appropriate string's nn?
    Or should I understand string names?
  - What's the difference between tracks '> | ly-track' and '> | when-ly'?
  - It would be convenient to be able to see where I am in the ly score, e.g.
    measure number.  Lilypond derivation makes a ScoreTime -> measure mapping,
    I'd just have to save that and invert it.
  - Infer ruler from meter markings, or maybe the other way around.  Meter
    markings seem more convenient, but maybe I could just make LRuler
    similarly convenient.
    . But since the ruler is more flexible, it's easier to infer ruler from
      meter than the other way around.
  squart/6:
    - Why does 7/8 not bar the eighth notes?
      . Because lilypond does beaming on its own: lily/Auto_beam_engraver.cc,
        configured in scm/auto-beam.scm and scm/time-signature-settings.scm
      . I should be able to use Meter for beaming too, but for now just beam
        manually.
      . I need to set the subdivision explicitly:
        \set Score.beatStructure = #'(2 3 2)
        Or \compoundMeter #'((2 8) (3 8)) to also set the visible meter.
      . Have the meter and subdivision commands set beatStructure for
        meters where lilypond doesn't already do a good job.
  - lilypond: espressivo <> should be like a normal hairpin
    But the way to do this is awkward, << .. { s4 s4 \< s4 \> s4 \! } >>
    . I also want tied notes to expand to 'c4~ \< c4 \>'
      But that has problems, I need a \!.
    . Even '<< b'2.~ { s4 \< s4 \> s4 } >> | b'4 cs''4 \!'
      is not ideal, the decrescendo extends to underneath the next note.
      If I put \! on the tied-to note, it still won't extend.
    . see \at in https://github.com/openlilylib/openlilylib/tree/master/input-shorthands/articulations-not-aligned-with-notes
    . Ideally:
      a \cresc \decresc % over duration of the note
      a \cresc ~ a \decresc % same
  - Lilypond.write_empty_staff creates incorrect rests for a tuple, as shown
    in Lilypond_test.test_add_bass_staff
  - to make notes without duration, ignore the existing duration and choose
    the simplest possible duration.  For zheng, yangqin, percussion.
    . Exception for +trem
    . Also applies to pizz, and sonically equivalent things like +det detache.
    . Or maybe I can fix detache in VSL by ignoring NoteOff, I think it can do
      that for pizz and staccato too.
  - optionally emit the lilypond to display a compound meter, e.g. 3+2/8
  jianpu
    . Research jianpu conventions, but basically:
      . Hide staff lines, stems, beams.
      . Noteheads replaced by numbers
      . Use a somewhat proportional layout.
      . Lines for 8th, 16th etc. notes.
      . Dots for octaves.
      . Stack chords vertically.
      . Grace notes as superscripts.
      . I still use lilypond's bars, slurs, tuplets, dynamics, etc.
    . http://people.ds.cam.ac.uk/ssb22/mwrhome/jianpu-ly.html
      . Produces extremely mangled lilypond.  I should make my own from first
        principles.
    . standalone commercial software:
      http://www.medeli.com.cn/soft/gb/soft.asp

negative duration / arrival beats:
  new arrival notes scheme infer-duration:
    . I don't want to trim because I might need the controls if I extend the
      duration.  I do want to trim because I don't want e.g. t-dia at start
      from the caller, but I do want pitch at start from the block.
    . t-dia:  0   1   0
              b1  b2
              a b|c   d
              a b|    d
    . If 'c' is present, then I clip off t-dia because I drop controls
      starting at 1.  The starts are replaced with ones from b1.
      So the sample at 'start' should come from the local block only.
      Samples after start can be used from global.  So what if the block
      call just deleted samples at exactly block end?  Any local tracks
      could put a sample there, but otherwise the event gets control signal
      afterwards.  If there is a note to replace, the >start samples are
      replaced, but otherwise, I get the ones from the caller.
    . E.g. global filter sweep.  A infer-duration note would stick out
      because the sweep is meant to be continuous.  In this case, I can
      just use the untrimmed control.  But t-dia should not do that, unless
      I really am treating it continuously.  This is the same problem as
      whether a control should continue changing into the decay or not.  The
      sweep should, but a pitch belongs to the next note.  So maybe this is
      a fundamental limitation of the score language.
  represent arrival notes differently
    . Instead of representing arrival notes as the sounding time plus
      a negative duration, I could represent them as a start time plus a flag.
      If the flag is set, it's considered an arrival note and the trigger line
      is drawn at the bottom instead of the top.
    pros:
      1 Cmds work the same for negative and positive durations, I don't have
        to do any special checks for overlapping with a following negative
        event.
      2 I can have a note arrive and another depart from the same point, e.g.
        trill up to a note.
    cons:
      3 The encoding seems not as elegant.  I can still do it with negative
        durations, but now the negative is just a flag, rather than
        representing the actual extent of the duration.
    4 This means that cmds work spatially rather than logically,
      i.e. I'll need a separate "set beginning" cmd since it becomes set
      duration for negative events.  I don't know if that's a pro or con, but
      it feels like a con since I need more cmds.
    #1 might not be compelling if I've already done the work to get them to
    work, but if it's buggy or turns into continual for for every cmd then it
    becomes a big deal.

external:
  ghc compilation time:
    - Cmd/GlobalKeymap.hs 400 lines: with -O: 72.89s, without: 1.26s
      . Something pathological, reduce it and ask on mailing list.
      mac:
        8.8.3: 60-70s
        9.0.1: 57s
      linux:
        8.10.3: 70s.
  hpc:
    - there should be a way to turn off .tix generation
      . also HPCTIXFILE /dev/null shouldn't crash
    - hpc tool is slow and noisy
      . hpc markup shouldn't spam Writing
      . and it should create index.html
    - ghc runtime shouldn't hard crash if it doesn't recognize the tix file
  parsing "1r" instead of "1s" gives a "unexpected eof" error msg, it should
    say 'r' was an unknown suffix
    Can't get attoparsec to consistently report an error.  Kind of hard when
    it always backtracks.
    - Need to add <||> to attoparsec.
  + send a patch to improve Random.Shuffle?
    . I did a very long time ago, but author unresponsive.
  + bug with cpphs: https://gitlab.haskell.org/ghc/ghc/issues/17185
    . I can put spaces in -pgmP.
    . Commented on the issue, but the workaround seems ok.

local: plugins:
  . http://simonmar.github.io/posts/2017-10-17-hotswapping-haskell.html
    . packages: ghc-hotswap, ghc-hotswap-demo, ghc-hotswap-so
  I also want local code in haskell.
    . I could put code in Local.Score.SomeName, and have those either
      statically linked in, or dynamically compiled and loaded on each
      derivation.
    . Static linking is easier, but I should at least automatically create
      a All.hs.
    . Also, creating calls is a bit heavyweight, since I likely don't care
      about tags and doc and module can be inferred.  Presumably I can get
      around that with a constructor that defaults those fields, and then
      the generated All.hs overrides the module.
    . Writing in tracklang lacks typechecking.  There could be utilities to
      write like tracklang, but in haskell, e.g.
        c_p1 = with_note_call "p" "subst1" $ block "pattern"
  . ghc can now unload code: http://ghc.haskell.org/trac/ghc/ticket/8039
  . might be relevant: http://hackage.haskell.org/package/dynamic-loader
    http://codeutopia.net/blog/2011/08/20/adventures-in-haskell-dynamic-loading-and-compiling-of-modules/
  . to do per-score code, I can put it in Local.Score.<namespace>
    Convert to module name by replacing -x with (upper x) and capitalizing the
    first letter.
    Then when you load a score, incorporate the static config from that
    module.  Shakefile can link in the local modules under the right name.
    . If it gets to be too much overhead to link on every single build, then
      I can load dynamically at runtime.

cleanup:
  - Derive.Score is more like ScoreEvent... but Score.event_start is nicer
    than ScoreEvent.event_start.  If I made it just Event, I could say
    ScoreEvent.start.
    . That's not really better than Score.event_start.  Maybe SEvent.start?
      I'm not ready to abandon record prefixes though, they're still the only
      thing that consistently works.
  - better serialize
    - I want a more systematic and safer approach to versions
      . I want everything to be versioned.  Since it's manual I was
        inconsistent about it, which has always been a problem.
      . But when I serialize repeated things, I want to only store the version
        once, e.g. Event shouldn't have a version, but Events should.
        I currently do this, but it's all manual.
      . The other problem is that I have serializes where I care about versions
        (Cmd.Serialize) and where I don't (Instrument.Serialize).  Conveniences
        like put_enum are ok for the latter but not for the former.  Since they
        use the same Serialize class they can get confused.
      . A manual approach would be: split into Serialize and SerializeVersion.
        SerializeVersion can use the Serialize implementation, but *might* add
        a version.  Dangerous things like put_enum are simply not in
        SerializeVersion.
    - binary is known to be slow, use something faster?
      . Comparison at: https://github.com/fumieval/winery#readme
        . store is the only significantly faster one.
      . binary-serialise-cbor is out and implemented by serialise, try switching
        save format to that.
        . It's now called serialise, or cborg for the low level one.
        . Not appealing since it includes field names, and having both
          (tag, len) looks both redundant and error prone.  Versions are as
          manual as ever.
      https://hackage.haskell.org/package/persist
        . It seems to be compatible with cereal, but faster?
        . No comparisons.
      https://hackage.haskell.org/package/store
        . More docs.
        . Giant dependency list, and incompatible interface.
        . Maybe I can use 'store-core', since it looks like I don't want any
          of the stuff in 'store': generic deriving, builtin types.
        . instance Store a => Store (Ratio a) where
              size = combineSize (\(x :% _) -> x) (\(_ :% y) -> y)
              poke (x :% y) = poke (x, y)
              peek = uncurry (:%) <$> peek
        . It looks like a hassle to track size.  And leads to memory
          corruption.  It really wants you to use the generics, but that's no
          good for version changes.
        . There is a Data.Store.Version, but looks overengineered and uses TH.
      https://hackage.haskell.org/package/winery
        . A generic structure thing like cbor, but stores structure just once.
        . Storing the schema looks awkward.
  - support cabal new-build
    . The advantage is that people can install dependencies without messing up
      their global package db.
    . Also I might be able to skip the install build tools step.
    . cabal sandbox already does this, but with new-build they can reuse
      installed packages.
    . I think to support this I install deps via new-build --only-dependencies
      and then compile with: -no-user-package-db
      -package-db $HOME/.cabal/store/ghc-8.4.1/package.db
    . Also I could consider using a freeze file if there are problems with
      deps.
    . The advantage of doing this for travis is that I can resue the cache but
      still use latest library versions as they come out.
      . I think?  Or does it prefer what's installed?
      . It's hard to test this with 8.4.1 because every single package was
        just update, so only has one valid version.
      . It will use global packages, but it won't use old versions in user db.
      . Yes, it will use the newest packages available.  This is probably good
        for CI, since it means I find out about new breakage.
      . If I can set up performance CI, then I can find out about performance
        regressions due to dependency changes.
      . But locally maybe I want to freeze, to avoid churn whenever I install
        anything new.
    . All in all, this is not really a big deal.
    . I think I'd really want to do nix, then I can get all dependencies in
      one go.
  - see TODOs: lentil ^build
  / replace fromIntegral with http://hackage.haskell.org/package/int-cast?
  - visualize module dependencies: https://github.com/yav/graphmod
  . Merge Val and MiniVal (RestrictedEnviron.Val for now).
    . NOTE [val-and-minival]
    . The problem is that I'd like to use Val to communicate with tracklang
      without having to re-parse, e.g. via Expr.ToExpr, but that means I can't
      use Val without dragging in Derive, due to VPitch.  I don't need the
      separate MiniVal if I can get rid of VControlFunction and make VPitch
      not in Derive, have a ShowVal, and serializable.
    . I already want to get rid of ControlFunction, but not sure how to do it.
    . I should be able to do those things with Pitch by adding more function
      fields.  Or alternately, typeclass + existential, but I'm not sure if
      that's any better.
  / Cmds don't indicate when they could abort or throw.  I rely on ad-hoc
    conventions like get_ vs. lookup_, but what about it actually being in the
    type signature?  I could try the "lightweight checked exceptions" in:
      http://www.well-typed.com/blog/2015/07/checked-exceptions/
      https://www.reddit.com/r/haskell/comments/3g41au/follow_up_safe_lightweight_checked_exceptions/
    . Or an easier way would be to put 'throw' in a subclass.
    . I have this implemented in the p-monad branch, but it didn't seem
      terribly compelling.  I think the reason is that it turns out most
      functions can throw.  It doesn't replace get_ vs. lookup_ because they
      are likely to call something else which can throw.
  . Could I simplify slicing and inversion by making it into a score
    preprocessing step?  It would annotate UI Events with children, so the
    sub tracks would be in Event, not in Context.
    . If I could get rid of the ctx_sub_events / ctx_sub_tracks thing too that
      would be nice.
    . Could I also somehow make inversion universal?  The idea is to
      eliminate the thing where I forget to add Sub.inverting.
    . I could also take evaluation control away from the event, effectively it
      would mean the Sub.notes bit would be hardcoded and events would get
      [[Sub.Note]] instead of a TrackTree.  I'd lose power, but what are the
      advantages?
  . Things I don't like about evaluation:
    . All that stuff in Context.  The presence of sub_tracks can cause
      unexpected further inversion.  An example is that when I inherited
      the Context for Call.note_here, it also inherited the sub_tracks,
      which caused Call.with_pitch to be overridden.
    . It's also dumb how Context has the event (start, dur) duplicated
      in the 'event' field.  It's not duplicate info for track events
      because they have TrackTime, which is otherwise unavailable.
      This I think is ultimately due to events being in TrackTime
      context instead of (0, 1) normalized.
    . Maybe the problem is inheriting Context?  Or maybe it's awkward
      how it's effectively a manually passed packet of data, while the
      stuff in Dynamic is dynamically scoped.  Events wanting to know
      about their neighbors really does complicate things.
    simplify Context
      . Maybe I should explicitly provide specific bits of context, e.g.
        . prev, cur, and next event TrackTime
        . prev and next logical pitch
      . Say I do that, and put them in Dynamic.  How can I then get rid of
        sub_tracks?
      . I still need prev_val
      . There's nothing intrinsically wrong with Context, ultimately it's
        just an argument, like passed_vals.  I guess it's easy to remember
        passed_vals as just the arguments and understand how they work,
        while that sub_tracks stuff was confusing.
      . Maybe it's just the presence of sub_tracks in Context?  How can
        I get that out?
    . That 'collect' arg in Eval.eval_expr.  Why False for Eval.reapply
      but other functions make the caller decide?
  - pitch transpose
    . It's confusing how sometimes the environ is applied to the pitch during
      derivation (e.g. Post.set_instrument), and sometimes it waits for Convert
      to do it.  Do I really need both?
      . The environ goes in the Score.Event, which is then applied to the pitch.
        So Post.set_instrument actually maybe doesn't work, if the event
        still has environ.  I have to replace the event environ instead.
    . Post.set_instrument needs to set because I need the environ from the new
      inst.  Could I instead overlay the environ into the event environ?
    . It's error prone because there's nothing that enforces that you set
      instrument with Post.set_instrument, and if you don't, it will work until
      you use a scale with e.g. tuning, and then it will be slightly off.
    - Maybe I should at least not export Score.Event(..) so I can't directly
      modify its fields?
    . Or maybe insist on rederive instead of just changing the instrument.
      In general that's the proper approach.
    . Originally added in the patch 'add interpolate scale':
      The bigger problem was that since pitches got the Environ at conversion
      time, the interpolate scale couldn't substitute `key-from` and `key-to`
      because any environ values it set before evaluating the pitch wouldn't
      "stick".

      So I switched to applying the environ when the pitch is created, but this
      broke the case that made me switch to applying environ at the end in the
      first place, which is when switching instruments in a postproc I want the
      new instrument's environ, specifically Environ.tuning, to apply to the new
      event's pitches.  So now when I switch instruments I have to explicitly
      apply the environ from the new instrument, via Post.set_instrument.
    . Also error prone: I applied octave transpositions via Call.add_constant,
      but then realize-ngoret uses transposed nn to infer, and untransposed
      pitch for the final pitch, so I get a confusingly wrong result.  The
      solution is to apply via Pitches.transpose, but I shouldn't have to make
      complicated decisions like that.
  - It seems I get slicing on an already sliced track if I have an
    intermediate empty note track, e.g.:
      [(">", [(0, 1, "")]), ("> | +a", []), ("*", [(0, 0, "4c")])]
    . Is it a problem?  Should I skip if already sliced?  Document if it's ok.
  - use Data.Vector.Algorithms.Search.binarySearch instead of my own, but
    make sure it has the right specializations.
    . Or at least use mine in Util.Vector.
  - Modification of State is still kind of messy since I have lens and
    non-lens versions.  And if I wanted to modify with a lens I wouldn't be
    able to add an effect, like causing damage.  If I used ekmett lenses maybe
    I could unify effectful modification.  I'd also need a way to focus
    on UI state.
    . For example, I can add an allocation with State.allocations, but if
      I wanted to make that cause damage I couldn't.  Of course maybe it
      doesn't matter since I infer damage based on config changes.
    . Also I can't make sure that UiConfig.allocate is used instead of
      directly modifying the map.  The root of the problem is that I have
      unrestricted modification via State.modify_config, but even if I removed
      that I'd want something as convenient as lenses, but with the posibility
      of effects, or at least access to Ui.State and Cmd.State.
    . That said, I'm not sure how much this actually matters.  Maybe I should
      wait to see if it's actually a problem before worrying about it.
    . I guess it already has been a bit of a problem, in that the test had
      a bug where it put on the wrong backend.
    - If State.allocations is so read-only, why not make it a plain function?
      . Tests use it to write...
  / Research a better solution to records: record:
    . generic-lens combined with generic-lens-labels, OverloadedLabels, and
      DuplicateRecordFields
    . Or, https://hackage.haskell.org/package/optics-core Optics.Label
    . At this point, wait for RecordDotSyntax.
      status: https://gitlab.haskell.org/ghc/ghc/-/issues/18598
  - Expr is NonEmpty since there is always at least a "" call, but this is a
    special feature of events.  Would it make more sense to parse "" as [],
    and then special case [] in EvalTrack.derive_event?
    . But I'd need a newtype, otherwise ShowVal [Call] overlaps.  Of course
      the only reason it doesn't already overlap is that a don't have
      a ShowVal for NonEmpty.
    . But Quoted is also Expr... should it be non-empty?
    . I now don't remember where it was that I had an Expr that made sense as
      [], so maybe I don't care about this anymore?
  - Move Derive.info_prev_val to the environ, maintained by EvalTrack.
    . This gets rid of all the Taggable stuff, at the cost of making
      Args.prev_val in Deriver and dynamically typed.
    . There's no Val for Score.Event, so I can't use it for note tracks.
      Of course I could just add one, maybe not a big deal.
  - Overlap detection in Derive.Slice I think is still messed up, or at the
    least it's more complicated than it should be.
  - I could make the fltk interface clearer by putting c_interface.cc into
    fltk, and then putting all the types it depends on in one header.
    . I could make that a .c file too, and get rid of the sketchy hsc2hs on
      c++, as well as clang's "treating 'c' input as 'c++' when in C++ mode"
  - split up CallInfo depending on type
    I got started but was discouraged when it came time to write
    GetLastSample, maybe I should make another go.
    Note tracks can't get a GetLastSample at all.
  - It would be nice to have a text interpolation syntax
    . E.g. "textlike: %s, %v ShowVal, %p Pretty, %x hex, %.3f showFloat 3"
    . Cmd.Load.Mod2.commands_to_controls: "from=%v | %s %v" vol c val
    . But printf style can't work for typeclasses without dependent typing
      because it doesn't know which one to select.
    . text-format: requires importing a bunch of formatters, type-unsafe
      . format "from={} | {} {}" ('val vol, 'str c, 'val val)
      . I don't like it because the format type is out of context.
    . formatting: import a bunch of formatters plus (%), type-safe
      . Probably worse errors.
      . format ("from="%'val%" | "%'str%" "%'val) vol c val
      . Still much noisier than "from=%v | %s %v".
    . fmt: even more operators and imports

performance:
  ruler: ruler-performance:
    . The ruler model of having all the marks all the time seems like it
      doesn't scale up to large blocks.  I would rather transmit minimal data,
      and materialize ruler marks as appropriate at the appropriate zoom
      level.
    . I guess this leads back to a computational notion of ruler instead of
      just the dumb [PosMark] data structure.
    . This comes up because I want to have a 'score' block whose ruler is the
      concatenation of the rulers underneath, and I'd rather it were that way
      by definition, rather than because it got copied that way.
  prof results:
    - Eval.eval
      . This is for val calls.  I don't use many of those, except pitches.
      . Most are from Control.derive_pitch
      . Most pitch calls are simple, I should be able to map
        Text -> PSignal.Pitch.
      . Also Deriver.Lib.state_controls_at calls eval/apply.
      . From c_block -> score_to_real -> d_note_track -> controls_at
      . Might be the Note.default_note
      . controls_at pays for ControlFunctions, which is the same thing is
        pitches, where they have to fetch everything they might need in
        advance, even though the majority don't need it.
      . controls_at itself is this, because it gets all controls though the
        note may only need some.
      . Laziness is one possible solution to this.  Another is to pass more
        and manually fetch the data when needed.
    - Internal.with_stack_block, with_stack_region
      . These are called a lot, but not sure why they get charged so much.
      . If this is due to add_stack_frame, then maybe it's still the seed
        updating stuff?
      . Seed is yet another instance of unneeded eager computation, though
        it's more complicated because the seed goes through many transforms
        before it's (maybe) needed.  I think I already tried to lazify it,
        and couldn't get it to work.
    - Score.transposed_at
    - Control.stash_if_wanted
    - Derive.PSignal.apply_controls
    - Derive.Control.d_control_track
    - Derive.Deriver.Lib.controls_at

  evaluating presumably CAFs in Vsl seems significant
    ? Shouldn't it only be evaluated if you use a vsl instrument?
    . https://gitlab.haskell.org/ghc/ghc/-/wikis/commentary/rts/storage/gc/CAFs
  . Staging via typed template haskell: uses [|| ||], $$.  Talk at
    https://vimeo.com/443276733 6:29:10
    . More talks at ICFP 2020
    . The ICFP talk claimed several times faster than happy, go find that.
      https://youtu.be/i9wgeX7e-nc?t=1679
  memory:
    . possible use this to get newer ghcs:
      https://gitlab.haskell.org/bgamari/ghcs-nix/
    ghc-debug
      . https://github.com/well-typed/memory-usage-zurihac-2021
      . requires 9.2
    eventlog2html
      notes:
        . use linechart to look for leaks, since it normalizes each one
        heap view:
          . live bytes: almost exactly what hs heap view shows
          . block size: total size of allocated blocks to the OS, so 2x for
            a copying collector
          . heap size: megablog (1mb) requested from OS
          . heap -> blocks difference is nursery size
      . set profiling interval, for heap sample interval.  Too often means too
        much time spent in profiling.
        +RTS -i1 for 1s
        also +RTS -s show GC time which will also reflect heap profile overhead
      . Debug.Trace.traceMarker
        eventlog2html -i can filter markers
      profile by info table (new): -hi
        . https://well-typed.com/blog/2021/01/first-look-at-hi-profiling-mode/
        . need -finfo-table-map -fdistinct-constructor-tables
        . eventlog2html detailed pane now has extra columns
          ARR_WORDS Cmm$ghc_1.cmm - from RTS
        . also can look for THUNK to make sure they are where expected
        . CTy = closure type
          CONSTR_2_0 - 2ptr fields, 0 data fields
          Just CONSTR is >2

      interactive editing, cerucuk-punyah.state
        - ?
      verify_performance cerucuk-punyah.state
        - Double 744.71
          . Spikes at certain places, what is that
        - ARR_WORDS 737.18
          . constant-ish, what is this?
        - Map 435.57
            . growing over time
        - actually a lot taken by Mark, can I intern those?
          . I'd have to do it on deserialize.
          . Mark and ForeignPtrContents are surprisingly large, maybe that's the
            ForeignPtr cache of the same stuff?
          . It's hard to share the same data because of the Texts in there.
          . In any case, probably can't share Marks because the labels are all
            different!
          . Is there a more compact way?  Somehow I'm back to very early days
            with the mark-generator...
        - What is with the periodic Color?
      . https://simonmar.github.io/posts/2018-06-20-Finding-fixing-space-leaks.html
    repl memory usage
      . I think this is high due to loaded modules.  What is it exactly?
    short data:
      - use short-text for Score.Event?
        . Is there attoparsec for it?  Would lacking slicing be a problem?
      - use short-bytestring for Id?  Or maybe just ByteString?  I think the
        space saving is negligable, but would it make hashing faster?
        . At least Namespace should be shared, but maybe not when loading.
          Can I intern it on load.  I can intern all the strings... why did
          I abandon that?  Maybe didn't seem worth it.
        . Transform.intern_text
        . Actually the number of Ids is low, just one per track and block.
      - I may not really have that much data?
        . Get some score stats (Ui.Transform) and figure out the weight of
          a loaded score ('weight' package)
        . Then, does the extra overhead hurt me?  Less memory is better, but
          is it drowned out by derive's memory use?
    nothunks:
      . https://iohk.io/en/blog/posts/2020/09/24/being-lazy-without-being-bloated/
      . Also there is ghc-heap-view assertNF
      - Check Ui.State
      - Check Cmd.State
        . Except state_current_performance
      - Check Derive.State during derivation.
    - find space leaks with nmitchell's stack limit technique:
      . run build/profile/verify_performance +RTS -K975K -xc -RTS --mode=Profile
          p/cerucuk-punyah.state
        Derive.LEvent.events_of,
        called from Derive.Stream.zip3_on.\,
        called from Derive.Stream.emap,
        called from Derive.Stream.zip3_on,
      . Also, what's with the compile_library stuff in the middle?  Should
        I make it stricter?
      . Giving up for the moment since I don't understand the output.
      . Maybe it was nonsensical due to auto SCCs?
  research:
    . https://ollef.github.io/blog/posts/speeding-up-sixty.html
      ? Look at threadscope again for GC allocation size: -A50m
    . https://hackage.haskell.org/package/stackcollapse-ghc
    . https://github.com/grin-compiler/haskell-code-spot
    . ghc-debug
      . Coming in ghc 9.2.
      https://www.youtube.com/watch?v=9zuAsGk9xoM
      https://well-typed.com/blog/2021/01/fragmentation-deeper-look/
    . http://neilmitchell.blogspot.com/2013/02/chasing-space-leak-in-shake.html
    . https://bgamari.github.io/posts/2016-03-30-what-is-this-array.html
    . https://lukelau.me/haskell/posts/leak/
    . https://www.well-typed.com/blog/2020/08/memory-fragmentation/
  general:
    - use 'text-builder' for Pretty and Log?
      . Unfortunately it has tons of dependencies, due to deferred-folds ->
        foldl.  Looks like it's not really a necessary dependency though.
    - vector-builder can replace Util.LazyVector?  I don't use that though.
    . Speedscope for flamegraphs from ghc-events:
      https://mpickering.github.io/posts/2019-11-07-hs-speedscope.html
      . Requires ghc 8.10.
    . use weak pointers to detect space leaks more precisely:
      https://github.com/ghc/ghc/commit/5fe6aaa3756cda654374ebfd883fa8f064ff64a4
    . Criterion-like with fewer deps: https://github.com/vincenthz/hs-gauge
      . Also supposedly --measure-with to run each in a separate process
        produces more consistent results.  But there's no reason I can't do that
        on my own.
    . http://www.tweag.io/posts/2017-09-06-hyperion.html
    . https://github.com/tobami/codespeed can make a web page with perf graphs
    . https://github.com/nh2/haskell-cpu-instruction-counter
      . But only works on linux.
    - experiment with GC flags
      memory usage:
        . 200 mb -> 350 rss
        . 250 by LDebug.memory and ekg, 500mb by system viewer.
        . I think I have a very large proportion of static data in the GHC API
          loaded .hi files, so that should avoid GC as much as possible.
          Increase the generation count?
          . In the future can I put that in static memory regions?
        . Then I have a lot of short lived garbage generated on each derivation.
        . Then the rest is medium life: score data, Performances.
      . -A8m - larger generation 0 means fewer collections, good if lots of
        garbage is generated.
      . H - Suggested heap size.  I don't really understand this.
      . -qg - turn off parallel gc
      . -n2m - divide -A into chunks, so the first thread to run out doesn't
        trigger a GC for all of them.  Good for unbalanced allocation?
      . -I0 to turn off idle GC.  But it's designed to be good for interactive
        use, and maybe I do pause for >.3s.  Or turn it up to 1sec?
  fltk:
    - tile based rendering so zooming goes back to being fast
      . Alternately, qt supposedly does this stuff "automatically" though no
        one is clear on it.
      . I'm then back on the incremental problem, where text visibility is
        dependent on coming from the top.
      . If the expensive part is drawing text, I could draw everything but the
        text, and then put that on top on demand.
      . I would still have to allocate the giant bitmap at once, and fetch
        all events, and draw non-text, so time that separately to make sure
        it's fast.  I can just turn off text rendering and try it out to get
        a feel.
      . This will break the CachedScroll abstraction, or it will need to have
        hooks.
      . It can call the child to do the initial draw, and then have to somehow
        call it for tiles.  I use Fl_Image_Surface::draw(Fl_Widget *) to draw
        the whole thing, I guess it's hardcoded to call Fl_Widget::draw, maybe
        I can look at the source to change it to call a draw_tile() method.
      . Fl_Surface_Device::push_current(surface);
        // fiddle with coordinates to set origin relative to widget
        widget->draw();
        Fl_Surface_Device::pop_current();
      . I could also make an alternate widget with a ::draw() for the tiles,
        but how would I tell it which tile?  I guess I could ask the child for
        a per-tile widget which has the appropriate draw:
          surface.draw(child.tile_at(offset));
      . Also have to keep the surface alive, so I can accumulate draws in it.
        I guess it'll make copies for each surface.image() call, but that's
        a copy, so quick, right?
      It's not the text, what is it then?
        . line 24533
        0.04 events -> EventTrack::draw-start
          ? many fl_draw, what is it drawing?  It's before find_events!
            they are all 0.00004s, but many of them.
            . It only happens once, this is probably the ruler!
          . 0.0073 fl_draw -> draw-start
          . 0.01   find_events
          . 0.0076 draw_waveforms
          . 0.009  ruler_overlay
          . Then (drawable_pixels, draw_trigger, fl_draw, draw_text_line) etc.
            Each is ~ 0.0003
          . 0.02 draw_upper_layer
        0.02 EventTrack::draw_upper_layer -> EventTrack::selection_overlay
        Block::draw ======> Block::draw 0.6480
      seq.events.3:
        0.0361 RulerTrack::ruler_overlay 28737
        0.0083 RulerTrack::selection_overlay 28738
        0.0127 EventTrack::find_events 28740
        0.0064 EventTrack::draw_waveforms
        0.0092 EventTrack::ruler_overlay
        0.0253 EventTrack::selection_overlay
    - cache fl_draw
      (int rotate, char *text)
      . Actually, cache the whole symbol.
      . Also cache measurements: draw(string, Style) measure(string, Style)
      . Style: Font, Size, Fl_Color
      . Turns out I already have CacheMap in there!  It only caches glyph
        size, so I can probably get rid of it.
    ? Could I parallelize drawing?
    ruler_overlay
      . .035 (with text), .01 (without)
    find_events
      . 0.013, 0.005, 0.01, ... depends on how many events
    before selection_overlay
      . 0.02, 0.015, 0.028, for all tracks
      . It's between EventTrack::free_text and SelectionOverlay::start
      . That's after the CachedScroll Body draw, so maybe it's overhead?
    ? Could I draw ruler_overlay once and then just stamp it on?
    ? To make find_events faster, could I store them in the Storable C format,
      and then convert to haskell for derivation?
      . Or maybe keep both, the extra memory is probably low.
    historical stats for scrolling:
      . Stats:
        13.5686 sync_status
        6.7 sync.verify
        8   sync.diff
        9.2 sync.sync
        7.7 derive_diff
      . New times:
        17.5420 sync_status
        0.0065 sync.verify
        0.0653 sync.diff
        0.0183 sync.score_integrate
        7.3165 derive_diff
      . Newer times:
        0.2990 sync_status
        0.0050 sync.verify
        0.0160 sync.diff
        0.0027 sync.sort
        0.3360 derive_diff
  cmd:
    - Integrate.score_integrate is linear in score size
      . needs_track_score_integrate
        . Needs TrackId -> [Block], which is also Ui.blocks_with_track_id.
        . Cache: track_to_containing_blocks :: Map TrackId [Block]
      . needs_block_score_integrate
        . Does a linear search for blocks with ScoreDestinations.
        . Cache: block_to_integrate_sources :: Map BlockId [BlockId]
      . I could put these in Ui.state_cache, which is not saved and loaded,
        but initialized by Ui.put, and updated by the various functions
        that invalidate it.
      . But since this only happens on event modification, it's not so bad as
        the scroll lag.
    - implement or find a cps-transformed ExceptT for Ui.M.
    - Update.UiDamage could mark Ui.state_config damage
      . I could remove the compares in Diff.score_changed and Diff.diff
    - For Update.UiDamage, research if it's less efficient to mappend mempty vs.
        direct modify
    - log total respond latency, and log if over a limit
    . Would it be more efficient to collapse CmdUpdate and Ui.State into
      a strict pair?
      . Probably... what does a fully inlined mtl layer become to (>>=)?
      . Nested states turn into a function of two args, paired state turns
        into one arg of a pair... I think my test was too small since
        everything inlines.
      . So actually probably nested update is same efficient, if not more.
        The values wind up as function calls, which means ghc can decide if
        it wants to pass on the stack or in registers, while a tuple is always
        heap-allocated.
      . What about that ExceptT though?  I think that's definitely inefficient.
      . Why isn't there a exceptt-cps package?
    - When I'm using ghc 8.2, try compact regions for inst db, especially vsl.
      . 'compact' package
      . Maybe even serialize it to disk?  Probably not worth it though, since
        startup is pretty fast and probably inst db is not a big part.
        . 0.584cpu / 0.222s.
      . Can I use heap profiling to find other large CAFs?
      . Can I use compact regions for the REPL loaded modules memory?
      . compactWithSharing is slower but retains internal sharing, test to see
        if it's worth it.
      . https://tech.channable.com/posts/2020-04-07-lessons-in-managing-haskell-memory.html
    - Reduce memory used by REPL.  NOTE [reduce-repl-memory]
      . About 200mb.
      . GHC reads interfaces maybe with ghc/compiler/utils/Binary.hs:/readBinMem
      Try -fignore-interface-pragmas
        . From ghci: 210mb without vs. 1552mb with
        . But from REPL seems to make no difference.
        . Actually, I can't reproduce this now.
      . 200mb for an empty score seems excessive.  Where does it go?
        . With inst db: 197, without sysex: 190, without vsl: 187.4
        . Without repl: 12mb
        . So 190mb consumed just by loading .o files!  du on obj dir is just 76mb.
        . Loaded modules:
          [254 of 255] Compiling Local.Repl       ( Local/Repl.hs, interpreted )
          [255 of 255] Compiling Cmd.Repl.Environ (Cmd/Repl/Environ.hs,interpreted
          . with verbosity=2:
          . Stable obj: [Local.Instrument.Kontakt.Wayang, ... 253 modules
          . log: Ready for upsweep
            [NONREC
                  ModSummary {
              { ... imports of every module }
          . compile: input file ./Ui/ScoreTime.hs
            *** Checking old interface for Ui.ScoreTime:
            [ 41 of 255] Skipping  Ui.ScoreTime( Ui/ScoreTime.hs,
                build/opt/obj/Ui/ScoreTime.hs.o )
            *** Deleting temp files:
            Warning: deleting non-existent /var/folders/6j/.../ghc_62.hs.o
            . bypecode compile for last two modules
      . 'du -hc build/opt/**/*.hs.o | tail -1' shows 55mb for object code,
        and 19mb for .hi.  I'd think object code would be loaded directly with
        little overhead, but that means .hi code expands by (190 - 55) / 19 = 7x
        expansion, which seems like a lot.
      . Also the memory measurements are haskell heap, which might not include
        loaded object files.
      . However, it's also loading .hi files for external packages too, though
        I'm not sure how much.  The external package code is shared libraries,
        which is shared with the app (and not in the haskell heap anyway).
      . Use dtrace to figure out exactly what the GHC API is loading and when.
      - I should be able to share object code by linking everything as a shared
        library... that might save 55mb at least?
    - Allocation when idle: about 300kb/sec
      . What triggers this?  Nothing, it's basically always happening.
        No, the allocation is always happening, but usually it doesn't get
        retained.
      ? Who is running?
        . Threads:
          / main - Ui.event_loop - should be blocked in Fl::wait,
            though it comes back on every cursor move.  But still allocates even
            when it doesn't have focus.
          . responder - Respond.responder - Should be blocked in STM.atomically
            block.
          / Midi.CoreMidi.initialize forkOS - goes into CFRunLoopRun
          / interpreter
          / Responder accept repl socket
          . Cmd.Performance: eval performance
          . Cmd.PlayC.play - updates the playback
          . Perform.Midi.Play render midi
        . Could it be EKG?
      . It stops during play.
      . Try disabling ekg and use LDebug.memory and see if it's still there.
      . It still grows without ekg.  Well, the second time it seems like it
        moves but doesn't grow.
      . Is there some way to instrument allocation so I can see which thread is
        doing it?
      . Actually it seems like ghci does it all by itself.  So it's either
        inherent to the GHC API or ghc runtime in general.
      . Does it grow with the repl off?  Yes, so apparently not the repl.
    - Check out score size with 'weigh', ala https://github.com/haskell-perf
      . cerucuk-punyah: blocks:25 tracks:194 events:6163
    - the first REPL cmd can take 2-3s, but they're fast after that, why?
      . Presumably it's forcing a bunch of CAFs.
    - If a msg aborts or doesn't run any cmds, don't bother to run diff.
      Except that hardly ever happens if I do shortcut thru.
    - cache track cmds for each track, update when the track title or skeleton
      changes
  derive:
    parser:
      -fexpose-all-unfoldings can speed up parsec, at the cost of code size
    suspected problems:
      . transformer streaming:
      . signal resampling: Signal.map_y
    - transformer streaming:
      . I suspect that transformers would be more efficient if they streamed,
        but how can I demonstrate an improvement?
      . I think it would manifest as drag, or at least as more active memory.
      . It should reduce memory use.  Can I make a demonstration profile?
        Have a long block of notes, then a few layers of id transforms.
      . No apparent difference between 0 and 8 layers of transformer.
    memory use
      . Do -hy, -hd, -hb runs.
      hb:
        . Seems to be phase 1 2 3.
        . I have tons of void, increasing: 29mb to 70mb, spikes in phase2.
        . Some INHERENT_USE, phase 1, increasing slowly; 2 flat: 16m to 21mb
        . Drag spikes in phase 2.
        . I suspect phases correspond to derive, then force the results, then
          write the results.  Can I put in markers to verify that?
        . Perhaps void is stuff in Collect I don't use?  If I had the Cmd
          layer, this might look different, run a profile on seq.
        . INHERENT_USE might be ARR_WORDS, which might be signals.
          Or could be ByteString or Text.
        VOID
          . Given f (g x), if the value of (g x) is never demanded, but is
            nevertheless stored in some data structure for a while, then it is
            void.
          . So this is basically laziness working.  If I want to reduce it,
            I have to not store things I won't evaluate, or maybe force them
            when not necessary (trade work, but allow GC).
        INHERENT_USE
          . Primitive objects like arrays and mutable variables, where we
            don't record the use time so we consider them to be implicitly
            used.
          . I don't really have mutable variables, so must be arrays.  Maybe
            it's ARR_WORDS?
        DRAG
          . You haven't touched the data for a while before it goes out of
            scope or its retainer goes out of scope.
        LAG
          . How is something created before it's used?
            oh, that happens a lot.  e.g. in  f (g x), if f doesn't demand the
            value of its argument for a long time, then the heap closure for
            (g x) is lagging.
        . http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.30.1219

    profile with SCCs
      . tools/run_profile verify_performance
      + put SCCs on... where?
        + I could still try a run with -fprof-auto-top, to see who gets
          called a lot.
        . bsearch_above, called by Util.Segment.at, called in many places.
          148406: from event_environ <- event_controls_at <- transposed_at
            <- DeriveT.pitch_nn <- Score.nn_at <- Score.initial_nn
            <- Idiom.next_same_pitch <- Idiom.avoid_overlap
            <- Postproc.apply_start_offset
        . From the flamegraph for bsearch_above, expensive:
          Semigroup DeriveT.PitchConfig <>
          called from Score.transposed_at -> PSignal.apply_config
    flamegraph:
      . What are samples?  It says 1,000.
      . Can I get the number of entries in tooltip?
      . Sorted by?  Time by default, can be --alloc or --entry.
    improvements:
      - use HashMap for Environ?
      - if parser is slow, then try separate lexing
      * Write a tool for diffs on .prof and .gc so I can feel good.
        . tools/profile_verify.py parses .gc
        . Then just diff the top CC list from .prof, sort by name.

    + Bring back profiling, and do it regularly.
      . Look into that graphing stuff, I have the links around here somewhere.
      . I can get historical data with a script to step through darcs history.
      . I don't have historical scores.  Well, I have backup/y-m-d, but they're
        done irregularly and don't line up to commits.  Still, I should be able
        to do ok by looking for the closest match.  Outright failures should be
        visible as outliers.
      . Profile MIDI and ly generation separately?
    - try INLINEABLE for the functions in DeriveM.
      . I think no good though, because DeriveM is already concrete, so there
        are no dictionaries to specialize.
    signal:
      - Util.TimeVector is Vector.Storable, which is pinned, which leads to
        fragmentation
        . Is it a problem?  I think I don't really need Storable, because I
          pass signals to fltk via a copy anyway.
      - clip_before and clip_after usually require changing the signal
        . I could eliminate this with _start and _extent fields.
      - Segment._offset might not be worth it
        . Since I think it's only really used to move Score.Events, I could get
          the same effect by making event signals relative to event start.
      old notes:
        . Slicing a signal will require changing the vector, to add a new
          sample on the beginning or end.  I could eliminate this with _start
          and _extend fields.  Not sure if it's worth it.
        . Do it the simple way first, and profile.
        . Do I need to clip at all?  The performer can clip to the start, but
          I think it needs to know where the note stops because otherwise this
          information isn't preserved.
          . I could do it more efficiently by just sticking an end time in the
            Score.Event, and leave it to the performer to observe.
          . Indeed NoteUtil.trim_controls only does drop_before.
          . E.g. BlockUtil_test.test_compile, final test
    - I should include the number of events in the verify profile, so I can
      compare relative event throughput per score.
      . Clearly the wayang ones are doing something expensive, what is it?
    - Criterion testing: why is cmd_derive faster than derive?  It should be
      doing more work!
    . Seq.sort_on winds up calling compare on Stack 13374153 times! 9.1% time
      I have to sort it because the stack is kept in reverse order.
      - Per-track stuff can wind up happening zillions of times due to
        inversion, so look for other places where I do work or collect data
        on every track fragment.
      - At least at one point, keeping EnvKey.seed up to date was expensive, and
        it's not even needed when there's no randomization.
      - I could analyze TrackWarp or TrackDynamic to get stats on how many times
        each block is called, along with overall stats on how many notes.  Just
        an interesting thing to know.
    understand deriver performance
      . I never know if changes I am making help or hurt performance, because I
        don't trust any of my profiles.  This means I hardly ever run them, at
        which point why bother having them?

      . Productivity is actually really good during derivation: 70-80%.  Only if
        I turn on heap profiling does it go down to 33%.  So maybe there's
        nothing to do?  Still, it seems like it's slower than it should be.

      . I want to find out how much list copying happens due to Stream being
        a list.  Perhaps I can use SCC annotations?  For transforms, I want to
        see the effect of a transform copying the whole stream so I can tell if
        making it interleave has an effect.
        . It would be nice to see how many times each cons is copied, but it
          would have to be for the output stream specifically.  How can I do
          that?  I think I would have to make my own list type, then count
          allocated cells?
      . Also, from heap profiling, the vast majority is PINNED, which is
        presumably ByteString.  But what is it then, if I'm using Text for
        events now?
    make composed transforms more efficient
      . Composed transforms have to keep the whole event stream in memory since
        they can't interleave.
      . Would it then be possible to deforest the intermediate lists?  Built-in
        deforestation won't work because of the intervening call machinery, but
        maybe I can recreate it manually.
      - First, figure out how to measure the amount of memory used by
        intermediate lists.  It might be completely trivial.
      - First, I have to detach threaded state for the actual map.  This is
        possible because I don't care about Threaded or Collect.  So modify
        Post.emap_m to map a Derive.run over every element.  Then I need to
        collect the output and turn Left into a Log... or leave it in the stream
        somehow so I can throw at the end.
      - I think the stream will then remain lazy, and I should be able to GC
        as it goes, but verify with Debug.trace.
    - I'd like to see if directly modifying Collect or a MergeList for LEvents
      could reduce garbage, so I need to get some profiling up first.
      . monad-par-extras Control.Monad.Par.AList is deprecated due to poor
        performance, what's up with that?
    - Internal.merge_collect is constantly merging in mempty, try reducing its
      use.  Can I continue to enforce monoid-nature?
    - I should be able to move samples only when converting to MIDI, this way
      I don't need to move parts of the signal that wind up being trimmed.
      Either try to trim the signal earlier again, or delay transformation to
      Perform.
    . Signal.sig_op has 4.8% alloc, from Control.cotrol_call ->
      Derive.with_relative_control -> Perform.sig_multiply
      . So default multiplication for dyn is expensive.
    - Store signal chunks in the Ui.Track so they can be directly emitted.
      This is only useful for large chunks of 'set' calls, probably recorded
      from MIDI.  So it's probably not pressing until that feature exists.
      . make Ui.Events into 'Map ScoreTime (Event | Chunk Signal)'
      . collapse chunks of adjacent 'set' calls into a Chunk
      . track_derive on a Chunk just returns the contents
      . fltk event render should detect too dense events and omit them, rely
        on the signal render
      . UI edits should see the Chunk expanded out as Events.  Inserting an
        event should modify the chunk or split it depending on if the inserted
        event is a set call or not.
    - parallelize derivation
    something more efficient than list for Derive.Stream:
      . Try Data.Sequence?
      . https://hackage.haskell.org/package/rrb-vector
      Util.AppendList
        - switch to AppendList and try to get garbage down
          Avoid copying sublists returned by block calls and cache hits
        - see if a Merge constructor can reduce copying
        - can I cache length and range in AppendList?  does it matter?
        - insert parallelism?  maybe the evaluator can do that when it sees
          Merge?
    - lazy signals
      - check out 'at' and 'bsearch' occurrances and see if they can use tails
      - There are lots of lookups in the tempo map
    - see if making a version of Derive.local that's non-monadic in the
      modifier has any effect on performance
    derive cache:
      - can I cache long blocks by slicing them if they're >n?
      - c_block should only cache if the block has > a certain number of
        events.
      - I won't rederive cached generators if they have control damage outside
        of the event range.  But there's nothing stopping a generator from
        reading ahead or behind... come up with some kind of solution for this.
    - fair amount of garbage generated by SignalBase.bsearch_above, I think
      this is because it has to box the values when it pulls them out.  But
      it's really just comparing to a Double, so I should be able to do the
      operation unboxed.  But decide about lazy signals before going nuts on
      this.  If I revert to linear search then none of this is necessary.
    - at_linear is called a lot by compose, by compose_warp, by d_warp
      can I make this more efficient?
  ghc-events:
    - GHC.RTS.Events doesn't handle unicode properly
    docs:
      . https://www.chromium.org/developers/how-tos/trace-event-profiling-tool/frame-viewer
      . https://www.chromium.org/developers/how-tos/trace-event-profiling-tool/using-frameviewer
      . http://www.well-typed.com/blog/2014/02/ghc-events-analyze/
    conclusions:
      . 10ms for mouse up + minor GC, 9ms for 'j' with no GC.
      . During derivation, I get 80ms for OutOfDate, which should normally
        be 10ms since it just sets the box color.
        . While GCs are longer than normal, there is still plenty of time with
          no GC... what is it doing?  Maybe just competing with the derive
          threads.
        . Can I put responder on its own thread, or somehow bump priority?
        . ghc-devs subject:(GHC Threads affinity)
          Might be able to pin respond to its own capability.
    Even once I do get this, what use will it be?
      . I can see if a hiccup is waiting on GC, or trying to evaluate
        something.
      . But I pretty much know it's going to be GC, because it happens
      . What would the "real" solution be?
        . Ideally a low latency or interruptible GC, but that won't happen.
        . I could put derivation in a separate process.
      . Reducing garbage would help both latency and throughput, so I could also
        try to speed up derivation.
      . It would be useful to verify that hiccups are indeed GC, and then verify
        that GC is particularly bad when lots of derivation is going on.  I may
        be wrong and it may be another too-strict field.
      . In fact it seems like they may just be thread priority.
    . ghc 8.2 puts heap profile in the eventlog so I can align heap profile
      with events: https://ghc.haskell.org/trac/ghc/ticket/11094
    + convert from by-HEC to by-thread
      . evCap is capability, which is more-or-less CPU.  But I want to track
        haskell threads, specifically the respond thread, since it may migrate
        across caps.
        . ghc-events-analyze does this.
        . I think I look for CreateThread, and then associate a HEC with the
          thread id.
      . Though I could use async events to track thread migrations.
      - Use ThreadLabel to add the name.
      - This works, but chrome doesn't combine threads, so there are too many
        short lived ones.  I should reuse thread IDs when they don't overlap.
        . Do this only for unnamed threads?
        . If there are named threads that don't overlap, I should give the
          same ID.
    + include the cmd name in the trace
      . I have msg in args, I'd need to emit cmd name as it is encountered,
        and collect them inside the respond bounds.
      . maybe use args?  Or put it in the name?
      . Use the Object feature?  No, not applicable.
    - put tracing in derive, I can put block calls in.
      . Can I make the hierarchical?  Get a flame graph kind of thing.
    - Is trace free-ish when eventlog is off?  Otherwise I could CPP it out.
    - add Object support
      . Thats all documented phases, right?
    - Think about generalizing convert_event_log so I can release it separately.
    * include GC
      . What's major vs. minor gc?
        GlobalSyncGC is involved, but I don't understand the GC events.
      ? Specifically, GCIdle should mark idle GC, but it occurs inside
        StartGC.  Shouldn't it mark the start of a GC?  And what is GCWork?
      - Mark major GCs like threadscope does.
    . JSON event format:
      https://docs.google.com/document/d/1CvAClvFfyA5R-PhYUmn5OOQtYMH4h6I0nSsKchNAySU/edit?pli=1
    old notes:
      . xi-editor, what did he use for that?
        https://www.youtube.com/watch?time_continue=12&v=4FbQre9VQLI
        . write "chrome tracing" format, chrome://tracing, then load
      . I probably need to save all cycles, and then search for ones with
        hiccups.
      . Use ghc-events, then I can get gc events too.  I guess this may turn
        into using chrome instead of threadscope, but why not?
      . http://www.yesodweb.com/blog/2012/10/future-work-warp
      . Can I use custom events to see lags in threadscope?
        . Yes, but hard to visualize with everything there.
          I can get labels with View -> Event labels, but often they are jammed
          together, and draw inconsistently.
        . What do the numbers in threadscope's green bars mean?  ThreadId?
        . What I want is for each respond cycle to see where pauses were, and
          why.  I'd want to bracket the respond cycle outside of waiting for the
          next msg, get the total duration of each one.  Possibly I can do that
          by using ghc-events to process the eventlog.
      GHC's +RTS -v flag writes eventlog to stdout
        . It's documented but doesn't exist.
        . It only exists when -debug, but this isn't documented.
        - Send doc fix to ghc.
  keep track of history save scores and timing:
    . https://gitlab.com/karya-group
    - I should have a way to commit saves on each karya commit, and keep track
      of which karya commit corresponds to which 'saves' commit.
      . This seems like submodules.
      . The thing is, I want this only for my local repo.
      . But it seems like .gitconfig can assign the submodule url locally.
        Could someone else use that to point to their own saves repo?
      . I want the commit link, but I don't want the local directory, because
        I'll use a symlink for that, so I can modify things inside.
      . Actually it's ok to use the submodule directory directly.
      . And local .git/config is no help after all, because the repo points to
        exactly one commit.
      . Since the save repo is per-user, it has to keep the local link to the
        karya repo, not the other way around.  I could do it manually by
        adding a tag with the karya commit whenever I commit the saves.
      . I can do this with a commit wrapper script:
        After each commit, check if there are diffs in save.  If so, commit save
        with the current karya HEAD hash.
    - Is it stupid to store git repos in a git repo?  What I would want is the
      unversioned repo, and then a versioned HEAD ref.
    I should have a more organized way to backup scores:
      . One way is to trigger a save-backup/backup after every patch that
        requires that score to be updated.
        . This is actually uncommon, less common than ones requiring an update
          for the the saved realization.
        . Also the backup needs the commit date, not current date.
      . Or put the saves in source control.
        . Not the same one as the source, I don't want to have tons of giant
          binary diffs.
        . So I need some way to link them... is commit date enough?
        . Other people have surely created solutions for this, e.g. git-annex.
        . This would be weird for git saves, I don't want nested source
          control!  git saves have their own history and could be rewinded
          their own.
      . Or use git saves for everything, now each score has its own history.
        . For some reason I don't really like to use git saves though.
        . If I extend the .last mechanism to make dated versions, it's
          essentially a simple homemade version.  It would be too cluttered
          if I did it on every save though, it would still need some trigger
          to notice when an incompatible change happened.
    . Ideally I have a separate set of scores that don't change other than
      compatibility updates and are just for profiling, like the old data/*.
      . In fact, maybe I should go back to that, except keep data/ in
        a separate repo.
      . The problem is I have to update twice as much stuff, but I don't need
        that many "reference" scores.

  research using pipes for generators and transformers
    . or streaming, or https://www.reddit.com/r/haskell/comments/7w79q1/what_is_your_take_on_conduits_pipes_and_streams/
    . This would handle the composed transforms thing.
    . What about parallelization?
    . What about the MergeList idea?
    . The bigger question is how do I do dynamic state when all the different
      calls are interleaved?
    . Actually now I'm thinking pipes aren't suitable for this.  Pipes are
      about interleaving effects, but derivation is pure.  But not quite,
      since it does depend on StateT.  In a pipes implementation, a generator
      would be 'P.Producer Event Deriver ()', and a transformer would take
      a Producer to another Producer.  Actually, since calls need to typecheck
      etc., it winds up being:
        type Events = Producer Event Deriver ()
        type Generator = Deriver Events
        type Transformer = Deriver (Events -> Events)
      . In a pure environment, pipes still give a constant bound on how many
        elements I hold on to at a time.  But since I look ahead arbitrarily
        much, maybe I don't want that.
    . The way to do this without pipes would be for transformer to be
      Deriver (Stream -> Stream).  Then I can run all the transformers, and
      then compose all their functions.  At that point, the only thing pipes
      would really give me is a clear picture of how many elements I need
      because each one needs to be specifically awaited... but it seems like
      the look-ahead stuff would be really inconvenient.  And I do the same
      thing, it's just less convenient with pipes.
      . It does mean I have to express all transformers purely.  This is true
        for the non-monadic Post functions, but it means I can't express ones
        where a previous monadic effect on a previous element effects a later
        one.  But that only applies to Threaded, and I can get that anyway by
        threading myself, so maybe there's no problem?
      . The way to prove that would be to remove the monadic Post.emap
        functions.
    . The reason transformers can't interleave is exceptions, and that's
      an effect, and something like pipes or streaming should be able to
      interleave that effect, which is what is needed.
      . Presumably they could also interleave the State effect, but I'd want
        to take that out.  Though of course keeping the Reader part is fine,
        and necessary.

fltk:
  * bug: solo: mute:
    . Track 'mute' status gets increasingly off.  Surely this is due to the
      bug fix in c523680838564ec55752302d1d591482971b9190 where I no longer do
      only absolute updates to the skeleton.
    . Commit is wrong :(  What was that bug fix?
    . It happens in save/bali/kebyar-duduk, e.g. mute reyong part in @b3
    . It definitely happens occasionally, but always when I'm busy.
    . It's accurately in a track, but it's on the wrong track.
    ? Are the skeleton lines also wrong?
    what happens when I hit S:
      . BlockC.set_display_track called with DisplayTrack::status, tracknum
        is from haskell.
      . Block::set_display_track calls
        skel_display.set_status(tracknum-1, dtrack.status);
      . SkeletonDisplay::set_status: tracks[tracknum].status = status;
    Possibilities:
      . haskell sends the wrong tracknum
        . Unlikely because it doesn't seem to be otherwise confused.
        . Debug by printing the tracknum it sends, and just count.
        . I can find out with ^a and look at debug output.
      . SkeletonDisplay is out of sync with the actual tracks
        . It has vector<Track> internally
        . In set_config, it has edges but not status, so it reuses previous
          status, and uses empty status if there are more widths than
          previously.
        . widths is from the block, I don't know why it wants to set them,
          because it's already keeping track incrementally in insert_track
          etc.
        . So, either keep trying to make the incremenal update work and find
          the bug where it gets out of sync, or go all-in on complete updates,
          and only have one complete update to SkeletonDisplay, which every
          change triggers.
        . Incremental update:
          . How to find where it's getting out of sync?
          . I can print internal SkeletonDisplay state, but the question is how
            did it get that way?
        . For complete update, is there a case where it doesn't have all the
          info?
          . info is: SkeletonConfig(edges), [Track(width, status)]
          . SkeletonConfig calculates track.center, .left, .height internally.
          . For this I need to store SkeletonConfig and [Status] in Block,
            or in the tracks themselves, since I need to send them on e.g.
            remove_track.
          . Isn't that the same result though?  Those can also get out of
            sync with the tracks.  Unless they are in Track, but
            SkeletonConfig is global.
          . But why is it less likely to get out of sync?  I guess it depends
            on why it's getting out of sync, which I don't know.
        . InsertTrack has a (DisplayTrack .. status)
        . In set_config, it sets edges at once, but if there are more edges
          than tracks, it assumes they were at the end and copies status
          from previous ones, seems sketchy.
        . When is set_config called?
        . Block::set_skeleton <- BlockC.set_skeleton
        . Ultimately because Status is from DisplayTrack, which is
          generated from Block.block_display_tracks while Skeleton is from
          Block.block_skeleton and integrate info.
    . SkeletonDisplay tracks
    . Undo track creation does it!
    . It does remove the Track, but doesn't recalculate offsets!
  * bug: floating input in track title gets out of place
    . cmd-L causes it
    . Block::floating_open ScoreTime pos -> TrackTile::floating_open
      ypos affected by: zoom y() title_height
    . is it y()?
    . Moving the window manually fixes it.
    . window()->y() goes from 45 to 23, -22.
    . haskell asks for 23, but titlebar of 22 puts it at 45
    . Presumably it previously would send back the actual size?
    . First resizes
        Rect(4, 45, 107, 855) -> Rect(0, 23, 107, 855)
        Rect(4, 45, 107, 855) -> Rect(0, 45, 107, 855)
      UiUpdate (vid "untitled/b1.v1") (UpdateViewResize
        (Rect {x = 0, y = 45, w = 107, h = 855})
        (Padding {left = 6, top = 55, bottom = 24}))
      UiUpdate (vid "untitled/b1.v1") (UpdateViewResize
        (Rect {x = 0, y = 23, w = 107, h = 855})
        (Padding {left = 6, top = 55, bottom = 24}))
      screen_work_area Rect(0, 23, 1440, 877) titlebar 22
    . Maybe the order is backwards?
      > Block::resize Rect(4, 45, 107, 855) -> Rect(0, 23, 107, 855)
      > Block::resize Rect(4, 45, 107, 855) -> Rect(0, 45, 107, 855)
        before Rect(0, 45, 107, 855)
        <view_resize {f='%dyn=.75' v='%dyn=.75' } Rect(0, 45, 107, 855)
      < after Rect(0, 45, 107, 855)
        before Rect(0, 23, 107, 855)
        <view_resize {f='%dyn=.75' v='%dyn=.75' } Rect(0, 23, 107, 855)
      < after Rect(0, 23, 107, 855)
    . Recursive call, how does it happen?
    . hs asks for (0, 23)
      calls Fl_Window::resize(x, y, w, h)
      which then calls back with (0, 45)
      record (0, 45)
      record (0, 23)
    . If titlebar==22, what is that 23?
      screen_work_area Rect(0, 23, 1440, 877) titlebar 22
      Cmd.gets Cmd.state_screens also has 23, probably from screen_work_area.
      . Actually menubar pixels seems to be 23
      . Then I think window title is +22.
    . Cmd.state_screens is from (UiMsg.UpdateScreenSize screen screens rect)
      msg_screen_update, indeed from Fl::screen_work_area(x, y, w, h, screen);
    . What should happen:
      . Could hs ask for (0, 45)?  It would have to know the derocated_h.
      . Or, it could ask for (0, 23), but get back a msg for (0, 45)
      ? Why does BlockWindow::resize -> Fl_Window::resize -> back again?
      . Fixing y makes it consistent, but the re-entrant call is still there.
  * remove TrackTile::set_title_height and make it constant?
  * bug: ever since the slow scrolling: change, I sometimes get a light gray
    background on track titles.
    . This is the selections getting in, if I use a blue selection then it's
      blue.
    . Am I missing a clip when drawing the selection?
    . Added a clip, hopefully fixed.
  keycaps:
    notes:
      . It could be useful to display a keyboard along with cmd for each key.
      . For cmds, it's cmd name.  For kbd entry, it's call entered (drums) or
        pitch (scales).
      . I need either a blank image of a keyboard, or to draw one myself.
      . How about I just draw it, then I can fill in the keycaps as appropriate.
      . Draw a set of rects of the given sizes, and then draw text at the given
        positions.  I should be able to configure it from haskell and then do it
        dynamically to tweak things.
      . Then draw keycaps as light gray text, maybe in the corner, with the
        binding as dark text on top.
      . If the binding is too big, how to show it?  I could use first few
        letters, and then tooltip.  Or if I don't like tooltip, then display the
        last mouseover rect with a color highlight and put text in a gutter at
        the bottom.
      . I want to change them when modifiers are held, for that I need
        a record_keys hook that sets bindings as appropriate.
    - highlight pressed key?
    - With no kbd focus and no border I still want a GUI way to close it
      . I guess I can put a red X inside or something.
      . But then Cmd.Responder needs to check if it got deleted, and remove
        PtrMap._keycaps in that case!
      . But there's no way to tell if a pointer is valid, I'd need it to
        point to intermediate storage which delete can set to null.
      . Is there a way to reuse shared_ptr / weak_ptr for this?
      . Or do the same thing as BlockWindow, which is emit an event when it
        gets closed.
  - Floating input in the wrong place for negative events with multiple lines.
    . Because it assumes the text goes downwards.
    . Since haskell doesn't know how the text is wrapped, it can't know where
      to put the input.  I think I'd want the input itself to know it's
      wrapping upwards, so it can get it right during input as well.
    . It seems like too much hassle for a cosmetic issue.
  slow scrolling:
    Get rid of the find events callback, ship over events directly.
      . I wanted to avoid having state in C++, but it's unavoidably present
        in the image on the screen.
      . The current situation replaces it entirely, so easier to use but not
        efficient?  Still, until now I used incremental replace via damage
        ranges, and it's been working ok.
      . But is copying the events actually a significant cost, even when
        only one has changed?
      . Even if it's not, replacing the callback with marshalling all events
        at once is simpler and probably faster.
      - Pass events directly, no callback.
      - Store events in the EventTrack, and just pass the updated region.
        . This is nice for zoom, which means no event change.  But the
          common editing case, just one event changes.
      . I think it can remain this way even if I do tiles, because it's
        still simpler to have the events in c++.
      . For events, is it worth interning the text?
        . That would require refcounts or an arena allocation for all the
          events.
        . It would slow down marshalling but maybe worth it due to the
          reduction of data:
          . Put each text in a HashMap to consecutive indices.
          . Then marshal as array of char*, or even just one big one with
            null separations, and replace event texts with pointers into
            that.
          . Then deallocate with a single free() when it gets replaced.
          . This will get in the way of incremental update though, so
            maybe don't bother.  Incremental update is probably a bigger
            win than making the complete update faster.
        . At least I can replace "" with a static "", or just nullptr.
    scroll with tiles:
      . Zoom is noticeably slower now.  Previously it would be ok speed when
        only displaying a subset.  I have to use tiles for this.
      . Redraws caused by waveform updates are really slow.
        . Maybe I can make the waveform stuff its own layer, which gets
          updated incrementally, and doesn't cause the whole redraw.
        . Not so slow now that I invalidate explicitly.
      . If the callback always gets all the events, I may as well just
        ship them over with the update, and never mind the callback.
        . But I still like the idea of only shipping changed regions... maybe
          I wind up with mutable events in tracks after all.
      . But isn't this just moving back to incremental, and won't I get the
        same artifacts?
    . Tracing chrome://tracing
    . I want to trace the whole event loop.  Where is the entry point?
      Fl::wait() -> run Fltk actions -> get_ui_msgs -> writeTChan
      Presumably fltk then does the draw after I go back into wait()?
    . start -> [haskell] -> haskell -> [draw] -> Block::draw -> [wait ui]
      fltk might skip [draw] and hence Block::draw.  E.g. for a cursor move.
    . Most time in draw_upper_layer 0.004, then ruler_overlay 0.002,
      then find_events 0.002.  But sometimes find_events was 0.03!  So it
      probably is a liability to scrolling.
    . draw_track is 0.005 to 0.007
      without draw_text: 0.004 to 0.007
      without wrap_text: 0.002 to 0.003
    . No, it's fl_draw that's expensive.  I'm not sure there's any way around
      that, except by optimizing scrolling.
    . Alternately, I wonder if I could draw it all in advance, and then use
      Fl_Scroll.  Or at least draw in chunks?  It would be nice to avoid
      drawing lots off off-screen stuff when zoomed in.  It means changing
      zoom levels might take a lot of time?  I also want to update
      incrementally when adding changing something.
  hiccups in haskell:
    . haskell is usually cheap, but once it was 0.72.  So that's probably
      the cause of scroll hiccups.  Haskell is running UI actions (which are
      fltk calls), and then gets ui actions and writes them to STM.  The
      latter should be cheap, unless there's a major GC.
    . If I write ghc events, maybe I can find out what haskell is doing in
      the longer gap.  But of course just visually, it gets quite clunky
      when it's deriving.
    ? Are the fltk actions fully forced by Fltk.send_action?  I guess not,
      because they're monad sequences, and could evaluate who knows what
      inside.  I could find them and make sure they're rnf'ing the data
      before it goes to Fltk.send_action.
    - Always time the haskell duration, and log when it's too long.
    - Look for possible thunks in the Fltk action, rnf them out.
  better drawing:
    see rust-gui: fancy gui:
    . All this incremental redraw stuff is fussy and seems like it should be
      unnecessary.  I should be able to lay it out and have someone else handle
      selection overlay and scrolling.
    . Or why not get rid of the callback, and just keep the complete track in
      c++, like I do with the signals.  I think I need to do that anyway for
      OpenGL, and that way I don't have to play with getting event ranges,
      I can just scan the whole range on every draw.
    Other libraries for 2d rendering:
      cairo:
        . fltk already has cairo support, try Fl_Cairo demo
        . Just make a Fl_Cairo_Window, then call
          set_draw_cb(Fl_Cairo_Window *, cairo_t *)
      skia:
        . Skia is a 2d library, like cairo, and it has a OpenGL backend.
          I guess it provides fancier features on top.  But if I don't need
          those features, then I should just use OpenGL directly.
        . On the other hand, if OS X wants to deprecate OpenGL... but then if my
          needs are simple, can I just write a Metal backend?
        . Skia doesn't include font selection, or kerning.  But it can be
          hooked up with another library:
          https://skia.org/user/tips#font-hinting
        . https://github.com/toptensoftware/RichTextKit - but I think it's C#.
      tiny-skia: rust
        . Skia is huge and complicated.
        . https://github.com/RazrFalcon/tiny-skia
      webrender:
        . Rendering engine in rust for servo.
      https://blend2d.com/
        . High performance, but immature.
        . No support for fonts?
      https://github.com/ocornut/imgui
        . Has backends for to vulkan, metal, opengl.
  ? Will using GPU rendering be harder on battery life?
  no callbacks:
    . I'll probably want complete data in c++ regardless, so I could do that
      with the current drawing setup.  I think this is actually totally
      orthogonal.
    - Each EventTrack gets a mutable vector<Event> and draws from that.
      . Convert to diffs, filter out 0s.
      . Sum times at each track, and at each TrackTile.
      . Looks like find_events is pretty cheap.  draw_upper_layer, then
        ruler_overlay.
    - Haskell copies over events instead of sending a new callback.
      . The main concern is that this will lead to a hiccup after a full
        update.  Currently a full update is cheap on the update, and then
        I only pay for visible events via the callback.
      . So the current approach should be more efficient in theory because it
        reads fewer events.  But it's probably less consistent in practice,
        because it continually rereads events from haskell, which may be off
        on a GC.  Whereas copying eagerly relies on full copy
        (BlockC.update_entire_track) being uncommon, and when it does happen,
        it's quick to copy all events.  I can still get interrupted by other
        threads, but hopefully the copying happens during the derive delay.
      Who does update_entire_track?
        . Update.BlockTrack - This is uncollapse, merge, etc.  But I think
          I don't need an update any more if I store the events by TrackId.
          But this means the EventTrack itself will have to have merged
          TrackIds.
        . Update.TrackAllEvents and Cmd.TrackAllEvents
          . Change the skeleton, may change event styles.
          . Change track title, may change event styles.
          . State.put, loading scores
          . Ui.create_track
          . Ui.modify_events - ModifyEvents, Factor, BlockResize,
            Integrate.Merge
        . Update.TrackRender - This is for adding control render, I don't
          need to update events.
        . Update.Ruler - Also no longer necessary.  Actually rulers are
          already done by copying, so maybe I should also have
          map<RulerId, ...>.  Or do I?  No, ruler marklists aren't shared by
          RulerId, which seems inefficient!
      . So I think whole track copies will be rare.  And the idea that it's
        during the derive delay is compelling.  But I should still instrument
        rendering so I can see where the time is being spent.
    - Share the events based on TrackId.
      . Since haskell will update by TrackId, I think I need a global
        map<TrackId, weak_ptr<vector<Event>>> which actually gets mutated.
      . An update will mutate the map, then call draw() on all tracks that
        refer to it.  I can either have a separate
        map<TrackId, vector<EventTrack *>> which ~EventTrack will have to
        manage, or have a public EventTrack->track_id, and a way to loop
        through all tracks.
  - Maybe I could ship over a chunk of playback data in advance, and let the
    UI interpolate playback cursors.
    . If I could keep the warp as linear segments then I just need to ship the
      segments.  NOTE [signal-discontinuity]
  - FloatingInput on linux doesn't interact well with a tiling window manager.
    The new window probably needs to be marked transient.
    . Can fltk even do this?  I can't even figure out what xprop should show
      for transient windows.
  - mini block:
    . Factoring a bit of score into a call makes it less readable because
      I can't see the events inside.
    . I could put a mini version in the background of the event.  I'd need
      to be careful to retain readability.  Maybe only show the first track,
      or the first note track.
  / reduce duplication in EventTrack.cc drawable_pixels
  - I need to differentiate DEBUG from LOG.  And LOG can go to seq.log.
    . I'd need to pass a haskell callback, so it can serialize to JSON.
  - what's going on with SeqScrollbar and FlSeqScrollbar?  Looks incomplete?
    . It still might be useful to put the top level ruler labels, or cues if
      I ever use those, but I'd have to make it wider.
  - Support set_ruler for Scrollbar?
  - Drag on an event track title doesn't work, because the new FloatingInput
    doesn't realize that a drag has started.
    . Explicitly sending it FL_PUSH doesn't seem to work, but maybe
      something similar could?
  - It gets a few extra focus/unfocus pairs before show, why?
    . I hacked around with FloatingInput::ready.
  / Also, it seems resize on a window which is a child of another window
    goes into endless recursion.  What is a child window supposed to mean
    anyway?
    . Who cares, I don't use any of those.
  - Manually fiddling with track widths is annoying.  It seems like I could
    ask the UI about text extents to resize them automatically.
  - I never wound up using rank > 1, so presumably I could simplify things by
    calling it 'bool align_right' or something.
    . I'm using EventTrack::Align, but the haskell side is still sending
      ranks.
  - When multiple marks from different marklists are in the same place, their
    text collides.  The one from the first marklist should take precedence,
    as should its line.  This is visible when I add logical range markers.
  ? There's an extra axis of information in the width of the event body.  How
    could I use that?
  - add edit and windows menu to all apps
    There must be special OS X support for these
    Apparently not?  iTerms is defined in English.lproj/MainMenu.xib
    https://developer.apple.com/library/mac/#documentation/Cocoa/Conceptual/WinPanel/Tasks/UsingWindowsMenu.html
    But it doesn't say how to add the Window menu.
  + bug: There's a focus bug, but I'm not sure how to reproduce it.
    . The focus bug is still here.  Even clicking on the "unfocused" block
      doesn't fix it.  Don't all msgs contain focus?  What can I log after the
      fact to figure out what's going on?
    . Actually this makes me think it's actually in MsgCollector.
      In that case it would be Fl::focus() which is wrong.  Is there a way to
      just ask the OS what window has focus?
    . Cmd.state_debug_ui_msgs doesn't help because I have to take off focus to
      turn it on.  I would need a key stroke that does that.
    . come up with the next step to find this
    . Last time: c0f6295365b3b1ad1df41f884c4b6a986cf2f608
    . Every msg contains the focused window, and since moving the selection in
      the same block doesn't fix the focus, it must be sending the wrong
      focus.  So I think printing msgs with state_debug_ui_msgs will not be
      helpful.
    . How does MsgCollector get the focus?  From Fl::focus().  So it must be
      out of sync with OS X focus.
    . How does Fl::focus() get it?  Can I directly ask the OS?
    . Yes, by hacking libfltk to add the function.
    . Of course fl_mac_get_key_window() is not a solution, but hopefully I can
      see it diverge.  Then what?
    . At least I want to narrow it down to a problem with how my program uses
      fltk, one with fltk itself, or that the OS is sometimes not delivering
      the notification, or doing it in a way not expected by fltk.  I think
      getting access to the "ground truth" of what the OS thinks is the key
      window is a first step for all of those.
    . Path from windowDidBecomeKey to Fl::focus():
      . Fl::handle(FL_FOCUS, w)
      . Fl::handle_ sets fl_xfocus, calls fl_fix_focus()
      . fl_fix_focus() walks up to the top
        window (presumably already there), checks if the window wants
        take_focus(), and calls Fl::focus(Fl_Window *), which will set
        Fl::focus_ unless visible_focus() is false.
      . visible_focus() is confusingly named, since it really means accept
        *any* keyboard focus, not just do so visibly, but whatever.
      . This is a pretty long convoluted path, with lots of ways to go off the
        rails, so I can't be totally sure it makes it in all cases.  There are
        also some seeming redundancies which make me confused about
        responsibility, for instance, fl_fix_focus() does "if
        (!w->take_focus()) Fl::focus(w);", but Fl_Widget::take_focus already
        does Fl::focus(this) if it's going to return 1.
      . Fl_Widget::take_focus:
        if (!takesevents()) return 0;
        if (!visible_focus()) return 0;
        if (!handle(FL_FOCUS)) return 0; // see if it wants it
        if (contains(Fl::focus())) return 1; // it called Fl::focus for us
        Fl::focus(this);
        return 1;
    . still happening:
      . fltk/Block.cc:858 FOCUS WARNING on push:(68, 565) -
        Fl::focus(): 0x7f8376969e00:'%dyn=.75'
        getKey:      0x7f8377838000:'%dyn=.75'
        lastKey:     0x7f8377838000:'%dyn=.75'
        lastMain:    0x7f8377838000:'%dyn=.75'
      . fltk/Block.cc:879 FOCUS WARNING on keydown:'a' ("a") -
        Fl::focus(): 0x7fb9e680fa00:'inst = zh | ... '
        getKey:   0x7fb9e50be000:'inst = zh | scale = just | ...'
        lastKey:  0x7fb9e50be000:'inst = zh | scale = just | ...'
        lastMain: 0x7fb9e50be000:'inst = zh | scale = just | ...'
      . What does it mean?  Fl::focus() was no fa00, but OS focus was all on
        another window.
  - I could set certain Symbols to stretch to the length of their event, this
    would yield a nicer looking score.  But it would mess up the bounds
    detection.
    + gmail: subject:(scaling text)
      But it's OSX only.
  - figure out how to have a minimal title bar in os x (win.border(0) removes
    it altogether)
    I can set something like kUtilityWindowClass in Fl_mac.cxx:Fl_X::make, but
    it doesn't get any kbd input
    . can I get fltk to omit the jellybean buttons on the window?
      . Yes, but requires hacking fltk.
      . Completely disables resizing.  Apparently this is hardcoded.
  incremental redraw / scrolling
    . I don't like the current situation of incremental redraw and scrolling.
      It's also buggy, i.e. one pixel difference between scroll and redraw.
      Get rid of damage and redraw everything every time.  Then I have to make
      it fast to fetch the data for one screenful.  What makes that slow
      currently?
    . Entirely turned it off, speed seems acceptable.
  Track
    - dividers can have separate color for upper part, for collapsable tracks
  + Disable application persistence for fltk apps:
    http://oleb.net/blog/2011/07/whats-new-for-developers-in-lion-part-1/
    http://developer.apple.com/library/mac/#documentation/General/Conceptual/MOSXAppProgrammingGuide/CoreAppDesign/CoreAppDesign.html#//apple_ref/doc/uid/TP40010543-CH3-SW26
    Can then re-enable ~/Library/Saved Application State.
    . Did the objc call, but doesn't seem to have any effect.

  control track, render signal
    - render option: solid with color gradient
    - combine multiple signals, e.g. one controls xpos, one controls color
      I could combine pitch and dyn.  This is appropriate for the note track.
      . I'm pretty sure OS X can do this, as can cairo, so I would need to
        figure out how to get direct access to that API.  I could get rid of
        the awful alpha_draw.cc hack while I'm at it.
      . Or perhaps I should just switch to OpenGL?

logview:
  - use Fl_Help_View and HTML to display text
  + Logview got some kind of file locked error, presumably trying to track
    a rotated log.
    . It happens if the write handle is still open, for some reason
      Posix.getFileStatus then gets openFile: resource busy (file is locked)
    . But I also got:
      . logview: ./log/seq.log: openFile: resource busy (file is locked)
      . Apparently not caused by log rotation.  Maybe if it checks for
        rotation at the same time a new line is written?
  - can I get the standard edit menu and copy/paste?
  - tabs are not lining up properly
  - option to wrap lines or not?
  - hide or display various attrs: date, file, function, ...

ghc-bugs:
  + ghci: often ghci will load a compiled module interpreted, why?
    . If I explicitly regenerate the .o file by deleted and rebuilding, it
      will load it.
    . Can I do verbose logging to find out why?
    . It's due to timestamp .o < timestamp .hs, probably caused by git
      checkouts.  I can fix it with touch.
    . This is because shake is using the hash.  Just passing --digest-not
      doesn't recompile everything ghc thinks should be, but maybe it's due to
      shake's database.
    . Could I have shake update output timestamps even when it determines that
      no rebuild is needed?
    . send mail to shake-build-system
  - Stale files when loading in ghci.
    . This has been around forever:
      WARNING in hptSomeThingsBelowUs
      missing module User.Elaforge.KeyLayout
      Probable cause: out-of-date interface files
    . What exactly does it mean?
    . I can also get run errors:
      WARNING in hptSomeThingsBelowUs
        missing module Solkattu.DslSollu
      Ok, 81 modules loaded.
      *Solkattu.Db D> writeHtml
      <interactive>: fatal:
          cannot find object file for module ‘Solkattu.DslSollu’
          while linking an interpreted expression
    . possible reproduction: sync to 99cfe84a2b4ff4c782ec7c550718c8d235ab5439,
      compile, sync to 99dfbbd4d45d0f593f2349f52e6643ae4f029a90, reload
  - -fdefer-type-errors is broken in 8.4:
    https://ghc.haskell.org/trac/ghc/ticket/14963
    . Maybe fixed in 8.6?

test: testing:
  - testing audio:
    https://goq2q.net/blog/tech/using-ascii-waveforms-to-test-real-time-audio-code
  - count number of tests in addition to checks within each test
  - run individual tests from shake
    . The idea is to only run tests when needed, since their dependents
      changed.  But for this to work, I have to preserve dependencies of each
      Something_test.hs, rather than lump everything into one RunTests.  But
      if I really made separate binaries, the per-binary overhead would be too
      high.  So maybe I can get shake to retain the dependencies, but
      implement as a single binary.
    . Have a rule to create a build/test-output/$test from RunTests $test.
      Get the list of all tests from RunTests --list.
    . This means test parallelism moves from RunTests to shake.  I should
      probably do this per test file rather than per test, since the process
      startup overhead is high.
  - on failure, instead of
      __-> Util/Format_test.hs:80 [test_render_full_width] ...
    print
      __-> Util.Format_test.test_render_full_width 80 ...
    So I can copy paste into run tests.  But fname:lineno is usual for editors
    to jump to that line.
  - Write a test for Ui.Diff and Ui.Sync.
    . I think the easiest way to do this is make BlockCStub record its calls,
      then have a UI simulation that interprets those.  Then I can use
      quickcheck to verify a bunch of starting and ending states.  It would
      compare the incremental output against creating the visible UI from
      scratch.
    . It seems non-trivial... but maybe worth it, seeing how complicated
      diff and sync are.
    . If I make Fltk into a typeclass I could substitute a pure State version.
      But I still can't get rid of FltkStub, because the main point is to not
      link in C++.  So as long as I'm doing that anyway, maybe I don't even
      need a typeclass, but I still have to replace the PtrMap functions so
      I don't need MonadIO.
    . Except BlockC uses IO in PtrMap.modify... but that's in BlockC, which
      relies on Fltk (IO a).  BlockCStub wouldn't need that.  So unstubbed
      Fltk is in MonadIO, stubbed one isn't.
    . But how am I supposed to record calls to BlockC without reifying the API
      into a type?  And if I do that, I don't need to do this at all, just
      have Sync return that type.
    . I guess I'm not too worried that an intervening data type will hurt
      performance.  Mostly because just one more allocation is probably not a
      big deal, but also maybe if I inline the interpretation function then
      the allocation goes away.
  / delete build/test/tmp on every test run to avoid test contamination
    . test/run_tests will clear it out, but sometimes I run them directly
    . But this is pretty much limited to expecting a file in a certain
      place, which pretty much only Perform.Im.Convert does.  Tests that
      create tmp files should use Testing.unique_tmp_dir.
  property: hedgehog: quickcheck:
    - Port quickchecks to hedgehog.
    . https://www.youtube.com/watch?v=z2ete8VZnZY&app=desktop
    . https://fsharpforfunandprofit.com/posts/property-based-testing-2/
    . John Hughes: "How To Specify It!"
    . quickcheck-state-machine
    . Hughes talk:
      https://www.youtube.com/watch?v=n4IgYrc0pes&ab_channel=Z%C3%BCrichFriendsofHaskell
      The new thing is the strategy language to construct action sequences to
      make sure it gets to a goal.
    . https://www.fpcomplete.com/blog/quickcheck-hedgehog-validity/
    cmd:
      . do + undo, undo + redo
    derive:
      . I switched back to Double for RealTime, but this means the roundoff errors
        are back.  Use quickcheck to repro them.
      + make a simple deriver that creates event and midi output skeletons
      - integrate quickcheck with generate_run_tests.py
      - assert that the reduced deriver output equals the simple deriver output
      - basic pitches: If the score was created with notes aligned to note
        starts, then every NoteOn should have the appropriate key, there should
        be no pitch bends, and "same note" should be the only reason for
        a channel split
      - basic controls: Given randomly placed control events, notes have the
        correct control curves.  Don't worry about times or midi.
      - slicing: Given some simple note transformers (tuple, place, ...),
        pitches and controls are still associated with the right notes as above.
        Don't worry about times, just that the right notes and the right
        controls.
      - block call property: a couple levels of nesting for block calls, notes
        still have the expected pitches and controls as above
      - inversion: as 'basic pitches' and 'basic controls', but controls are
        below the note tracks, results should be the same
      - stack: generate nested events, check that stack is as expected
    notes:
      . In general for RealTimes, I'd like some which are the same, some which
        are close, and some randoms.
      ? How does shrinking get associated?
        It's encoded in the test rose tree via 'shrinking'
        Run just explores the tree, which already has shrinks.  So they go into
        Property construction.
        . Testable converts to Property
          Testable (Gen a)
          Testable (Arbitrary a -> prop) does a forAllShrink
        . So I only get Arbitrary's shrink if I do a test directly on an
          Arbitrary, no forAll.  If I want to use forAll with Gens, then I also
          have to construct and pass a shrink.  The point of Arbitrary is to
          construct both that and the Gen together.
      . Arbitrary vs. manual Gen:
        I don't really want to make all RealTime -4 to 4 integral.
        But that means I lose shrink, unless I make a newtype.
      ? Also I want falsifiable msg to pretty print the failing data.  Where
        does that come from?
        . From Q.testCase, which is from counterexample calls, which
          forAllShrink does with show.  So while I can add, I can't replace it
          without using my own forAll.
    hedgehog:
      . http://teh.id.au/posts/2017/04/23/property-testing-with-hedgehog/
      . Hedgehog lets me use Gen more easily, since it automatically infers
        shrink, and keeps it with the Gen.
      . But no classify/coverage?
        . https://github.com/hedgehogqa/haskell-hedgehog/issues/127
        . https://hackage.haskell.org/package/tasty-hedgehog-coverage

debugging:
  - Can I have a way to display inferred things about notes, such as reyong
    hand, and damping status?  I could integrate it back into a score but
    with text on the notes, sort of like a visual log.

midi record:
  - implement
  . Ideas for editing recorded MIDI:
    . control: realign attacks, smooth or sharpen attacks.
    . pitch: retune intervals, fix wrong note or add notes, change portamento
      speed.  Add, widen, or narrow vibrato.

REPL: repl:
  - get ghci API to load .o files, specifically vector.cc.o
    . Linux links .o files eagerly, so any dependency on e.g. Audio
      will fail with:
      . compile error: seq: panic! (the 'impossible' happened)
        (GHC version 8.10.3:
        Loading temp shared object failed:
        /run/user/1000/ghc4892_0/libghc_74.so: undefined symbol: mix_vectors
    . ghci will load vectorc.cc.o, but ghc API won't.  If I try to force with
      libvectorc.a, it says "Loading static libraries is not supported in this
      configuration."
  - enable :doc, like in ghci
    . This in turn requires some special setup, see -haddock flag.
  - :browse to look in modules... can I use GHC.getBindings for this?
    . Show names, types, and docs.
    . Tab completion already does this, but just for names.
    . It uses GHC.getRdrNamesInScope
  - use ghc package:
    . I could probably the repl more robust by putting most things in a package
    . Pier.Build.Components.buildLibraryFromDesc
    . ghc
        [ "-this-unit-id", display pkg
        , "-hidir", hiDir
        , "-hisuf", "dyn_hi"
        , "-osuf", "dyn_o"
        , "-odir", oDir
        , "-shared", "-dynamic"
        , "-o", dynLibFile
        ]
    . for dynlib:
      /usr/local/bin/ghc-pkg init dist/package.conf.inplace
      /usr/local/bin/ghc -shared -dynamic '-dynload deploy'
        -optl-Wl,-rpath,/usr/local/lib/ghc-8.4.1/array-0.5.2.0
        ...
        -optl-Wl,-rpath,/Users/elaforge/.cabal/lib/x86_64-osx-ghc-8.4.1
        -this-unit-id fast-tags-1.4.2-EKWV1xgHS3F5IyzUV7QwVY
        -hide-all-packages -no-auto-link-packages
        -package-db dist/package.conf.inplace
        -package-id base-4.11.0.0
        ...
        dist/build/Control/Monad/EitherK.dyn_o
        ...
        -o dist/build/libHSfast-tags-1.4.2-EKWV1xgHS3F5IyzUV7QwVY-ghc8.4.1.dylib
      /usr/local/bin/ghc-pkg recache '--package-db=dist/package.conf.inplace'
      . -this-unit-id - unique package name for type equality and linker symbols
      . For the packagedb I need a cabal file with export modules etc.  Cabal
        does ghc-pkg init, and then recache, but I can't see where it adds the
        package .conf.  Unless ghc itself adds that?
    . for static lib:
      /usr/bin/ar -r -s
        dist/build/objs-39495/libHSfast-tags-1.4.2-EKWV1xgHS3F5IyzUV7QwVY.a
        dist/build/Control/Monad/EitherK.o dist/build/FastTags/Tag.o
        ...
    . Have to figure out how to cabal does the linking.
    . https://github.com/judah/pier implements its own compile.
      Probably in Pier.Build.Components
    . This might also help with the memory problem, check memory use before
      and after.
  - sometimes vim fails even though the app is open:
    App/Repl.hs:274 - non-zero exit code from
      [ "vi", "-c", "source vim-functions.vim", "-c", "source ky-syntax.vim"
      , "-c", "nmap gz :call Send('LState.set_ky %s')<cr>", "+0"
      , "repl-NDpIUn"
      ]: 1
  - vim should abort the changes if I quit with :q instead of ZZ
    . But I don't necessarily want to lose the changes.  Maybe I can save the
      repl-???? tmp file in that case.
  - :h should put the selected cmd into the history
  - something like :h where I can edit a single line
    . Maybe a control key, so I can edit the contents of the current line.
  - It would still be useful to save a single unified history.  Then use
    something like :h to search it.
  - on load kbd focus is somehow not on the root block, even though it looks
    like it.
    . Is it due to keycaps?
    . Save has a Cmd.focus, which does lead to BringToFront.
    . This is probably fltk level, since OS X thinks the block has focus.
  - Now that save file is a poll instead of being pushed, it takes a return
    to notice a change.  Can I restore the notification thing?  Or maybe it's
    enough to make sure I write the history to the new name?
    . I can use ReplProtocol.NotifyRepl
  - I don't really use ReplStub, can I get rid of the awkward #ifdef then?
  - only write history when the cmd succeeded
  - command to open the haddock for a module
  - is Cmd.Lang.Fast now obsolete?
  - can I get local variable bindings (let x = ...; y <- ...) to work in the
    REPL?
  - :compile cmd that turns on compilation for everything except Environ
  - :module cmd to move evaluation context to a certain module, maybe I
    could also get rid of the need for Cmd.Lang.Environ to import everything.

solkattu:
  notation conveniences:
    / mark karvai groups automatically?  I don't have to highlight it.
      . If I'm not going to highlight, why bother?
    / Then I can make tri like r3, but groups the sequence, as does tri_.
      . Find existing uses and delete group, or ensure group make sense.
      . Only apply group if it's not already a group (or pattern or whatever).
      . Should repeat also group?
  - replace is useful to express variations
    . e.g. Mridangam2019.c_19_06_24_a
    . This can perhaps solve "reduction with irregular bits" and
      "replacements" below.
  search:
    . create an event with a duration and solkattu
    . e.g. tat_taka takadinna nakadit_talang_ga
    . This turns into a search for phrases with that duration (or power
      multiple), and those solkattu.  If there are >1, I can pick any one.
    . With a library of phrases, and small fragments, I should be able to
      write percussion parts quickly.
    . Still the problem of long text for events remains.  Maybe I can open vi
      for individual events?
  - can I highlight karvais?  I guess I have to infer when they are, e.g.
    tri_ can put the group on, or join, though maybe it should be called
    karvai to emphasize that.
    . Or maybe it's enough that the non-karvai is highlighted.
  David Nelson mridangam transcriptions:
    . http://www.ancient-future.com/atfp.html#MIDI
    . http://dpnelson.web.wesleyan.edu/publications.html
    . http://dpnelson.web.wesleyan.edu/mridangam.html
    . $38 for pdf only, but no dvd
    . For ordering information, please send email to dpnelson@wesleyan.edu.
  transcribe:
    - lots of korvais in Solkattu2013 are not really from that time, just
      undated
    - after 2014-06-17
    - complete Mridangam2013.dinnagina_sequence, maybe move to solkattu.
  practice: Solkattu.Practice:
    I can't say I practiced a tani:
      . I could get rid of Part by putting korvais inside other korvais.
      . Then the sections lose their identity.  But if I keep the index with
        the section, they keep the correct numbers.
      . But it doesn't work with solkattu, because I only have one StrokeMap
        per Korvai.
        . I could put StrokeMap per section, but the usual 'korvai'
          constructor just gives the same one to all of them.
        . I suppose this could be useful in general, though rarely.
        . This is inappropriate for lint, because lint has to be global,
          because I don't scope strokes to their sections, because that would
          be too much work.
        . But most of all, it doesn't seem right to put StrokeMaps in every
          section, when I only ever use that for tanis, which have pretty
          non-overlapping uses.  Except of course realizing them, and going
          into All so I can put them in the practice db.
        . I'd have more motivation if I had a use for per-section StrokeMaps,
          but even if I did, I think I'd want to merge them with a global one.
        . Is there a way to share the printing and All, without moving
          StrokeMaps?
        . It's also nice to have tanis show up in the db, e.g. html output,
          with the "tani" type.
        . I could have a whole new Korvai constructor?  I want metadata...
          well, maybe not, maybe just Location.
        . This means that everything that deals with Korvai now has to deal
          with the other constructor.  The other approach didn't because there
          were already multiple sections.
      . I still want name and location for tani parts.  Ultimately I can't get
        this though because it's an expression, not even guaranteed to have
        a toplevel Korvai.  I'd have to replace with an address, or search for
        matching Korvai.Single in the same module.
      . At least put in date as the max of the Part dates.
    - remember what I did last time, and do spaced repetition
      . https://en.wikipedia.org/wiki/SuperMemo#Description_of_SM-2_algorithm
      . https://mochi.cards/
      . This isn't memorization, just randomization with coverage.  So it's
        enough to pick random but twice as likely to pick with score one
        lower.
  technique:
    - o with space can become od.
      . I guess I would want to tag a stroke, and technique postproc can then
        apply it if appropriate.
    - I should be able to configure per-korvai technique
      . For irregular reductions, e.g. Solkattu2018.misra_muktayi1
      . Or just general purpose post-processing.
    - kook kook -> kook nook, or kook took
    - kt_ kn_ ko_ ok_ D -> kt_pkn_pko_ook_oD
      . This is a general fill-in gaps thing, e.g. it could work in tisram to
        k__t__k__n__o__ -> k_pt_pk_pn_ko_o
      . The general rule is before a rh stroke we get p, before lh get k.
        Except if o then follow with o unless it's p.
    - fillers for karvai:
      . tang.__.gu -> tang.oknp
      . din.__3.tat.__3.din.__3 -> din.din.__.tat.tat.__.din.din.__
        4: din.__.din.__ etc., 5: din.__.din.__3 etc.
      . tk, tktu - these fill 1 and 2 respectively
  inline mridangam:
    . Transcribing ad-hoc things and sarvalaghu mixed with korvai is awkward.
    . Maybe I could inject strokes in directly to solkattu, but it would only
      work for one instrument of course.
    . If I really want it for another instrument, I would want to write it out
      individually, and in the stroke map is still the best place.
    - So maybe what I want is a generic named "pattern" which is matched in
      the stroke map.  I don't want to make up some sollus for it.
    - Then if the instrument doesn't have it, I could render with
      placeholders.
      . In fact, why not do placeholders for all unmatched strokes?  That would
        make it no longer fatal, and also render everything that can be.
      . However, I'd want inline strokes without a match to be nonfatal for
        tests, while a normal non-match is still fatal for tests.
  - Duration is supposedly absolute, but it only works at the top level.
    So it's awkward when everything is in tisram, I do 'map (nadai 6)' and now
    sarvaD is wrong.
    . One way is to store as Duration, and then do a Duration normalization
      step.  This would work for sarvaM which stores its duration directly.
    . I guess restD could do that too.
    . (==>) wouldn't work though, because I need to drop a certain amount of
      the space, and if I have to normalize Duration I'd have to wait until
      after that to do it.
    . As opposed to a postprocess step, I could have the current tempo in the
      environment, which means SequenceT would become a ReaderT, where the
      monoid instance runs and combines results.  As long as it's a monad,
      I could also replace the IO exceptions.  The downside is that all that
      stuff becomes monadic... but how bad is that really?
    . I could probably write a Show instance that runs with the default tempo.
    . I could do the section metadata anywhere thing by putting WriterT, or
      if I don't want children to see it, maybe make it a
      (Metadata, SequenceT sollu) and put Monoid on that.
    . newtype SequenceT sollu =
        ExceptT Error (ReaderT Tempo Identity) [S.Note Group sollu]
  sections:
    - if I have 'section' get CallStack and put section on each element,
      then I can tag sections with line numbers.
      . This won't work with 'map section', and I want to get rid of noisy
        section annotations anyway.
      . But I don't think I can do that with 'map section', maybe have the
        usual 'x2' 'devel' etc. be overloaded on ToSection.
      . This may require SequenceT to be a newtype instead of type synonym.
  format: output:
    html:
      - link to source
      - Offset rests make empty cells like <td><b> </b></td><td colspan=7> </td>
        . It looks fine but seems messy.
      - color abstracted groups too
      - start <hr> right next to the text, instead of in the next cell
        . <hr> wants to go below text, can I get it to go to the right of the
          next, or have another way to draw a horizontal line?
        . Also when the sym text is long it overlaps.
      - sarva double dots are pretty ugly, how about single dots?
        . And can I stop them from clumping together at the breaks?
      - rests could be wider, since I have more space
        . But just doubling them leads to an ugly gap in between.  How can I
          emit a long underscore or double underscore?
      - Decrease font size for higher speed.
      - For high speed split avartanam.
      - I shoud be able to display nested groups.
      / use JS to switch between konnakol and mridangam
      db ideas:
        - similar_to should be a link
        / source should be a link, click on it to see everything from that
          source
          . Nah, sorting is good enough.
      - Can I align by structure?
        . E.g. reductions or tri would line up vertically.
    terminal:
      - Ruler dispaly is still buggy!  Final ruler doesn't redisplay if the
        last line is short and changed the spacing.
      - The warning carat only lines up if there is only one line.
        . Otherwise I have to divMod i by strokes per line, and use that to
          insert in the formatted output
      - Why does there seem to be an additional realize after printing the
        output?  Debug in realize fires again before "unmatched:".
  What would a web UI look like?
    . Have a field for the where block, a field for mridangam (or other)
      strokes, and korvai fields.  Separate entry for name and tags.
    . Enter sends it off, where it gets interpreted, and mridangam and
      konnakol realization appear next to it.  There are probably examples out
      there for semi-securely evaluating haskell, but even without them
      I think it may be hard to do evil things if you can't import modules,
      and I should be able to run as nobody anyway.  The main thing is
      noticing and killing a loop.  There should be haskell execution code
      in the IRC bot or evaluate expression web page thing.
    . The DB goes in a separate repo, which is edited and synced from the web
      UI.
    . To render sounds, use Solkattu.Play.
  . Solkattu2017.c_17_07_13 is showing the difficulty of the
    (solkattu, stroke_map) approach, because there are too many meanings
    for taka and din.  Really if it's meant to be useful for different
    realizations, I should emphasize the reusable phrases, so I should
    try to figure out ways to make that easier.  For instance, understanding
    about reduction is good for that.
    . To an extent, it's acceptable that it's harder than just writing
      the strokes, because I'm trying to find a more general
      representation.
    . Still, I could make it easier with tools, see StrokeMap:
  - Some strokes change realization based on the tempo, e.g. 'od' when
    slow to 'o' when fast.  I could add a stroke attribute for that, or
    I could try to do a global instrument realization heuristic.
    . Not just individual strokes, but a whole section can change, e.g.
      okookook -> nakatiku.  This implies just a realization heuristic
      won't be enough, though maybe I want it anyway for things like
      dynamics.
  karya integration:
    - I could emit groups as blocks with clip or Clip.
      . But then I lose technique.
      . Unless I also implement that in karya, I'd need a mridangam-specific
        clip and Clip.
    - LSol.insert_* doesn't clear and replace existing notes
  sarvalaghu:
    - automatic sarvalaghu variation
      . In Mridangam2018.e_323s, all of the 3 and 2 groups are mix and match,
        and the order is also mix and match.  There should be some way to
        generate sarvalaghu variations, where I can use these to either come up
        with material, or restrict the pattern to 323 or something but allow the
        specific patterns to vary automatically.
    . Fill it in based on position in the tala.
    . Sometimes there's a final note, e.g. D that replaces the first 1.5
      aksharas.  I don't have a way to notate it.  Maybe a sequence
      needs a separate final stroke, which is played when leading back
      to sarva.
  ? Some patterns are end-weighted, e.g. thom in sarvalaghu.
    . I can just add a rest to the beginning, but I still need to
      take duration from the previous note, e.g.
        d.d.n.n . su (n.d) .d.n.n
      should be ' d d n nnd d n n'

  unify patterns and groups:
    notes:
      . Groups have an optional name and highlight :: Bool.
      . Then a realizeByDefault :: Bool, which says if realizePatterns :: Bool
        will replace it.  Otherwise it can use name or "p" <> matras.
      . In this way, everything is a group of some duration.  Groups may have
        an explicit realization, which will be sollus, or be implicit, in
        which case they can be filled in generically as with Patterns.  They
        can have a name, which can inform the realization, e.g. difference
        between p4 and nakatiku.
      . realizePatterns becomes realizeGroups, and it can take a predicate.
        So I can say realize only certain explicit groups, or don't realize
        any for a fully abstract view.  I can tag "taka/takatiku" as "filler"
        groups, which can be rendered differently.
      . As currently, even after realization (or not), group boundaries are
        retained, to highlight or not in the realization.  The group can have
        some metadata about this.
      why do this?
        . show non-Patterns as abstract durations
        . generalize nakatiku etc. to just a named group
        . put Pattern realizations in StrokeMap
        . But I don't like how I wind up with redundant
          Group (Pattern dur) [Pattern dur].  Why not treat the pattern as
          a group?
        . Well, if I turn nakatiku into a named group, I need some place to
          attach the name.  In that case, why not Pattern Name Matras?
    / support tags on patterns, e.g. (2^p5, [something else])
  - Mark for variations, e.g. mark a 'tri_ x 345' for 345.x.345.x.3333.
    end4 (tri_ x (p6, tk.p6, tknk.p6)) -> can play final as p6.p6.p6.p6
    . Variation markers put a branch in the realization, so now I have
      multiple realizations, and I need some way to not just enumerate
      them, but choose a certain path.
    . This is also part of the intensity pattern, where the final repeat
      may have an alternate more intense realization.
  - I should be able to add multiple realizations of the same
    instrument, keyed by string, e.g. for different mridangists realizations.
  pakhawaj:
    - integrate pakhawaj bols
      . I think I need "kre" support.
      . The other thing is tette infer.
    - Copy the stuff from Derive.C.India.PakhawajScore.
  instruments:
    konnakol:
      - alternate ways to say nakatiku tarikita, e.g. dikutari kitataka
    reyong:
      - some way to select between melodic and rythmic realization, and
        transposition for melodic
        . This could be the same as the emphasis mechanism, if I extend
          it to attach Attributes.
        . Or if I have alternate StrokeMaps by name, then I can use that.
  - Emphasis or automatic variant versions of patterns, e.g.
    . kt_kno -> ki_kno.  k_t_kno -> i_i_kno, i _ i _ ktkto _,
      pu_ pu_ ktkto
    . The emphasis note can be i, or pu, or maybe u, or p+u (play like
      kre on pakhawaj).
    . Generally ktkno -> kikno when there is a longer time on nam.
  - Mridangam patterns can vary by intensity in addition to duration and
    family. How can I represent and realize that?  E.g. the final of
    a group of three can be higher intensity.
    . E.g. k_t_kno -> i_i_ktkto
    . It can also be a variant pattern, e.g.
      k_kto k_k_kto k_t_k_kto -> repeat 4 k_kto

    . If I have patterns with duration and can also put strokes inside, then
      I can represent as 777 777 777, but put a special rule for the last 7s.
    . Have a high level structure, and then it can be realized automatically,
      but there are also overlays, e.g. like integration.
    . But if I keep it abstract, like 777 777 intense(777), then I can write
      rules for other instruments, or more quickly generate patterns.
    . I have a 'mid' tag, why not an 'intense' or 'final' tag?
      I can put the tag in the score, and then realization can do things
      based on that tag.
    . But for those variations to actually be in the rendered output, I need
      to have pattern realization in the score.
  - replacements, e.g. takita -> nang.kttk
    . use this in koraippu_janahan
  / I think I need an absolute SetSpeed, so I can pad a number of
    aksharas, regardless of the speed.
    . I also need it to rest by Duration, or to turn that into matras.
    . At the score level it's most convenient to work with sollu-matras.
      These are relative to nadai, but that's actually good.  With speed
      changes I can get fractional matras, and operations can actually
      work as long as the speeds line up and I don't have to drop
      half of a sollu.
    . However, for things like 'align', I need to know that tala and
      nadai, so I can emit a certain number of aksharas.
    . Actually since align is used at the top level, I can assume s0.
  - extend Karvai to take a minimum number of Rests before it applies.
    Default to 2, but a chapu might require 3.
  variation:
    - 345 x 345 x 345 can be transformed to 345 x 345 x 3333, or generally
      any arithmetic progression.
    . This is automatic derivation of variations.
      transformations:
        . karvai u u u -> u i u
        . X X X -> gap X, gap-1 kpX, gap-2 kpnpX
        . X X X -> gap X, gap-2 oktpX, gap-4 ktktoktpX
        . alternate realization for 3rd repeat: 345 345 3333
        . __3 -> __2.p or __2.o if o follows
        . variation for a phrase prefix, usually on its repeat:
          k_k -> kpk, or k_p -> kpt
        . stroke substitution in a transformation, e.g. reduce or expand:
          pk -> kk, e.g. k_kto, k_k_kto, k_t_k_kto.
      . If I can apply them as a postproc, then I can get even random
        variations.
      . Or maybe I should write them explicitly, but make them easier to
        write?
    - Higher level variation, e.g. 666 666 666 -> 555 666 777 or even
      777 777 777 -> 567 876 789.  Actually the latter seems not so
      interesting.
    - Repeat oriented variation, e.g. 3 5 33 5 333 -> 333 5 33 5 3
  - Implement PatternFamilies so I can have 6 8 6 7 6 5, or even just
    distinct realizations within a single korvai.
  - Should I change mridangam notes to be consistent with Solkattu.Dsl?
    I have to put thoppi on the left, for 'od' instead of the keyword
    'do'.  And I have to change tha to p instead of +.
  . Conditional derivation that depends on position in the tala, e.g.
    thali / khali.
  alternate realization
    - kendang pasangan
    - kajar
    - gangsa
  ? Crazy idea: it might be nice to use underline or double underline
    for faster.  Is there a way I could get the editor to display
    special brackets as underline, and then turn those special brackets
    into a 'faster' call?  I think if I'm doing this, I definitely need
    a preprocessor, though if I keep basic haskell syntax and define it
    as a translation to haskell, then I can keep all the usual features.
    . Alternately, use syntax highlighting.  Sufficiently fancy
      highlighting could highlight 'faster (...)'.  I don't think ascii
      can do double underlines, though it could do italic+underline or
      something.
    . I could also try to automatically align by time.  I imagine
      a sufficiently advanced vim macro could do that, e.g. bind ^tab to
      annotate the current expression with line info, evaluate it, and
      align the current line, or try to move the cursor to the next
      beat.  Maybe not worth it though, since the whole idea of the dsl
      is that time can be abstract.

Cmd:
  Repl:
    - LNote.sort_on_pitch is still not right.
      . With multiple chords I get stacked up extra tracks.
      . Turns out this seems really complicated.  Do I really care that much?
  - Paste between blocks with different track layout is awkward.  Can I have
    a note-oriented paste that reuses or creates the track structure?
  - ModifyNotes doesn't seem to understand about parent note tracks.
  - Interpret a midi file with keyswitches back to the attrs.
    . This is so I can load VSL examples and learn from them.
    . Should it be a score transformation, or start from the parsed MIDI?
    . MIDI seems easier because it's already in a linear format, while for
      the score I'd have to interpret it into one.
    . But then I need to pass the instrument mapping to Midi.load.
    . Maybe not really worth it?  For learning I can load in reaper and just
      watch the VSL UI.
    . But still worth keeping existing work, because I'll need something like
      that for MIDI record.
  - Figure out exactly what bad things could happen because of the
    Ui.fltk_event_loop race.  Also figure out what kind of cancelling I'd need
    to fix them.
  - Write a fancy tile like ViewConfig.horizontal_tile but guesses if you mean
    to tile vertically.
    . I have notes in ViewConfig.auto_tile, but it turns out this is hard.
  - Create tempo by "stretching", i.e. select start and end, and create tempo
    mark that will cause the start point to be played where the end point used
    to be played.
  - give Cmd.ModifyEvents.Track the ability to change the track title?
    Cmd.Repl.LPitch.change_scale and to_relative could use this.
  meter / timestep
    - timestep 64*2 skips two 's', because 's' is the minimum match
      skip should be ignored when the match is a larger rank than exists, or
      maybe step should fail.

  ruler:
    - meter type and the construction functions should be integrated more
      tightly
    - LRuler.inject, opposite of extract, replaces sub-block rulers
  Cmd.Edit:
    - move events limit:
      . Can I have ^j and ^k only move events up to a limit?  How do I set the
        limit?
      . Here's a use for multiple selections.
      . If there's a secondary selection, it should disappear somewhat
        automatically, so I don't get confused by it still being around.
      . Maybe I can get space to do that?
      . Or I could set it to a timestep, e.g. one measure.  Then it would turn
        into move within measure.
      . If I stop clipping events at the end of a block, it's not so annoying to
        move everything, as long as I move it back.  I guess it's still kind of
        annoying though.
      ? Is move_event_forward / backward with a selection enough?
    - Make Edit.cmd_invert_orientation set orientation based on the first
      selected event, so I can easily set all to the same.
    - alternate finale-like note entry: hold down step key to set step and
      turn on edit mode, but only while the key is down
      (merge will clip them to the next event)
  copy / paste / Clip
    - clip block should use the ruler, just to make it easier to look at
    - clip could also copy over the skeleton
      It could use it to make sure the paste is compatible, but that might
      be more of an annoyance than a convenience.

  Undo:
    - Suppressed undo for val edit is surprising since I tend to do a lot of
      edits without leaving val edit.  Maybe don't do it for pitch val edit.
      Try going back to using the name to suppress, but ignore cmds with no
      name.
    - Add a "revert within selection" that searches backward for the last
      change within the selection.
    - Along those lines, should each block have its own independent history?
      This is supported naturally by the git layout since each block has its own
      file.  Wait, actually it's track, and that would be awkward if I undo one
      block and it changes tracks on another.  How do a say what position
      a block is in the history in that case?
      . One appealing thing is that I don't necessarily want things like config
        changes to be included in undo.
    - Visual display of undo history, because stepping back one-by-one is
      a bit of a hassle.

Derive:
  random:
    . https://alexey.kuleshevi.ch/blog/2019/12/21/random-benchmarks/
    . randomR goes through Integer, so it's slow
    . I use mersenne-random-pure64, which is ok for speed, but not splittable.
    . splitmix is fastest, but use Word64
      https://hackage.haskell.org/package/splitmix
      I don't use splitting, but it seems like I might.  It's unlikely that
      random performance is significant for my use though.
    . I don't use the Random typeclass though, so I don't go through Integer.
    . Many distriutions at:
      https://hackage.haskell.org/package/random-fu
      https://hackage.haskell.org/package/statistics
      This is probably all total overkill though, I just want something like
      a normal distribution, but bounded and cheap to calculate.
    fancier randomization
      . How much a note differs depends on its neighbors, so it's not an even
        distribution.  Use brownian noise, or a fractal subdivision scheme.
        But it's also constrained in how far it can wander from the base
        value.  Regardless, I think this means I need history, so it can't be
        a stateless control function.
      . Divide on instrument and hand, so each part gets its own individuality.
      - randomization should be centered on a value, with variance as a signal,
        so I can turn accuracy up or down.
      - Randomness could have some hysteresis, so I can e.g. reduce omit chance,
        but not get isolated notes.  At the extreme setting, it means it turns
        on in a slightly random spot, but stays on after that.
        . Is there a simpler way to get this effect?
  - A block with logical range called at time 0 gets messed up.
  idiom
    - In string-idiom, the end of the attack curve always coincides with the
      start of the next note.  There also could be an attack prepare time,
      analogous to the release delay.
  sekaran
    How to apply sekaran?
      . >hang -> sekar abab -> notes
      . I want to change the pattern, so the problem is how to set an env
        var for a range on one track?
      . I can add a 'sekar-pattern = abc', but I need to repeat it whenever
        there is a gap.
  tracklang: TrackLang:
    - It seems there's no way to explicitly pass Nothing if the default is
      Just, because _ turns into set the default.
      . Ultimately I think because VNotGiven is special-cased in Derive.Sig.  I
        would need some way to distinguish between "give me the default" and
        "pass Nothing".
      . I could change the default to "pass Nothing" by having Sig check the
        type against VNotGiven and only default if it fails.  But of course
        now there is no way to indicate "use the default" for a Maybe argument.
        This might be more likely to be what I want, but it's inconsistent in
        that the type of the arg influences the process and nothing else does
        that.
      . Meanwhile, there's never a point to defaulting to (Just x) instead of x.
    - Keyword args.
      . A problem with environ defaulted args is that if I do e.g.
        'merge=add | a=b | block', then all of 'block' will have merge=add.
        There's no way to set it just for 'a=b'.  So they're not necessarily
        a great substitute for keyword args.  Also keyword args should
        complain if you give one it doesn't understand.
      . I think a=b syntax is available, but do I want to make a Val out of it?
        It would be resolved by Derive.Sig, and not actually make it to calls,
        but Quoted is like that too.
      . And realistically it seems really invasive to support a=b if it's not
        a Val.  But I wind up with weird things like a=b=c.
    generalize sub-event calls
      - Generalize sub-event calls so that they can also take block names.  This
        is just another way to write sub-tracks, perhaps more convenient if
        I want them to be independent.
      - Also generalize them so if I put it as a transformer in a track title,
        the track is treated like a sub-event call.  This way I can apply a
        transformation to the whole track without needing to wrap it with an
        event.  Paired with the Sub.modify_notes macro feature, I can have
        a track with its own little language, e.g. pakhawaj bols.
        . Could do this by making 'ctx_sub_tracks' available in the track title
          call.
        . I think there were calls in Prelude.Lily that would be interested in
          a more defined distinction between track and note level transformers.
      - Could also do a block-level thing.
    - Perhaps I should have a separation between "" as called by Util.note by
      other calls, and "" as called from the track.  The problem is that it
      applies Flags.can_cancel at TrackTime 0, which is only appropriate for
      a direct call from the track.  This is the reason for
      Gangsa.realize_notes.remove.
      . Flags.can_cancel is now obsolete, but maybe the issue still stands?
    - I was confused because I wrote '%just-base = (nn (c3))' instead of
      '%just-base = (hz (nn c3))'.  Can I use type tags to catch that sort of
      thing?
      . Hz doesn't have its own type, so it winds up being Untyped.  But any
        type can coerce to Untyped, so it can't complain if you passed NN.
        I could make Typecheck Double require Untyped, but that would break all
        the stuff that doesn't care about types.
      . Ultimately, this is because pitches take a PitchConfig, which takes
        ControlValMap, which is untyped.  I started a branch making it typed,
        but eventually lost interest since it seemed overly complicated.
    - Rethink if I really want track event calls in TrackTime, rather than
      normalized time.
      . Implementing c_sequence I was confused how stretch was applied twice,
        since Eval.eval_quoted doesn't normalize the event duration.  Same
        problem is in Gamakam2.  It's error prone that you can place the note
        via both Derive.place and via the Derive.info_event.
      . On the other hand, working in TrackTime is convenient, e.g. in gangsa
        norot I can place notes based on the passed-in dur.  If it were
        normalized, I'd have to unwarp back to TrackTime... can I even do that?
      . Details are also in "Derive.EvalTrack".
      . Adding the repeat call was unintuitive because deriver placement is
        unintuitive.
        . Ideally I could just say (0, 2), (2, 2) and it would work.
          Instead, I get (0, 8) and (2, 8)
          This is because the block isn't normalized, so stretch by 2 makes it
          4, then the stretch by 2 for the event goes to 8.
        . This is so that just 'deriver' by itself gets it right.  If I instead
          made deriver always normalized, then the above would work, but
          I would have to do 'Derive.place (Args.start args) (Args.duration
          args) deriver' to avoid it always showing up at 0-1.  And actually,
          I couldn't do that from a transformer, because what about the next
          transformer?  I should instead have each transformer be in
          normalized time.  'repeat' becomes
            [Derive.place start (1/times) | start <- Seq.range_ 0 (1/times)]
        . For blocks, it's actually almost that, except I have to translate
          back by the start time first.  This is because blocks are already
          normalized to the event duration.  I think?
    Typecheck coerces to TypedFunction as a common signal type
      - It turns out this is not so useful because a default TypedFunction
        doesn't have a default control name like a Sig.typed_control does.
        The documentation is also worse.  The way to fix this would be to
        let the default be any coercible type.  But to do that and be type safe
        I'd want a separate class for pairs of types that can definitely be
        converted.
        . Possibly a way around is to include ControlFunction in ControlRef...
          but why do I want so much to pass control functions?  Especially since
          I can already pass a concrete signal as a ControlSignal.
    . It would be nice to be able to have an arg default to ControlRef and
      have typecheck coerce to scalar via Call.control_at.  But once again the
      problem is that I can't coerce to a type different from the default.
    - if I had a boolean type, I could generalize calls in Conditional:
      . when-e key -> when (env key)
        when-e key val -> when (= (env key) val)
      . when-c 1 cont -> when (= %cont 1)
      . if-c< cont 1 a b -> cond (< %cont 1) a b
      . However, they get more wordy, so maybe I don't want it.  E.g. for
        cond I'd actually want a 'switch %cont' and then I need either
        partially applied functions, or just write 'switch<'.
    - replace VAttributes with a general purpose VSet.
      . No users though?
    - there should be a character that triggers a parse failure, which is used
      by invalid ShowVal instances like ShowVal Pitch
    - it's confusing how some calls expect env vals like 'x = 1' and some
      expect controls like '%x = 1'.
      . The obvious way to solve this would be to merge env vals and controls,
        but that's a big change.
    - Track caching is too fragile, if I add a track with scope over everything
      then I get no caching.  Instead I should cache the bottom note track, or
      perhaps every note track.  But that doesn't work because they're all
      sliced up.
  Derive.Sig:
    - Support pairs, e.g. a list of pairs of arguments.
      . many_pairs :: (Typecheck a, Typecheck b) => Text -> Parser [(a, b)]
      . Can I generalize to triplets etc. without a separate function for
        each?  Also, could I reuse many / many1?
      . Can I have a Typecheck instance for (,)?  No, becaues it comes from
        a single Val.
      . I would have to turn Sig into a real parser.
    - Try writing a new Typecheck / Sig which is a real parser.  It can have
      backtracking and nested parsers.
    - if I add an Alternative instance to Sig.Parser I can write arg parsers
      like 'Sig.many xs <|> Sig.many ys'.  I think.  If I wind up with something
      else like Derive.Call.Val.num_or_pitch it would be worth trying out.
      . E.g. Conditional.c_if_c takes: Symbol (Number, Quoted)* Quoted
      . Implement empty as pure (), then (<|>) should try left and if it fails,
        try right.  Doc is (x | y).  'some' and 'many' are like Sig.many1 and
        Sig.many, except they have to backtrack.
      . But derivation may evaluate expressions and check the type after that.
        Do I really want to do that with backtracking?
  postproc
    performance details / humanization
      - irregularize runs based on fingering patterns, e.g. groups of 3
    - retune a note depending on the previous interval (e.g. sloppy pitches
      when playing quickly)

  tempo track:
    - Nested tempo tracks at the toplevel block should normalize like they do
      when called.
    - Nested tempo tracks are probably broken for hybrid and absolute tempo.
    - Nested tempo tracks are probably also broken with a logical start.
  note calls:
    - retune call: differences based on speed should be more obvious, so that
      should also be on a curve.
    + chord calls, with automatic dyns for the notes.
      Originally I intended each note to go in its own track, with the idea
      that it takes about the same space but is more powerful and flexible.
      But it's not quite true, because the extra track is there for the whole
      block, though perhaps that's a side-effect of having blocks which are
      too large.  More compellingly, chords can automatically fiddle with dyn
      and start time, and can also interpret chord symbols.
  mridangam:
    reconcile tracklang and solkattu notation:
      use p in addition to or instead of +?
        . Then I don't have the nice - notation for soft tha.  I guess I could
          keep using '-', but it no longer has the visual correspondence.
        . Except I already use 'p' for the pattern call.  This isn't
          ambiguous in solkattu because patterns are p5, not "p 5".  I could
          do the same in tracklang, but it seems silly to bypass the
          perfectly good argument syntax.
        . Maybe call it pt then?  Or pn?  No, that's p+n.  Ok, pa then.
        . But '-+*' is really nice looking for soft, medium, loud.
          I don't mind taking * from dry thoppi because I never use it.
          Is the tracklang and solkattu discrepancy really so bad?  They
          have different constraints, e.g. for solkattu haskell ident for
          simple strokes, but full unicode is fine for output.
    - Automatic inference for Ki vs. Mi, e.g. in sarvalaghu.  E.g.
      dxd -> dld, but dxpx -> dkpk.  Also it can change based on speed and
      emphasis.
    - connect kendang, reyong, etc. to 'tir' and 'seq' calls.
    - make india.mridangam seq call align to the end for -0 dur
    . It would be nice to alternate mridangam and kendang tirmanam, e.g.:
      mridangam, kendang, both.  But I'd need to either write the tirmanam
      in solkattu dsl and give it a name, or have a mini solkattu dsl, e.g.
      with syllable breaking:
      . tri-mk 'kitakitataka nakadit_ talang_ talang_ ta' lang_
    . reyong: takadinna -> cccc, nakadit -> i12, talang -> +O
      . c = cek, k = kempyung, 0123 -> relative scale degree, .+ -> byut,
        oO -> byong
      . I could also have shift up, shift down annotations, like speed or
        nadai.
    - Perhaps mridangam should automatically transpose the octave to be within
      its range.
      . I can use something like Cmd.Instrument.Bali.wrap
    sarvalaghu
      - get them from Score or MridangamScore.
      - adjust to the talam
      - subdivide at slower speeds
  pakhawaj bols
    . Score integrate to convert bols to low level calls
      . Actually score integrate doesn't work like that, it just copies the
        input.  It would have to be derive integration.
    . Or maybe just interpret the bols directly, but due to context
      sensitivity they need to be all processed together, not as separate
      calls.
      . In general I don't have a way to interpret a track as a whole.  This
        is the "track call" thing I was thinking about a long time ago.
    - Add an input mode for bols.
  bali:
    infer gender damping:
      . Also don't damp repeated pitches.
        . Though with rambat this might have the effect of always choosing
          the long sample.  Still, doubled short notes will be ok.  Even
          short samples are usually around 3s.
      . I should be able to remove the explicit duration changes in ngoret.
        For that to work, I also need to say you can't damp even a neighbor
        if the notes are too quick.  But it's a certain technique, so maybe
        I shouldn't try to generalize.  Also jit-jeng is undamped but not
        just because it's too fast.
      notes:
        . The basic task is to set the duration for each note appropriately.
        . Firstly I want to mark notes with explicit duration and not touch
          those, and mark explicitly undamped notes, to extend them to the
          next damp.
        . So the first pass marks as infer-able.  Notes that touch the next
          note (with a certain threshold) are infer-able.
      - First infer hands:
        . If there are (or will be) two notes ringing, then left for low and
          right for high.
        . If there is one note, then pick based on the center of the range.
      - Infer damping based on assigned hands:
        . A note is damped when there is a hand available to do so.
        . You can always damp a neighbor of 1 or 2, >2 requires a bit of
          time to move the hand there and back.
        . You can damp two neighboring notes simultaneously.
      - Damping is different for gangsa style.
        . I think it's in the jumps, so gangsa can damp arbitrarily long
          jumps, instead of just 1 or 2, but can only do one at a time.
    - loop in save/bali/teruna-jaya leads to long notes
    - >kantilan | unison prevents nyog from working
    - kajar: automatic hand muting as with reyong.
    legong scale:
      - pick better nns for pemero notes 4 and 7
      - dotted cipher notation should use 4 and 7 instead of 3# and 6#.
    kotekan: gangsa:
      - >gangsa instrument, which is pemade + kantilan
        . It can be a alias of `multiple`:
          gangsa = multiple "(inst=pemade) "(%t-oct=1 | inst=kantilan)
      - nyog polos first can be inferred based on whether it's a major ruler
        division.  But should I?  I can just write 's+' to be explicit.
      - Simplify reyong norot in the same way as gangsa norot.  I also
        want to add the prepare_start feature.
        - Can I remove Once now?
      Kotekan kernel notation can be hard to use:
        . The kotekan call can be hard to use for irregular sections like:
          . |       |       |
             3-23-3-23-23-23-5
            2-12-2-12-12-1234-34-4-3
            |       |       |
            -3-23-3-23-23-21-
            2-12-2-12-12-1-10
            |
          . 4-3-4-3-44
            12-212-211
        . Maybe just a literal "once" kotekan call?
          Start at 0.
        . Maybe it's not "once" but "normal alignment", so maybe I can unify
          this with orientation.  But I think I need an explicit Positive
          orientation call like 'ko', rather than using event orientation.
        . For end orientation I still want to align to the end, but can I
          do that just by rotating the kernel?
        . I could say rotate or not based on the leading 'k'.
          (1)-12-1-21
        . Actually, maybe rotation isn't the problem.  Instead I have places
          where the inference rules don't work because the pitch is moving:
               3-23-21
            (2)-12-1-10
          . Can I infer?  (2)-12-1-10  -> ... not sure
          . Or write both? ke '-12-1-10' '3-23-21-'
          . I can, but it still takes longer than just writing it out.  And
            if it's not pitch-independent, there's not much benefit to the
            specialized kotekan notation.
      - k '-21-21-21-21-12-' infers with 1 below the pitch.  It should be
        . 43-43-43-43-434- 3-43-43-43-434-3
          1-21-21-21-21-12 -12-12-12-12-1-21

                          56-56-56-56-565-2
          2-32-32-32-32-23 23-23-23-23-2-32
        . Write as:
           -21-21-21-21-12- 12-12-12-12-1-21
        . Maybe it would be more predictable to say that 1 is always the
          pitch.  Then I can know if sangsih is above or below by looking at
          pitches.
          . 2-32-32-32-3232- 32-32-32-32-323-
            21-21-21-21-2-21 6-16-16-16-16-612
        . I can get it work, but it takes a lot of thinking.
      - Maybe have a character extend previous note.
      - Another option is to write the polos notes directly, and then
        a parent call that infers sangsih.  This avoids the problem where
        I have to figure out how many little numbers.
        . But if I'm going to do that, why not just use +p, +s, and +k to
          write the whole thing explicitly?
        . Well, that's quite a bit more fiddly.
      - in norot -> nyog transition, the last norot note cancels the first
        nyog note.
        . sangsih 6i cancels out the explicit 5e
        . Since {final} cancels normal notes, this is working as intended, and
          I can fix with final=f or 'strong', but it's surprising.  Maybe
          I should only have a final for negative events?
      - make gangsa and reyong norot and noltol dispatch to 'm' instead of
        directly applying +mute.  Or should I have a call for a weak note, and
        leave 'm' for an explicitly muted note?
      - gangsa zero dur mutes too loud
        . Really I need loose and tight mute, but I'll have to do my own
          samples, or maybe add a loose mute as open with just envelope.
      - noltol puts a mute stroke after a final note.
        . It's becasue it has a lower threshold, but not an upper one.
          But really it's not the threshold, but the form, noltol should be
          during kotekan.  So maybe I should really build this into kotekan
          calls.
      - clip should be end-weighted.  If I used a negative duration I could
        make it based on that...
        . Wait, isn't that what Clip is?
      - generate all possible kernels following some playability rules,
        e.g. no more than 2 notes in a row, only one rest
        . I could then use that to automatically select a pattern for
          a given destination, with some constraints like playability from
          the previous pattern (no fast jumps), above vs. below, telu vs.
          empat.
        . Then do that to make a random kotekan for ngubeng and majalan.
      - in Gangsa.realize_kotekan_pattern, pass Nothing as the start to not
        limit the start
      - inst postproc can interpret +mute as either just a mute, or open, or
        in between depending on %mute.
        . Then I don't need a configurable mute for
          Gangsa.gangsa_norot_arrival.
        . Reapply the 'm' call instead, and override that as appropriate.
      - an optional special pattern which switching between kotekan and back,
        e.g. 112-2-2-
    wayang in octaves
      . pemade: >p=>p-umbang | >s=>p-isep
        kantilan: >p=>k-umbang | >s=>k-isep | %t-diatonic=5
      . I could do it with >wayang-both that emits >wayang-p and >wayang-k. Or
        just call the score twice, once with transpose +1 oct.
      . I definitely want two calls because then kantilan randomizes
        differently.
      . Or I could create the kantilan as a integration of the pemade, so it
        can still be modified. I think this would want a "score integration"
        which just copies and merges the events directly, and doesn't do
        the intermediate derivation.
      . I could add inst aliases, e.g. >umbang = >p-umbang, etc.
        Or a note-track call: '>umbang = "(>p-umbang)'
        This can't be done with call aliasing because it's actually
        'note-title >inst', and anyway wouldn't help with 'inst = >x'.
      . The intended way to do this is have > instrument, and then set it in
        the caller.  But then you can't put >1 inst on the same block.
      . But this way doesn't work if I want differences in the kantilan
        version.  I would have to do correspondingly more copy and paste to
        replace the bit I want to change.
      . Ideally I'd like something like integration: everything is
        duplicated with no extra work, but an integration is available to
        edit.  But it would be a kind of "deep integration", where
        I duplicate the entire structure, from score on down.  Score
        integration could theoretically do that.
    trompong:
      * octaves shouldn't be able to infer damping
        . E.g. (6e 6o 6o, 5e - 5o)
      - I need a better way to notate a section as lower octave.
        . vv doesn't work is a note parent.
        . This is similar to octaves notation for gender rambat.
      - split to ngembat
        . There are several ngembat variations:
          . fast:
            5 61    35 61
               1        1
          . slow:
            561   53561
             21      21
    reyong:
      - divide infer-damp into infer-hands, and then use hand-damp.
        That way I can put an integrate after infer-hands, as
        a visualization if nothing else.
      - Damp level is way too high, I have to put %damp=.2 everywhere.
      - remove kilit, isn't it just norot now?
      - for infer-damp, also infer damp level
        . Damp gets louder when notes are closer, or faster.
        . Also longer note is a quieter damp, or just say if the length is
          over a threshold don't damp at all.
      - How to configure open and closed damping?  I can currently do it
        by adding +open, but that might be too broad because it also applies
        to +cek.  Or I could always damp closed if that sounds good.
        Or I could infer it based on speed.  Otherwise, I can change the
        attr to +loose-mute or +tight-mute to explicitly configure.
      - kbd entry for /, X, O, + etc.?
      kilitan: norot:
        . How to do norot for real?
          . Each voice is semi-independent, and may have different
            preparation patterns and times.  But then sometimes they
            coordinate.
          . Variations are random, but frequency is controlled by
            "kawayahan".
        variants:
          . omit notes
            . Especailly emit downbeats.
            . It either becomes a gap, or previous note is lengthened.
          alternating patterns:
            - possible mute or not for first two prepare notes
            - invert two notes, especially on downbeat or prepare.
              This only happens on the upper note.
            - hardcoded variants, e.g. p1 on dong
            - Delayed note, e.g. on ding, oiioioi
              ? What's this?
          . Make patterns based on matching pitches, e.g.
            [ ("212_", ["012_"])
            , ("1010", ["1100", ..])
            ]
          . This still isn't enough though, because alternating may also be
            2020 or 0101
          . Pickup can be iioi style, but parts that don't have the pitch
            often play the normal kilitan, or a passing tone.
          . I might be able to do all of these by hardcoding variant
            fragments, unless I get permutations.
            . I think I do get permutations, so let's do it programmatically.
          variations:
            ding:
            Iioi oioi
            Iioo iioi -- flip, more likely on strong beats
            Iio- oioi
            Iio- iioi
                 oio- -- drop beat, more likely on strong beats
                 ooii -- flip
                 _ioi -- drop note, uncommon, except maybe when fast
            . any muted can be unmuted

            - some prepare can be longer:
              . dang:
                aa uaea eaea
                33 2313 1313
              . dong:
                33 2232 3232

        above speed threshold:
          - omit more notes
          - Entirely different fast patterns, but what exactly?
        - Also I want to be able to control the dyn.  There should be
          a single control for +mute dyn.  Actually I already have that
          if I multiply %damp, right?  Still, explicit +mute notes and
          kilitan +mute notes are stronger than damping, so I need two
          I think.  Damping should default to a fraction of +mute dyn.
        - write an alternate style of kilitan, e.g. with a 6 note scale in
          tisram
      kotekan
        - reyong-voices doesn't seem to affect 'k' 'k//' and 'k\\', but does
          k_\ and k//\\ (and shouldn't the last be k/\ for consistency with
          gangsa?).
        - support high dung for position 4
    gender:
      - rambat damping emulation: notes ring on by default until they can be
        damped.  Damp at the first opportunity, where opportunity is defined
        as a break with no notes for a certain amount of time.  Can only damp
        two neighboring notes at a time.
  india: gamakam:
    . Get rid of gamakam1-4:
      - Remove gamakam4.
      Save what I want from 1-3 and remove.
        - gamakam1:
          . kampita and nkampita implementations
        - gamakam2:
          . use @ begin; middle;* end
          . middle can be kam, to get multiple oscillations + lilt as
            appropriate
          . It has a separate implementation of kampita, which might be more
            modern.  Also I still like the idea of a stretchy middle section,
            and I think I'll need something like that to write higher-level
            gamakam.
      - Remove ; syntax when gamakam2 is gone.
    - How to represent sangatis?
      . Also what about accumulating phrases, as in kuvalaya dala or mosaboku?
      . Maybe define a time range, then an edit in that time range will cause
        a score derive to be appended to the end of the range.  Since the
        "repeat" mark is also included, as soon as you edit the next section,
        it appends another one, unless you delete the repeat mark.  Editing
        a section will cause integrates down the line.
      . This would be a new kind of score derive that integrates into the
        same block and tracks, just at a time offset.  I could do the same
        thing with blocks, and maybe I should to avoid the additional
        complexity of a new "within track" integrate.
    - Bowing ornamonts.
      . gradual attack, and "puff" attack, ...?
    - I think Gamakam4 doesn't test next event pitch, e.g.
      Gamakam3_test.test_sequence on '!!-v-'
    dyn:
      - I think T is messed up, it seems to not know it's 0 dur.
      - Add support for '_' and, why not, '.'.
    - '.' call on the note messes up gamakam
    - 'v' for next pitch is wrong when the next pitch isn't on a note start
    - There still seems to be a case where prev pitch is wrong, it has to
      do with a '--' event.
    - And another prev pitch bug:
      [ (">", [(0, 3, ""), (3, 1, "")])
      , ("*", [(0, 0, "2d"), (1, 0, "3s"), (2, 0, "3r"), (4, 0, "3s")])
      , ("*", [(0, 0, "!^20"), (1, 0, "!0="), (4, 0, "!=")])
      ]
      . Last note should get 3r, but instead gets 3s.
    . For the violin, I want to experiment with other controls, e.g. pitch
      slides also do less bow-force, or dyn can reduce bow-force and
      bow-speed.

    - overshoot "curve" for 'smooth': over2 over3, depending how far over
    . instead of hardcoding specific times, I should say short, medium, long,
      which can vary and have some randomization:
      . short, medium, long: -s = "(rnd low high) | -m = .. | -l = ..

  control calls:
    - signal transformations: +, *, max, min
    - saturation limit, e.g. flatten sine wave but without clipping
    - continuous tempo warping for signals
      tempo: "2" -> "1", "2", cont: "2" -> "i, 1", should emit a bent line

text score: tscore:
  . doc/dev_notes/text-score.md
  . observations about tscore:
    . I really have to be able to read and hear the notation in my head, which
      means I really have to internalize the the solfege, whether it be sa ri
      ga or nding ndong ndeng.  It's probably a good way to force me to get
      stronger at reading.
    . Making time go horizontal seems awkward because it forces line wraps.
      Actually, I could just make long lines... screens are wider than tall,
      so maybe it's ok.  I'm not used to reading such long lines though, at
      least staff notation horizontal lines as guidelines, but maybe it's just
    . The main problem with horizontal time is that with text, each note can
      be a completely different width, so one note with an ornament causes
      everything else to get pushed back, and messes up the rough spatial
      relationships.  Staff notation gets around this because it has 2D to
      squeeze things in, and tends to use symbols instead of text.
      . Maybe I should do syntax highlighting that puts underlines on all
        lines with notation?  Probably not, because all lines have notation,
        I don't really have parallel non-note parts (e.g. so I can put
        ornaments above).  Maybe if I do control tracks, I could put the
        underline on the note track only.
    . For irregularly metered music like gender wayang, barlines are not much
      help.  Perhaps what I really want is "same time" assertions, so e.g. a
      | can appear anywhere, but if it appears in a spot in one part, it must
      appear in the same spot in all concurrent parts.
    . But in general I spend too much time trying to see the temporal
      relationships between parts and lining things up vertically.
      Even with sync-to-tracklang on save, it's still an extra step.
    . The automatic block length stuff is really nice.  I want this for
      tracklang.
    . I want to integrate ky and tscore so I can edit them together.  Maybe
      make tscore into a section of the ky file?  This will make syntax
      highlighting more complicated if tscore further diverges from ky.
  mascii has some nice ideas
    . https://github.com/arikast/mascii-source
    . automatic durations, calculated from required barlines
    . letter case for pitch direction
    - I should be able to try this out as another rhythm mode.  Use numeric
      suffix 2 to double duration, or :2 to halve it, instead of the __ thing.
  https://github.com/werckme/werckmeister
    . lilypond but with lua transformers
  standalone:
    . now that I have im and direct play, can I make a headless version?
    . Standalone parse, render, play.
    . But also I need a ky file, and instrument definitions.
      . Maybe nix-style '' strings for embedded ky?
    . But I can dispense with integration.
    * im: wait for all instruments to start
      . Otherwise I miss chunks for two instruments starting at 0.
    * check that %ky and %instrument not set for integrate
    - get MIDI and audio a bit better synchronized
      . Is there a way to actually synchronize, other than play_cache?
    * Transport.PlayMonitorControl can only monitor one thing, which is MIDI.
      . It could be a counter for each started player, so it could be used for
        im direct play too.  Maybe this would even allow stop during the decay?
    - tambura with no elements just made silence, no warnings
    - start from non-zero, and solo/mute
      . But how to indicate where to start?
    - without get_external_duration, merak-ngelo.tscore is broken
      . it uses Derive to get duration for expressions like "repeat=2 | p3a"
      . This is doable if I refine the get_external duration stuff to only
        take what it needs, and it makes it clearer that it's not actually
        circular.  But annoying:
      - get parse ky and inst allocs in parse_score
        . Actually it has to be in track_blocks, after parse_blocks
      * implement mini_derive
    - Trigger --check automatically on save, or via 'entr' like ghcid.
    / skip MIDI initialization for im-only
      . Need it for load_cmd_config
    / also skip audio initialization for midi-only
      . Needs to be initialized closer to main, don't know why.
  bug:
    - if I delete a block, I get
      keys collided in "state_blocks": [(bid "faust/test")]
      . I can't reproduce this now, deleting the block just disconnects from
        integration.
      . It would be nice to change the text style to non-integrated though.
    - adding pitches to a track that didn't have one can insert a pitch track
      on the left side of the note track.
      . E.g. "[s r]/0" then append "g m".
  * initialize sc patches
    . first, include the sclang versions in Example/tscore, or in ky
      make some patches:
  * unify ScoreT.Instrument with Shared.Note.InstrumentName, and
    Shared.Config.InstrumentName
    . Shared.Config._instrument is ${inst}_${patch}, fix that!
    . What does clearUnusedInstruments expect?
      It wants dir names, so wrong for faust!
  * octave hints seem wrong
    . 'm ,s' should be the same as 'm s' because both go down, but 'm ,s'
      seems to go down an extra octave.
  - Similar to renames, is it possible to detect track moves?
    . This also happens when I add a track in the middle.
    . If there are no edits, this works out because it looks like a complete
      change.  But if I have local edits it would destroy them.
    . This is harder than block renames, because tracks just have indices.
      Diff should be able to do it.
    . I can do the diff, then for each Second, look for a matching First.
      If it exists, rename the tracks, and the NoteDestinations.
    . In fact I have to rename even Boths, since a move will shift everyone
      else.
    . Could I do this in Merge.pair_tracks?  Then it will work for derive
      integrate too.
    . Maybe, but I do want to actually move the tracks, rather than just
      matching to the right track, but leaving them out of order.
      This only happens for a move though, not a delete.
    . I think I can detect deletes in Merge, but not moves?  Or rather that it
      has to be above the Merge.merge_tracks level.  In any case, do it for
      tscore and see if I need it for other kinds of integration.
    . The awkwardness with renaming TrackIds is that they are all generated in
      Merge.  That's why I wanted to move this to merge in the first place.
    . In fact, maybe since merge_tracks is just via zip, can I just rearrange
      them before sending to merge_tracks?
    . Just try it.
    . The diff gives deletes and adds, I still need to use tha move detection
      on that.
    . But I still have to merge non-matching tracks!  I only delete if there's
      an extra that has no match, but I don't know which one it corresponded
      to.  I could match equal ones, and then zip the insides.
    . Or, could I attach some identity to NoteDestination?
      For tscore, I would have to infer it somehow... unless I could embed
      some code in the track?  Make a vim command that inserts a magic key?
      Or the first time it sees a new track, stash an ID code and then have
      vim reload?  I could pick a 漢字, if I can get a list of the most
      common.  Actually I don't need anything that big, I don't have that many
      tracks, so could be 一二三. Or even !@#$%^&*()—+, or any symbol?
    . In the case of gender, the title is already unique.  I could have a rule
      that says track names have to be unique, and you can stick symbols after
      the > to make it unique, which won't go into the title.
    . Match tracks by key, and emit tracks that have been deleted, and the
      new track order.
    . But I want to make sure merge matches them, so I need to leave space for
      inserted ones so they go in the right spot.
    . Can I have Merge match on the keys?
    . It reorders the dests based on matching keys.  If multiple ones match,
      they get zipped as before.
    . Then reorder the block tracks to match the dests, and
      create/delete/merge as before.

    . src: x y
      dst: 1x  2   3y  4y  5   6
      out: 1xx 2   3yy 5   6
    . src: y x
      dst: 1x  2   3y  4y  5   6
      out: 1yy 2   3xx 5   6
    . If they're in the same order I can keep the positions, but if the order
      changed, I don't see how I know where to put xx, unless I keep the
      positions of dest tracks.  I think that would match the intuition that
      those are slots managed by integration, and extra tracks inserted in there
      keep their relative places.  But do I need to be that complicated?
    . I would do it by getting tracknums of dest groups, then zipping those up
      with the new dest group order.
    . The simpler way would be to shunt all non-dest tracks to the end.
      Simpler still would be to assume exactly 1 key per track, or at least
      handle keyed and non-keyed separately.  In fact maybe it has to be that
      way.
    . Ok, so: if there are any keyed srcs, assert they all are, and there's
      1 of each key.  Match them 1:1 with dests, and do move detection and
      deletes, and use the src order.  All non-dest tracks go to the end.
    . If there are unkeyed srcs, assert they all are, and then use the old
      algorithm.
    . The problem is that the merge-with-keys is more natural as generate
      a new block, then modify, because it imposes track order.  The
      merge-without-keys is based on mutation, presumably because it's
      preserving track order.  The non-mutation version seems nicer, but maybe
      that's just a knee-jerk reaction, since it needs to turn into mutation
      at the end anyway, unless I want to replace the block every time.  Which
      I don't want to do, because I want to retain TrackIds.  I guess once you
      opt into pointers you're opted in to mutation.
    . So should I go back to trying to reconcile the two approaches?  The
      reason it doesn't appeal is that it's work for features I never wanted,
      which is mixing keyed and non-keyed.  And it seems like I should be able
      to key deriver integration, and that I'd want to so it can delete
      tracks.  So keyed is the future, and I'd like it to rearrange tracks,
      but also coexist with non-integrated tracks.
    . But Derive.Integrated is just a stream of Score.Events, I don't know if
      I can key them, or enforce unique keys.  Convert.integrate separates
      them onto tracks automatically, because Score.Events don't have tracks,
      and can overlap.  This is because derive integration is coming from
      a lower-level source, which is also why I wound up with score
      integration.
    Bottom line:
      . Derive integration is not important, since I'm not using it much, so
        I don't know in what form I will want it.  If I can use it for e.g.
        rambat integration then I'll have a use for it, but in that case
        I think I will want to have control over tracks, e.g. left and right
        hands.  But it does seem like it's right, in the way that coming up
        with a whole other language for fancy score integration is not.
        I should instead augment the Score.Event output so it can be both
        played directly, and converted back to high level score.  That
        potentially means track keys, because I'd want it to be able to
        generate one more or less tracks without destroying all my
        modifications.  So maybe this means derive integration will likely
        stay, but maybe not in its current form.
      . Meanwhile, tscore integration will always have unique track keys, and
        I do want non-integrated tracks in the same block, but I don't mind if
        they're segregated to the end of the block.  In other words, it's ok
        to force the tscore integrated tracks to be a contiguous range of
        tracks.  I definitely want to enforce track order, and hence detect
        moves, because tscore has an order.  Of course, maybe derive
        integration will want to as well, after all if I'm going to generate
        score, I should generate nice score!
      . If I'm going to insist on track keys, I could fake them up in
        Convert.  The result should be the same as with zip, but at the merge
        functions can have a uniform interface.
    Let's do this:
      . Pair tracks by key.  Emit a Seq.Paired for tracks, in order.
      . Collect non-dest tracks before and after dest tracks, and replace the
        dest tracks in the middle.
      . If the tracknums then don't line up with the current state, delete and
        add as appropriate, and apply mutations to merged tracks.
    . If I have multiple destinations for one source, this is going to force
      them all together.
    . It seems like there are separate cases: tscore manages the track order,
      because I have the order in the source, and if I want multiple dests,
      I can come up with some way to say that in tscore, rather than putting
      the state in the tracks.  But integration as a general building-block
      may not want to do that.
    . Can I have an explicitly different kind of merge?  Just call a different
      merge function.
    . This takes me right back to doing it first, before the merge.  Do a step
      to line up the tracks based on key, and then do the zip based merge.
      What stopped me from pursuing that?
    . I think it was that I need to have the keys in the NoteDestinations
      to do the reorder.  Suppose I do:
      . In tscore: convert to NoteSources, pair (NoteDestination, NoteSource).
        Use the pairing to map a TrackId to a NoteSource via NoteDestination.
      . For each track_id in the block:
        . If not in NoteSources, continue.
        . If the NoteSource is the current one, then recurse on the control
          tracks.
        . If I can find the current NoteSource as a TrackId, move it to here.
          Recurse on its control tracks.
        . Otherwise it's obsolete, delete it.
      . To recurse on control tracks, I do the same find and move thing.
      . The not so appealing thing about this is that it seems like I'll want
        this same thing for other kinds of keyed integration, e.g. rambat
        produces two hands.  I'll cross that bridge when I get to it.
    - Add key to Convert.Track, rename to NoteSource while I'm at it.
    - update Merge.pair_tracks to take [NoteSource]
  - How to notate weak notes?  I'd like to make it concise.
    . Maybe I could have a set of symbols that are then macros:
      !, @, #, $, %, &, =, -, +
      . Then I can write %macro-=/* [ r g - r g - ] -> [ r g /* r g /* ]
      . Wait could I just write [ r g * r g * ] then?
      . Yeah it works.  But I still might want to e.g. replace _ with that,
        and make * be the real rest?
  - carry octave and dur into sub-blocks.  It should go lexically,
    left-to-right.
    . This means I'd have to do Check.check before resolve_sub_block.
    . Currently it goes: parse, unwrap_block_tracks, resolve_sub_block,
      put in ParsedTrack, then make_tracks, Check.check.
    . Could I leave ParsedTrack unresolved, and make blocks later?  It seems
      awkward because then I would have to create more blocks after check,
      which would then require check, etc. recursively.
    . Or, I could have Check.check emit the final state, and initialize the
      sub-block with that.  I would have to know what was the parent block.
      And since sub-blocks can occur anywhere, I would need to interleave
      one way or the other.
    . Why can't I carry octave and dur in a separate pass before
      resolve_sub_block?
    . Octave requires parsing the pitch, so it pretty much requires
      Check.resolve_pitch... though I could carry it as an "carried octave",
      which would be enough for lexical carrying.
    . Mult and add durations carry differently:
      add carries int1 and int2 separately
      mult carries int2 to int1, or if int1 is set doesn't carry int2.
      Whut?
    . mult: 1:2 -> 1/2, 2 -> 1/2, 2: -> 2/1
      add:  1:2 -> 1/2, 2 -> 2/1, 2: -> 2/4
    . I want to carry both always.  :x -> 1:x, and x: -> x:1
    . But for additive I want to carry the denominator independently so I can
      set it: 1:4 2 3 2 1:5 2 3 2 1
    . So I actually need to resolve pitch and dur, I can't carry
      independently.
    . Octave can be done separately:
      resolve_pitch :: Scale
          -> Stream (time, T.Note call NPitch dur)
          -> Stream (time, T.Note call (T.NPitch (Maybe Text)) dur)
    . resolve_duration: (Either T.Time T.Duration) T.Duration -> (T.Time, Bool)
    . So I could do it, but I'd have to pull out resolve_pitch and do that
      first, and change dur and rdur to (Maybe T.NDuration, T.NDuration).
      This means T.Tracks would have to get some more type variables.
  + copy from:
    . [s r g]/0 ~ ~ works nicely for repeats, but what if I want to duplicate
      from another track?
    . At tracklang, this is what I wanted to use score integration for, but
      I'd need special support to do it from tscore.  E.g. %integrate-from,
      and then some kind of "unchanged" note.
    . If I did support directly in tscore I'd need the same thing, e.g.
      ^ means "copy from integrate source".
    . The difference is that integrate would show the connection, and it would
      reflect changes over.  But I think this means the track is integrated
      from two places, which is awkward.
    . A "copy from source" would be pretty straightforward, but limited to 1:1
      copy.  It would be more powerful to put in a score integrate, and then
      ^ is a "don't replace", and the rest of the notes become modifications
      to the integrate destination.
    . Do the simple copy first.
    . ^ has a duration, which is the extent of the copied range.  It should
      carry like notes.
    . If I make it a TNote then it happens automatically but I get things like
      call/^, which could be interpreted as "replace call".  It means
      pitch becomes an Either or something, but it's already a variable, so
      I can factor it out in a separate pass.  Actually it's probably nicer
      than being at the Token level for that reason.
    . The tricky thing is that I need a resolved source before I can resolve
      the dest.  This is a similar situation to CallDuration.
    . Can I do it together?  I think not, because a CallDuration dependency is
      orthogonal.  But it's the same memo table technique, complete with
      cycle detection.
    . How to name source?  For intertrack, a %from=tracknum.  If block has
      %from=blockname, it's like having a %from= on each track, with the
      corresponding tracknum.
    * This means I need track directives!
    * To get the copy ranges I need times.  But I only get times after
      resolution.  But I need to resolve after the copy.
      . So maybe I have to do the memoize thing, to copy over resolved notes.
      . I can do it after resolution, since I don't want to carry durations
        and pitches.
      . So I have to plumb the CopyFrom through as a pitch.
    + Figuring out the proper durations can be annoying, can I use
      0 CallDuration to get it to stretch until the next barline or coincident
      assertion?
      . branch tscore-stretchy-copy
      . Do in Check.resolve_call_duration.
      . Adding the durations doesn't work because I need to know when it
        *should be*.  That's what check barline does.
      . To get AssertCoincident time, I need to look at another track with
        AssertCoincident and no CallDuration.  If I do barline, it risks being
        confusing because it's the next valid barline, not the one that
        appears in other tracks.  And in that case, I might as well just put
        in the explicit duration, because I know how long a bar is.
      . So either I have to have barlines stick around, or just do
        AssertCoincidents, but in either case, I need to get the duration at
        the same level as TScore.match_asserts.  But it's more complicated, in
        that I can't go top to bottom, I have to find at least one track with
        no stretchy dur, and pass its AssertCoincident times to the others.
      . It seems doable but non-trivial.
    - I usually want to copy according to a certain pattern, e.g. sangsih from
      polos, and the %froms get cluttery.
      . A simple and explicit way is rename %from to %f.
      . An implicit way is declare default directives by track title, e.g.
        >sl=%from=4
      . This is not only implicit, but dependent on the exact track structure.
        Of course it's often the case that I don't want to allow deviating
        from the structure, but I'd rather it be explicit and enforced with
        a check, than implicitly relying on it, and doing the wrong thing if
        not followed.
      . Maybe I can use a tracks template?
      . I guess it would be a set of default track names, and then I can just
        use ">".  It's pretty implicit though, and just copy-pasting the
        standard set is not so bad.
      . Or, I could make %from inherited across tracks, to each track with the
        same name.  That would be like the >sl=%from=4 only even more
        implicit, but with no special syntax.
  - using blocks to express repeats means the barlines get off, since they're
    always relative to the start of the block.
    . But sometimes I do want them to be relative, and it's certainly easier
      to read if they are.  Maybe what I need is a way to set the starting
      beat, either via directive or a barline that asserts that it's correct.
    . If I had a "assert" barline, say |*, I could use it with stretchy
      duration *, so e.g. [s r g* ||* ...] will make g last as long as is
      necessary to get to ||.
    . If I have "copy from", it would do the same: [^* |* ...]
      But why do I need the stretch on both?  I could use a regular barline.
  - I have a lot of things with alternate endings.
    . This is part of the general problem of variations.
    . Also endings change depending on where they are going.
    . Copy from block should be able to do this.  But since it's time-locked,
      it wouldn't work for an alternate beginning.
  * negative durations:
    . So I can put beats at the end:
       e o u e | i o a i | ~ o ~ e |
         o-2 e |   o   i |   ~   e |
      "k//"/e-4 |"k\\"/i | k-12-1-21/e |
    . realize as:
      _ e o u | e i o a | i ~ o ~ | e ~
      _ _ o ~ | e ~ o ~ | i ~ ~ ~ | e ~
        e oe o| e i oi o| i eu e u| e ~
    . or more naturally:
      e o u e | i o a i | ~ o ~ e |
      _ o ~ e | ~ o ~ i | ~ ~ ~ e |
      e oe oe | i oi oi | eu e ue |
    . As usual, this works as long as I don't have rests.  Actualy it seems
      fine, it's just a rule about where barlines go:
      _ o _ e2 |   o1 _ i2 |   o   e |
    . Right after the downbeat note, regardless of its duration.  So can I do
      it just as a barcheck rule?
    . Probably not, because what about sequencing blocks?
    . How about just a rule that says the barline goes after the note with the
      beat, rather than before it?
      . That's probably not enough because I still want to say the block ends
        with a note, not starts with one.
    . Maybe they should be only for zero duration notes, where I notate the
      duration via explicit damping.
    . Durations are 0, and the note starts go to the end of the duration.
    . But I might be able to resolve barlines as normal before that.
    . It works, but it just pushed the problem to the tracklang, where it's
      the same as it always has been...
  / How to do numbered repeats?
    . If I have a repeat last note thing above, then just attach a number to
      it: '4s .4' or '4s ~4'
    . I'd need to make this a special token and parse, rather than reusing
      the normal doted or tied note syntax.
    . What if I keep hijacking?  '4s 4.' or '4s 4~'.  This seems confusingly
      reusing something reasonable, why should '4s 4' be completely different
      from '4s 4.'?
    . What about the : syntax, did I implement that?
  cleanup:
    - Collapse new tracks on an existing block.
    - Also adjust block view size.
      . I should use standard Create functions to do this all automatically.
    + Manual integrate is error-prone, where can I document it better?
    - fltk: the final pitch event is misaligned
      . It only happens when no ruler, and it's a visual drawing artifact.
  repl:
    - communicate parse errors back to vim to highlight
      . use quickfix mode?
  parsing:
    - directive for basic pulse/matra?
    - Just akshara:matra isn't necessarily good enough because what about
      1/2 matra etc?  mult is apporpriate at this.
      . I could make : into a list, so e.g. akshara:dur:denom.  Or I could
        hijack . to subtract instead of adding dur, then 1. is speed 2, and
        1.. is speed 3, etc.  Probably lots of dots get hard to read though.
      . I can get this by doubling the nadai, e.g. :8 or whatever, but it
        still seems like I'd want an easy 'su' type annotation.
      . Maybe . could be su, and I carry it?  Then I need an undot for sd.
  rhythm check:
    proportional durations:
      . I think this is like add, but everything has the same duration, and ~
        continues the note.
    mark durations ala gongche:
      . This replaces barline check with setting the durations.
  pitch check:
    / put resolve_pitch before resolve_time
      . This way ties work with inferred pitches.
      . Then I have to plumb through TBarline etc. which is annoying.
      . I think it's not necessary now that I have repeats.
  Time problems:
    . I want to say "repeat n times".
    . I want sections with their own tempo, and then the caller just sequences
      them.  If I turn the whole thing into one call, then I can still fit it
      into a global timeline, and apply transformations or tempo there.
    . If there is meter information in the text score, I can derive a ruler.
  notes:
    . I could generalize Pitch.Pitch to 'Pitch pc'.  Then Bounded types would
      have per_octave built-in, but I could still use Int for generic cases.
    . Rhythmic framework: in the solkattu branch I extracted the rhythmic DSL
      to 'Note a | TempoChange (Speed | Nadai)' and I have have generic
      functions to get durations and check tala alignment using matras, and
      flatten to (Time Ratio, a).
    . This winds up being more general than haskore, but probably less general
      than music-suite.  It looks like 'temporal-media' is analogous, though
      with arbitrary time shift/stretch, and events have duration.  Also since
      it uses (start, dur, note) events, it doesn't need rests, and can do
      overlapping events.
    . Henning Thielemann's LiveSequencer highlights score as it plays:
      https://hackage.haskell.org/package/live-sequencer-0.0.6
      . He does it with a custom gui widget and language, but I wonder if
        I could do this with by sending highlighting info in real time to vim?

pitch: scales: scale:
  - non octave equal temperaments, e.g. 12ed5
  . Try octatonic with 21 ascending, and 12 descending.
  just:
    - should just chromatic scales differentiate A4 and d5?
      . In general they should probably deal with enharmonics, but I don't know
        enough about just intonation.
    . How could use a custom set of intervals?  Or custom set of ratios?
      . E.g. charukesi: M M m M m M M, 2 2 1 2 1 2 2
      . The existing setup gives easy access to piano_layout and rotations,
        with 5-limit and 7-limit, but ideally I want any ratios and layout.
        I could do this in haskell, but it's awkward to recompile each time.
      . How about: just-intervals = (list 2 2 1 2 1 2 2)
        | just-ratios = (list ...) | scale=make-just
      . I really want a better solution for Scale.Make, so I can write
        scale = (make-just (list 2 2 1 2 1 2 2) (list 3/2 ...))
        and not pollute the global environment, so maybe that's the real
        problem.
      . But maybe that's orthogonal, if I want that I should have named
        arguments.
      . Or, I could delete the keys out of the environment.  I wonder if that
        would even be a reasonable keyword arg implementation if I put it in
        Derive.Sig?
      . Well, but I think scales can't do that since they're not really calls,
        they'd have to hook into Derive.with_scale somehow.
        . What if I replaced Scale.Make with with_scopes, so it can handle
          the scope modification itself.
        . Actually it already happens: get_scale makes the scale including
          degree calls, then degree calls are stashed in scopes.
        . I could just hack this one thing by adding
          Scale.scale_delete_env_keys, which Derive.with_scale then looks at,
          but I don't think I hate env pollution that much.
      . Back to just, there are two possibilities: if I have 7 degrees then
        I can use sa ri ga, but for a variable number of degrees, I'd need
        oct-degree type notation, like *hex.
      . I.e.: (TheoryFormat.letters pc_per_octave)
          (TheoryFormat.cipher pc_per_octave relative_fmt)
  - Think of a way to return scales from val calls
    . Detailed notes in Derive.Scale.Interpolate NOTE [make-scale]
    . It's hard because of the Val and Derive circular dependency.
    . Can I put something in Val that will make a Scale without referring to
      Scale directly?
    . Or can I move Scale out of Deriver.Monad?  I guess if I could I would
      have.
    . I guess no because it has ValCall and Deriver.  Fundamentally it's
      because scales are implemented as val calls, so Derive must be higher
      than Val, so Val can't contain a Derive, unless they live in the same
      module.
    . At one point is it worth trying hs-boot again?  I remember I really
      hated it when I had it, because ghci tended to reload tons of stuff.
      . Could be better in 9.2:
        https://gitlab.haskell.org/ghc/ghc/-/merge_requests/5661
    . Ok, can I do it without vals, but get the same kind of syntax?  Like
      maybe LookupPattern for ValCall that evaluates to the scale symbol plus
      whatever it is that makes the scale?
    . Speaking of which, what exactly is that?
      . Scale.All.lookup_scale -> Derive.state_lookup_scale -> Derive.get_scale
      . So it actually makes the scale on every lookup.  I guess it has to be
        this way, since it's not in Val, there's no way to store it.
  - I'd like to make a local scale derived from another one but some notes
    missing, and have input and transposition skip those.
    . Ideally it could be a modifier to any scale, so it would modify input
      and transpose accordingly.  Symbols remain the same.
    . I'm still unhappy with the Scale.Make Make|Simple thing.  Returning
      Scale from a val call would be better, but I think that runs into the
      big Derive / Val circular dependency problem.
    . Do as a Make for now.
  - twelve-k doesn't work entirely correctly.
    . The problem is that ChromaticScales.pitch_note doesn't preserve an
      explicit natural, so it gets lost after a pitch->note.  I think
      show_pitch has to have twelve-k support.
    . I don't care enough about twelve-k to fix this now, but maybe some day.
  scales / Derive.Scale:
    - I think the symbolic pitch_note functions should use RelativePitch,
      otherwise the symbolic pitch they produce can't be parsed back in to
      produce the same pitch.
      . Demonstrate with some tests and fix if necessary.
      . For ChromaticScales and JustScales
    - TheoryFormat.make_relative_format is a confusing name because it makes
      a Format from a RelativeFormat.
    - It's confusing how the default_key is built-in to parse_key but also
      passed separately... maybe it should take a flag to say whether an error
      should become the default?
    - Strip type prefixes from Pitch.Pitch and Pitch.Degree?  Add lenses?
    - add ratio transpose signal, that multiplies hz
    support scales that are different ascending vs. descending
      . Scales have two versions of each degree.
      . scale_input_to_note takes a previous Note arg, which it can use to
        guess the appropriate variant.
      . Variants have to have unambiguous names though, maybe 4n^ and 4n_
      . Use scale_alternate to switch a note between alternates, bind to the
        same key as enharmonic.  If there are no enharmonics, then fall back
        on alternate.
    raga: ragam:
      - Omit missing swarams.
        . It seems most natural to treat it like a scale of fewer notes, so
          e.g. mohanam like *wayang.
        . But maybe it's less confusing to have a consistent keyboard.
          Maybe the original approach is best, where janya ragams still have
          all the same notes as their parent.
        . What then should janya ragams do?
        . Gamakams (and transposition) should skip missing swarams.
      - arohana / avarohana:
        . Select which depending on an env var, and have a postproc to go
          through and assign those.
        - I also want a cmd to cycle unspecified and explicitly arohana or
          avarohana.  I can bind it to the flip-enharmonic key unless I want
          to have scales with both concepts.
        . I could have both srgm notation, and s, r1, r2 etc.  Then use
          enharmonic to cycle r, r1, ... depending on what is available in the
          ragam.
        . But until I have ragams with alternate pitches, there's no use.
        old notes:
          . I could keep it at the Cmd level by remembering the last entered
            pitch and defaulting this one based on it, or I could try to put it
            at the Derive level too by having the pitch itself be based on the
            previous one.
          . Putting it at the derive level seems really hard and unreliable, so
            I should have separate symbols, e.g. 4r^ and 4r_ for up and down
            variants.  For western modes this isn't necessary since the notation
            is already absolute.
          . Or I can model r1 r2 r3 as accidentals.  The raga gives the default,
            and then I can change the cycle enharmonics binding to instead cycle
            number of "accidentals" to force a particular one.
          . So I would model as a chromatic scale but with a custom number of
            accidentals per degree:
              s, r1 r2 r3, g1 g2 g3, m1 m2, p, d1 d2 d3, n1 n2 n3
          . How should ragams look anyway?
            . Absolute chromatic scale with all pitches, and g[123] notation to
              explicitly choose one.  Arohana and avarohana show how to infer
              given plain g.  If >1 exist, then try to infer based on the
              previous pitch.  Also g^ and g_ chooses between 2, if applicable.
            . I need inference for gamakam, but I'll need an override, maybe
              ^_ postfix for numbers?

    - letter and jianpu but with implicit accidentals based on the key
  intonation: think about how to do e.g. meantone melody, with just harmony
    . Do a postproc to analyze simultaneous notes.  If I use an attr to
      tag the melody, I can tune everyone else to it.  But how do I retune
      notes with non-trivial pitch curves?  Well, I could use a transpose
      signal to tell the pitch calls what's going on.  I think I might just
      need the frequency of the melody note.
    . Do an analysis pass, and insert environment that says what the harmony
      is.  Then pitch calls use that to tune.  Doing the analysis might be
      tricky since I have to extract a "principle pitch" from each event,
      but it might be useful in general to have an analysis framework.

Perform:
  - move patch initialization to Cmd.Initialize, and do it automatically on load
    . midi, sc.
    . For sc, if configured with the path to scsynth, I could start it
      automatically.  In that case, I may want to send a /quit on exit.
  supercollider: sc:
    research:
      . https://doc.sccode.org/Reference/Server-Architecture.html
      . https://doc.sccode.org/Reference/Server-Command-Reference.html
      . https://www.youtube.com/watch?v=R0ulauoGCvI&ab_channel=EliFieldsteel
      . in sclang, s.plotTree and s.meter to see graphical representations of
        the scserver.
      . How to load a synthdef that responds to pitch, amp?
        SynthDef(\test-sine, { |out, freq = 440, dur = 1, amp = 0.5|
            var sig;
            sig = SinOsc.ar(freq, 0, amp)
              * EnvGen.kr(
                Env.linen(0.05, dur, 0.1), doneAction: Done.freeSelf);
            Out.ar(out, sig ! 2) // sig!2 = [sig, sig]
        }).add;
        x = Synth(\test-sine, [freq: 440, duration: 1]);
        x.set(\freq, 660);
      ? What OSC messages do those correspond to?
      . I could either send the whole control env as one OSC message (does it
        support variable length arrays?), or stream updates like with MIDI.
        Or just do the duration, since that is fixed-length.
      . I'll probably use /d_load str [bytes]
      . /s_new str ID
      . /n_set str float ...
      ? What are: array type tags ($[ and $]) ?
        . https://doc.sccode.org/Guides/NodeMessaging.html
        . I can set a paremeter with an array value, but it implies the array
          is fixed length.
      . If I'm going to use /n_set style, I could get the parameter indices
        so it's more efficient.
      ? How do OSC replies work?
        . Maybe it just sends back to the same port that sent it?
      . OSCFunc.trace(true); to show incoming OSC
      instruments:
        . /d_load to load an external file, but how do I know which ones
          exist?
        . Can I get the directory of them, and parse them, to know names
          and (control, controlID)?  Yes, vivid-supercollider can.
        . Use SynthDef.writeDefFile, will wind up in SynthDef.synthDefDir.
        ? Could I run sclang standalone to compile to scsyndef?
      How does vivid do it?
        send synthdef:
          (`runReaderT` serverState) $ oscWSync $ \syncId ->
            callOSC $
              SCCmd.d_recv [sdToLiteral synthDef] (Just $ SCCmd.sync syncId)
        . SCServerState has things like socket, IDs.
        . sdToLiteral makes LiteralSynthDef, which is the low level sc format.
    plan:
      . Each note is a synth.  It sends a /s_new with duration and initial
        control values.  If the synthdefs all have doneAction:Done.freeSelf,
        then I don't have to free explicitly.
      . Play thread keeps track of node id internally.  I could do
        /s_noid synth_id for all tracked synth_ids still in duration if
        I wanted to quit the thread to reuse the IDs.
      . Do a /g_freeAll 1 on "stop all".
      . Then send OSC scheduled for n seconds in advance, it is just /s_new
        and /n_set.  Since existing patches won't support line segments, I
        wuold have to do interpolation myself like with MIDI, so there will be
        a lot of these.  I could try to group coincident ones.
    - add docs
    - make some patches:
      - wavetable examples from end of
        https://www.youtube.com/watch?v=8EK9sq_9gFI
        http://sccode.org/1-5bF
      + MembraneCircle
        . must install sc3-plugins
        . no sound?
      + zot
        . It has no duration... is it reasonable to add, or do I have to track
          SynthIds?
        . In general I'm going to have to enforce standardization on control
          names: freq, dyn, ...?  im uses: dyn, vol, pan, pitch
      - use sclang from the commandline to compile to scsyndefs, that way
        I can include patches as source.  Possibly even put in ky?
    - Is there really no way to send segments and let scserver interpolate?
    make noid work on groups:
      . This seems to be not hard to add to scserver though, I wonder if they
        would accept a patch?
      . But, even if they did, now people have to install latest sc.
      * add feature to scserver
      - compile and test it
      - send a patch upstream
    - I still feel I should move osc perform into convert, and remove the
      MSignal intermediate step.  And if that's possible, why not do it for
      MIDI too?
    instruments:
      . https://sccode.org/1-57B
      . Bits from end of wavetable and granular in tutorial:
        https://www.youtube.com/watch?v=UoXMUQIqFk4&list=PLPYzvS8A_rTaNDweXe6PX4CXSGq4iEWYC&index=23&ab_channel=EliFieldsteel

  midi:
    - Overlapping notes with different ControlSwitch cc numbers should share
      a channel.  Of course it'll work anyway if only one channel is
      allocated.
      . Currently they definitely won't, because the performer assumes that
        all controls affect the sound, and so you can't share with any control.
    - Pick the best channel instead of the first one.
      . An event can share a channel if it has different controls but the events
        don't overlap.  This is required so that a sequence of notes that each
        set a different control will go on the same channel.  But since it
        always picks the first usable channel, you can have controls trade
        channels, depending on how the coincident events are sorted:
          [(0, 1, c1), (0, 1, c2), (1, 1, c2), (1, 1, c1)]
        This should put the c1s together, but they will trade channels if they
        come in that order.
      . I think to fix this I'd have to have can_share_chan return
        Left fail_reason or Right priority, and pick the highest priority.
        It would have to give a lower priority to events that could share, but
        have incompatible controls just out of the event range.
      . let f = Perform.shareable_chan
        let mkevent start controls pitch =
                Perform.Event inst1 start 0.33 controls
                    (Signal.signal [(0, pitch)]) DeriveTest.fake_stack
        let pedal = Map.fromList [("pedal", Signal.signal [(0, 1), (6, 0)])]
        pprint (f [(mkevent 3.33 pedal 45, 0)] (mkevent 3.66 mempty 72))

    - I can work around the pianoteq tuning bug by not stripping redundant
      conrol changes.  This also means that recorded MIDI can be played from any
      point.  If bandwidth isn't a concern then why not?
    - damper pedal causes all notes to extend until the pedal comes up, should
      the performer know about that?  Is there anything that this breaks?
      I don't think so, it affects channel allotment so notes could be
      improperly joined, but mixing pedal and multiplexing seems rare enough.
    - Perform.Midi.Perform: should be possible to lead keyswitches as long as
      they don't precede the previous NoteOn, since I think samplers will only
      switch on the next NoteOn

Util.Format:
  fix incorrect wrapping:
    I think the information available is incomplete:
      Record
        f 1 g 1
        h 1
      [(0, "Record"), (1, "f"), (2, "1"), (1, "g")] (Just (2, "1"))
      . Should break at (1, "f")
        0
          1 2 1 2
          1 2

      { [ k1: v1
        , k2: v2
      [(0, "{ [ k1"), (2, ": v1"), (1, ", k2")] (Just (2, ": v2"))
      . Should break at (1, ", k2")
        0 2
          1 2
    . So these two are inconsistent: [0, 1, 2, 1, 2] -> ([0], [1, 2, 1, 2])
      But also [0, 2, 1, 2] -> ([0, 2], [1, 2]), rather than ([0], [2, 1, 2])
      Because it looks ugly to split on 0 2:
        { [ k1:
            v1
          , k2: v2
    . I could resolve it by breaking before the *first* lowest indent, except
      the first one, rather than the last one.  This well make lists with
      many small elements very vertical though.  Maybe it just winds up being
      like pretty-simple, which is too spaced out for me.
    . Also break-on-first breaks the assumption of spanLine, which tries to
      fit until it runs out of space.
    . And then since it likes to break so much, I get
      0
        1 2
        1
          2
    . Because it see that the next is an implicit 0, and wrap before that.
      But if it did, I would get:
      0
        1 2
        1 2 1 2

  HsPretty:
    problems:
      . Missing close paren after wrapped constructors.
      . If I add an indent after each constructor then I get tons of indents.
        What I really want is a way to collapse multiple constructor calls
        with a single argument.
      . For some reason it's not wrapping tuples properly, they become
          (a, B
            c
          )
        instead of
          ( a
          , B c
          )
  - move format related modules to Util.Format.*
  - don't use 'reverse' in 'flatten'
  - lazy implementation?

Instrument DB / browser:
  - Fl_Help_View supports limited HTML, use it to display formatted text
  - browser has lots of empty space on the bottom
  - z1/virus-bass has UnknownMessage for initialization?
  - patch files could go in the Local/Instrument dir with the source?
    at least it should go in source control
  - colorize the info_pane so tags are easier to read
  - search lang supports quotes
  sysex
    z1
      - convert patches to larger pitch bend and send them back
      - I need control over which program and bank the patches go when they
        are initialized.  I can use the card as scratch space.
      - I also need to initialize a new multiset, and give the score
        a multiset config, or derive one from the midi config.
    vl1
      - test sending sysexes back
      - move patches to new format
      - figure out how to set category for builtin patches
        . *word shorthand for category=word?
        but I want to use the inst name, not the score name...

OSC backend
  in doc/dev_notes/sythesizer
  - Write a simple supercollider instrument and try controlling that with OSC.
  - Even if reaktor and supercollider don't understand bundles, I could write
    a scheduler server that takes bundles and emits their msgs at the correct
    time.

linux:
  scrollwheel too slow
    . Can I tune the sensitivity somehow?
  faust segfaults:
    . data/im/notes/test/faust/tambura/faust/b4/faust
    . faust-im specific or sampler-im does it too?  faust-im
    ? All faust or just tambura?
    ? Faust version?  nix is 2.19.7, mac is 2.5.34
    ? gcc/clang?
  jack: JACK:
    bugs
      - something is still wrong, I get "no space in output port" and then
        corrupted output
      ? jack1 doesn't work at all: other clients don't see writes, until
        I quit, and then they get continuously spammed.  Apparently the
        jack_port_t* from the registration and the lookup are different.
        - Try stashing port from port_by_name port instead of
          jack_register_port.
    - does jack not support sysex at all?  Maybe I can't use it at all then.
    - Ensure that shutdown stuff is being called correctly.  I don't care but
      maybe JACK does?
  alsa midi:
    . Would it be simpler to write a alsa midi driver?  I think JACK can then
      spy on the alsa midi output.
    . https://hackage.haskell.org/package/alsa-seq
      This is presumably usable, but undocumented and directly implements the
      API at the lowest level, so it's really complicated.
    . https://www.alsa-project.org/alsa-doc/alsa-lib/seq.html
      Incomplete, but e.g. aconnect.c is an example.

misc ideas:
  . What would a generalized staged evaluation system look like?
    E.g. evaluate note (start, dur) and first pitch track.  Then go through
    again and evaluate the rest of the tracks.  The second time the
    neighbors are now incomplete Score.Events with timing and pitch.
    I would also flatten out the block structure and cancel weak notes so
    I have access to true next and prev.  This implies some way to stash the
    unevaluated tracks in the Score.Event.  Then a postproc pass would go
    through and evaluate again, providing new context to the unevaluated bits.
    . I already have something vaguely like this in the Inversion dynamic
      state.  I can provide new context with Dynamic... though it would be an
      essentially untyped way to do it since there's no type difference
      between the first and second evaluation.
    . At the moment I don't need a generalized solution, so I could just
      hardcode:
      event_stage2 :: Maybe (([Score.Event], [Score.Event]) -> NoteDeriver)
      Then at conversion time, any event with an event_stage2 is replaced by
      its evaluation.
    . Conversion isn't quite right, because I still want next event on track
      etc... but actually no, I've been here before.
    . Then I need some way to specify notation that wants to wait until
      conversion.  I guess it would go by track, so maybe a magic symbol in
      the track title.  Then slicing separately returns slices from those
      tracks.  These still have to be evaluated in their original environment,
      so I then wrap in a derive_tracks and store as a NoteDeriver.
    . So I think this could work... but is it really worth it?  It seems like
      it introduces a whole new level of complexity.  And, if I go the
      typesafe route, a whole new type of calls, which a new accompanying
      namespace.
  . Import or trace curve from a pitch tracker into the pitch track.
  . Staff notation represents chords well, but tracks don't.  Think of a more
    compact notation.
  . Why can't I write a 'tr' that generates pitch signal in some cases, and
    adds an attribute in others?  It would be redesigning control tracks so
    they are just note tracks that slice their children and apply
    a transformer to them.  I'm not sure that will coexist with the curve
    description language that control tracks currently implement.
    It would be interesting to get rid of track types entirely though.
    . This would get a nice feature from trackers, where an effect track can
      contain any kind of effect.  That means copy paste is easier, it's more
      compact, no fussing about creating a whole new track for a new effect.
  . optimistic merging: http://hintjens.com/blog:106

tracklang problems
  . It's too low level for chord-oriented music like piano.  For instance, I
    have to care about which note is on which track, while staff notation
    only has one way to write the cord.  So I have to do busywork like sorting
    notes by pitch, or copy pasting notes around between hands.  The whole
    thing about "what track is it on" is a result of the proportional time
    display, otherwise the horizontal position is unnecessary complexity.
  . The way that note, pitch, and dyn are separate is a hassle for reading and
    for editing.  Automatic pitch track selection and collapsing helps a bit,
    but it's still awkward.
  . Also it's not so easy to differentiate all those tracks, especially if
    every pitch track has its dyn track.
  . It can also be complicated to copy paste around if there is a bit of
    non-trivial structure like parent note tracks.
  . It's still hard for me to see relative positions and chords just from
    text.  Staff notation seems much easier.  Also hard to see enharmonic
    spelling.
  . In large scores, especially lilypond-using ones, I wind up with
    a complicated 2d structure to get all of the right transforms on the right
    notes.
    . One problem is that it's hard to see and understand the skeleton
      relationships, but also that each instrument has a unique ad-hoc setup
      based on what it happened to need, and then I fit in whatever I can into
      that ad-hoc structure.
    . Not only does the complicated structure consume thinking power, it makes
      things like copy paste awkward.
    . Also I spend time fiddling with track widths.  Because one track has the
      same width for the whole block, it should generally be wide enough for
      the widest text, but frequently that makes it too wide in general.
    . Also it makes me reluctant to solve problems by adding a new track.
    . Maybe the problem is blocks are too large.  They're generally awkward to
      navigate.  But on the other hand, things scattered into lots of separate
      blocks make it hard to read, and annoying to update.  A "1:1" mode could
      alleviate the update part.
  Solutions?
    . Theoretically lilypond could give the advantages of staff notation for
      reading only, but it's too slow for realtime update.
    . I could use verovio to maintain a instant staff display of the current
      surroundings.  Of course all this only helps with reading, not writing.
    . More utils like LNote.sort_on_pitch to automate away hassle could help
      with writing, but not reading.  So maybe it's worth trying to make
      sort_on_pitch more robust.
  verovio:
    . Lilypond is really slow.  If I use verovio maybe I could have a realtime
      display in staff notation.
    . I'd need a lightweight svg viewer, or svg display widget.  A web browser
      might work, if I can get it to update.
    . It has a standalone binary that can read MusicXML or PAE or various other
      formats, but why should I use some awkward intermediate format when
      I could link it in and use serialized notes as im does.
    . How much work this is depends on what format it expects.  Probably similar
      to lilypond, and should be able to use the same tracklang notation, except
      of course embedded lilypond code won't work.
    . But it's probably not worth it unless there's really a good reason for it.
      It could be a simpler than the lilypond backend since it's just meant to
      give a basic overview of durations and intervals, but still it's probably
      a fair amount of work to create and maintain a binding.
    . One complication is that it might be necessary to do an incremental or
      local-only update for speed, and I'd need to come up with some mechanism
      for that.

long term:
  - midi record
  - dense / efficient control signals
  - stable api
  - solution for per score haskell
  + text score
  + non-realtime synthesizer: doc/dev_notes/synthesizer
    - include audio inline, so I can write signal transforms like event
      transforms
  - horizontal layout
  - Unify environ, controls, and pitch signals by making signals of
    arbitrary type.
  - print scores

planning / research
  african rhythms
    . Book: African Polyphony and Polyrhythm
    . https://github.com/ctford/african-polyphony-and-polyrhythm
    . kolmogorov music: https://www.youtube.com/watch?v=Qg3XOfioapI
  cmj:
    . Wendy Carlos' tuning article: "Tuning at the crossroads", CMJ 11/1
  things for expressive music
    There needs to be some way for notes to affect surrounding notes.  For
    example
      . A trill might want to push the next note back a bit so it can complete
        its cycle.
      . Portamento might want to put controls points on a curve, so the speed
        a distance between pitches affects how quickly they approach, and
        quick notes will have less accurate pitch.
      . Gender tick affects the damping of the previous note.
      . If I control uses bezier curves, the curve is determined by the last
        control point of the previous and the first point of the current call.
    Other ideas:
      . Switch samples when played quickly.
      . Drum thing where successive strokes lose some energy.
    . Randomization is a first step, but true variation in playing is not
      random.  Things to study:
      . Tempo variation.  This is related to intentional tempo variation, but
        there should be slight tempo variations all the time.  This also has
        to do with higher level controls like rushing or lagging, and slight
        amounts of swing.
        E.g. some instruments may tend to rush when they want to be more
        prominent, or get louder.
      . Start / duration variation.  Related to tempo but at a lower level and
        less systematic.  Interpretation of staccato depends on surrounding
        tempo.
      . Dynamic variation.  Many instruments tend to get louder at higher
        pitches.  Tempo speed up tends to increase volume.
      . Pitch variation.  Some instruments tend to attack inaccurately and
        then correct.  Higher dynamics and tempo could make pitch less
        accurate.
    Modelling notation as a set of constraints:
      Notation specifies parameters along with how "fixed" they are.  For
      example, specified pitches are usually immovable, but onset time might
      be variable, depending on how important the beat is.  Higher level
      notation then assembles components and combines the constraints, and
      results in either conflicts, or a set of more specific constraints.

      . Example: janta attacks from below, normally one diatonic step, but
        avoids repeating the previous note.  A trill can end on either low
        or high, but if followed by janta, will change to avoid making janta
        repeat a note.  If trill speed is unfixed, it can change that,
        otherwise change attack time of the following note.  If the trill end
        is fixed, then the grace note must adapt by picking another higher
        note.
      . Carnatic ornaments change when time is reduced.
    constraint solving:
      . Procedural generation:
        https://www.youtube.com/watch?v=nkIMTc1wPaI&feature=youtu.be
      . "Wave Function Collapse", uses propagators, which is cells that modify
        neighbors in a monotonic way.
      . SMT solvers seem related.

  think about grammar for ornaments
    . Notes have a syntax: there are ornaments or articulations only valid at
      the attack time, ones that apply to the sustain, and ones that serve as
      transitions to the next note.  Also, the shapes of ornaments vary based on
      the note or absence of a note preceding and following, in addition to the
      speed.  It makes me think of cursive Arabic, where letters change shape
      and placement based on the previous letter, along with rules about which
      letters go where in the word (I'm sure linguists have a name for this,
      e.g. English has "ng", but won't start a word with it).  I've noticed
      there's a tension between specifying exact times via a timeline or
      whatever, and the kind of higher level flexibility implied by a syntactic
      approach.  E.g. if you say "attack X, sustain Y, end with Z", you are not
      saying exactly when X, Y, and Z start and end, and they are free to
      arrange themselves according to context.  But you do need a certain amount
      of precise control over times, at least in some cases.
    . This is similar to the "constraints" idea, at least with regard to some
      aspects being flexible, while others are fixed.  For instance, if
      I write ornaments with no specific times: 'A; B; C' then the start times
      and durations are flexible, and its up to the interpreting code to
      arrange them, but if I make separate events for A, B, and C, then the
      times are fixed.  Of course I also want to be able to fix A and C, but
      leave B's position flexible.
    . How to represent this as events?  I think I need a "macro" facility,
      where a call can interpret following events as a separate mini-language.
      I used to have this, and could probably get it back, by re-introducing
      the "skip following events" return value.  In that case, some notation
      like a leading '=' would indicate that the start time is fixed.
      Otherwise, the event_start is irrelevant except that it's in between
      the previous and next events.
    . Or maybe I do it as sub-notes, that way the one on the left specifies
      the extent of the "note DSL", and I don't need a "skip following" hack.

  . Give a visual indication of the events emitted by a call.  This is the
    note level version of the track signal render.  The underlying problem is
    that textual call names are not necessarily very clear about what the
    notes are, especially if it's a relatively ad-hoc call.  But I think
    I need a fancier GUI for this, since I'd have to have some way of turning
    a bunch of events into a distinctive looking graphic, e.g. a scaled down
    image of the block or something.
  . spline curve interpolator: evoral/Curve.cpp, www.korf.co.uk/spline.pdf

  . If I implement a VST host or patch a DAW to accept VST controls like MIDI
    controls can I get low latency high res controls?

ideas from renoise:
  Pattern Editor:
    Track colors and track groups.
      Renoise uses a swatch at the top.
      . I could set the background of the track title.  Set a note track and all
        controls below it at once, to distinguish instruments.
      . Or set color by instrument, and then putting in that instrument
        automatically sets the color.
      . Renoise can collapse a group, I could do that by instrument.
      . But if I want a track group I need another UI feature, and structure in
        Ui.State.  I could use the skeleton for this, but I'd have to make
        a dummy control track, say with the group name.  The problem is that
        it consumes horizontal space.  I'd really want the group name to go
        above the skeleton.
      . But I'd like to force a skeleton edge to go to the group, to simplify
        it, and so I can always add a track controlling a group.
      . So skeleton display becomes two level: above groups that points to
        groups, which then have text label, and below, where edges come out of
        the group label to individual tracks.  If groups can be nested then
        this gets even more complicated, basically a full graph up there.
        Too much!
      . DAWs do this by having a mini-track representing the folder, and then
        indenting below that.  They can squeeze in the text because they go
        horizontally.
    Drag and drop to move tracks.
      This is easier to remember and use than the shift-click thing.
  Pattern Sequencer:
    . Calls are more flexible, but it's convenient to add an order
      automatically.
    . I could do this via tscore, just for the "score" block:
      "score = [b1 b2 ...]"
    . Clone block seems useful, maybe I could have a cmd that copies the block
      and inserts it into the order.
    . Section headers let you put text in between.  I would do that with
      hierarchy, or in tscore just use a comment.
    . Renoise has a way to reorder patterns on the fly, for a live-performance
      kind of thing.  Karya derivation is not set up to interpret on the fly,
      but it could.  I'd need to have some mode where when it gets done
      playing a block, it can check a channel for new blocks to derive and
      play.  This is fundamentally realtime though, and won't work with im.
    . Looping patterns: I can do this with hierarchy.
    . In general, I can get all the renoise features but more simply by
      make tscore easy to use for the "score" root block.
  Pattern Matrix:
    . This is a way to manipulate blocks at the track level.  I don't have
      the ability to reach inside blocks like that, but can get the same
      effect with calls.  It's more work though.
    . I could get the effect by automatically refactoring blocks to have calls
      per instrument, and then just copy pasting that block, with
      modifications.
    . Or I could have a general transformer to mute tracks within a block, and
      then the score uses that.
    . It also has a graphical miniaturiztion of the score, using colors and
      maybe zoomed out tracks.  It would be nice to get the same thing, by
      including some kind of representation of a block inside a block call.
  Advanced Edit:
    . Subsumed by REPL.
  Instruments:
    . It could be nice to have a GUI representation of the layout of the kbd
      input, appropriate to scale or instrument.  In fact, it could have all
      keybindings when not in edit mode, as documentation.
  Sampler:
    . sampler-im can do all this, but without the GUI.  I don't have anything
      for looping.
  Phrase Editor:
    . I think it's all subsumed by calls.
  Sampler Waveform / Sampler keyzones:
    . Audio editing, this can be a separate program.  Too bad audacity is so
      clunky.
    . There is some integration with the score, e.g. start offsets.  Also
      keyzones display graphically, it would be nice to have this to generate
      patches for sampler-im.
  Sampler Modulation:
    . This seems to be synthesizer stuff.  For controls, like fancy LFO stuff,
      I put that in the score.  Response to controls would go in sampler-im.
  Effects:
    . I would do this in faust, either by writing a custom effect, or by
      having some separate compose langugae to build them on the fly.
  Plugins:
    . This goes in the DAW.  It's awkward that I can't coordinate midi port
      / channel assignments automatically.  If I had my own VST host I could
      do that, but would lose all the other DAW features.
  MIDI:
    . Renoise can get audio back from the MIDI synth... I guess I use the DAW
      for this as usual.
  Lots of GUI elements:
    . I don't want to do these in general because it would be a lot of work.
      But I can pick some that seem high value.
    . GUI for config could be independent: either a totally separate process
      that communicates via REPL, or in process but a separate window that
      communicates via its own queue.  Effectively this is like the via-REPL
      option except it's using in memory calls instead of text RPC.
    . GUI for drawing curves.  It may be easier to tweak by hand than typing
      in breakpoints and coefficients.  But dragging little spline handles is
      probably a waste of time, there should be higher level ways to say it.
      Dragging the breakpoints themselves though could be useful.
  Effects routing:
    . It would be nice to have effects by group, track, block, instrument, and
      note.  Currently I only have by-note for im, and then by instrument or
      group of instruments, but in the DAW.
    . Doing an effect for im at the transformer level should be theoretically
      possible, but it would have to trigger its group of notes to be rendered
      together, so the audio graph would become an arbitrary graph, not just
      the flat 'notes -> synth -> file per inst' thing I have now.
    . Per-note could be supported at the sampler-im or faust-im level though,
      if I automatically converted them into a named effect.
    . And then I could maybe do multiple notes by grouping all notes with the
      same effect into an audio stream.  So that would be constructing the
      graph inside the synth, but implicitly based on effect name.

FFI:
  There is no good solution for talking to C++ from haskell.

  Each struct is declared multiple times:
  - In a C++ idiomatic style in Keymap.h
  - In a Haskell idiomatic style in KeymapC.hs
  - Translated into SOA style in c_interface.h.  This is not even C
    idiomatic, because the haskell FFI can't pass structs.  It can construct
    them via CStorable, but this supports only static allocation, so it's
    no good if you have a string in there.
  - C function declaration translated into haskell FFI foreign import style.
    c2hs could do this mechanically, but hsc2hs is too primitive.

  Then it's marshalled, and hence copied, twice:
  - From haskell to the c_interface.h signature.
  - Inside c_interface.cc from C to C++ object.

  Ok let's go back to C-style structs.
  Then I only have it declared in two places, and both in struct style.
  Bindings can use withArray.
  C++ has to use explicit C-style deallocation.

research:
  . algorithm for violin fingerings: https://github.com/jmorag/open-strings
  rust-gui: gui: ui:
    what could I do with fancy gui:
      . See better drawing:
      . Faster.  The caching made scrolling fast, but it's now slow to zoom in
        on large blocks.
      . I could use gradients or transparency... but for what?  I could put
        multiple signals into one track, but would I?  Maybe dyn and pitch for
        note tracks.
      . mini block: Render blocks inside the calls.  But I should do a mock-up
        first, because it might be too cluttered.
    . try out druid for proof of concept
    - make a mock-up in druid: block, single track, events
      . How to do scrolling?
      . See how it works with lots of events and text.
    - integrate into shakefile, I think I just dispatch to cargo build
    - call from haskell
    - implement track tile
    pro:
      . More active development than fltk.
      . Modern drawing, including gradients and transparency.
      . No GPU acceleration, but likely to eventually get it.
      . Rust should be nicer than C++.
    con:
      . Generally unstable and immature, probably need to keep up with
        updates.
      . Will need to implement mostly the same stuff I needed for fltk:
        MoveTile, SymbolTable, etc.
      . No IME at the moment, will proabbly come eventually.
      . Dependency on rust.

ness:
  Questions:
    multiplate:
      . You can define membrane and drumshell, but not strike them?
        . It seems like 'strike membrane1 ...' works, but is undocumented?
          Are there any examples of its use?  The demos on the website sound
          pretty good.
      . What's the point of the name on drumshell?
      . In plate, what's rho, H, E, nu, T60, sig1?  Membrane has the same
        parameters, but with an extra T.
        . nu = poisson's ratio?
      . In plate, what does the center coordinates mean?
      . What shape are the plates?  Square, circular?  I assume they're the
        same thickness everywhere?  Depending on the parameters, they can have
        a definite pitch, but where is the continuum between gong and tamtam?
      . How difficult would it be to add features like hand damping, striking
        with soft or hard mallets?
      . Multiplate can be slow!  61m for a 4 second simulation (5m in demo
        mode).  Are there guidelines about what parameters influence runtime?
        It seems like the presence of a membrane makes demo runtime go from
        34s to 5m, and sound become empty.

    soundboard:
      . Each string has its own frets count and distance from the string, but
        you can't place them, and since you can't press on a string, you can't
        generally hear them... I assume they're for collisions only?
      . What's the meaning of the baseboard profile?
      . Each string has start and end coordinates, what does that affect?

    guitar:
      - What's the formula to derive the sounding frequency from the string's
        length, tension, and material?
      - How about the inharmonicity value as used by string_def_gen()?
        I assume it also affects material.

      - "itnum" is presumably iterations for a newton solver... which does what?
      - I guess "tol" would have been its tolerance, but isn't used for the C++
        version?

    bowed string:
      - In this model you can directly set the frequency of a string, but
        isn't that determined by length, tension, and material?
      - The (instrument, instrument_numb) presets affect only strings, right?
        What string definitions do they correspond to?
      - What's kw, alpha, beta, lambda and M in the finger and bow definitions?
        Finger has an extra ku.
      - The bow movements have: w0, vw0, u0, vu0 (initial positions and
        velocities).  I assume w is vertical, and u is horizontal?
      - Then the breakpoints are (position, vertical force, horiz force).
        If the position is horizontal position, what's the relationship
        between it and force?  Wouldn't the force be whatever is necessary to
        put it at the given position and time?

    brass:
      - is the online version the same as the downloadable binary?

  guitar:
    Things that work:
      . Strike open strings, with possible collisions, "jawari fret".
      . Originally, sliding up worked, but not sure how to get that back.
    Things that don't work:
      . Interaction with frets is hard to get right.  If the frets are
        very close (0.0005), then there are lots of string collisions, but
        further distance produces only silence or unpitched jangle.
      . For instance, "fingering", striking with the finger at or below each
        fret, tends to just get a jangle with a tiny bit of pitch.  Also
        touching at or below a fret and striking the string gets a lot of
        collisions.  So try as I might, I can't get the effect of normal
        fingering.
      . Since a finger can only be in one place, I don't think I can do
        artificial harmonics.
      . However, with no frets and a more distant backboard, and touching with
        high force, I can get another pitch, which is presumably the string
        segment on the other side of the finger, which is a nice effect.
    Bugs:
      . Occasionally the guitar model renders the whole sequence with
        a high-pitched whine.  E.g. ness-data/whine-1
      . Segfault, probably when finger movements overlap.
      . Seems like >2 fingers on one string results in no sound output.
      . Negative times or string locations in finger_def causes segfaults or
        no results.
      . For the web interface, output directories marked with seconds means
        parallel submits are unreliable.

    - Experiment with string connections for sympathetic strings.
    * Why do I get attack artifacts?
      . First, I need a stronger touch, like 0.5.
      . I get a cleaner sound if I go from zero to finger from t-0.05
      . I can't release without a new note.

    - Maybe I can use the "jawari" fret with parallel strings as a special
      effect.
    . Can I get a muted string effect by plucking while touching with low
      force?
      . Yes, sort of, just don't touch a node.

  * I need a better way to name strings.  string.idiom needs pitches, but the
    instrument needs symbolic names.
    . Maybe I could use custom pitches with a symbolic name, then convert via
      PSignal.pitch_note?  It seems like a misuse, since it's not really the
      pitch name.  Unless it is, and I also name the strings like that, but
      then I can only use an instrument with one scale.
    . Articulation.c_harmonic open_strings uses [NoteNumber]
    . Or why not use PSignal.Pitch, but the instrument definition converts it
      to a Text of the NN?
    . But I can't use just NN as string name, because then it breaks on
      scales.  It's the symbolic name.
    . I can't put PSignal.Pitch in the patch for open_strings, because Pitch
      can't go in a RestrictedEnviron.  Even though these patches are
      definitely code, and don't need to be serialized.  I only need
      RestrictedEnviron for local config, which is saved with the score.
    . Other than that, is using PSignal.Pitch for strings ok?  Basically
      I need a symbolic name and a NN, which is basically what Pitch is, minus
      the transposing stuff.
    . I think only Common.config_environ really needs to be RestrictedEnviron.
      But since Cmd.ResolvedInstrument merges common_environ into
      Common.Config, I'd have to make the environ a type parameter.
    . But there's no reason the string kind of pitch can't be in
      RestrictedEnviron, because it's just a pair.  So the other approach is
      to add an untranspoesable pitch to RestrictedEnviron.
    . Would it be really awful to just call it VPitch?  Then coerce via
      PSignal.constant_pitch.  The danger is silently casting away
      transposability, for instance put pitches in patch environ and expect to
      transpose them.  I could make it a bit clearer by not having ToVal
      Pitch, but requiring an explicit constructor, or ToVal ConstantPitch.
    . Setting patch element in the note call doesn't work, because it's too
      early.  I assign string via postproc.  So I need to assign at convert
      time.  Don't I have a postproc field for that?
    . Yes, Cmd.inst_postproc.
  - How to do strums and rolls with harmonics?
    . A roll transform would do it, and fix the grace note problems too.

  - Have some way to more easily switch between kontakt mockup and ness.
    . How would this look for real?  A hybrid instrument that writes to im but
      otherwise acts like a MIDI instrument.
    . But on playback I want either im or not, which means I'd have to tell im
      to mute the tracks that are now MIDI.
    . Or I could just use a custom thru, but then I can't get the playback
      mockup.  But in the longer term I'm hoping incremental rendering can fix
      that.
  Expressive things:
    . mute note: just do a short note?
    . pdm: make a quick turn at the beginning.  Use hybrid tempo?
    . ping: rapid pitch drop
    . roll

  ideas:
    . yangqin?
    . play string like reyong, with a hand damp
    . string like gangsa with noltol
    . jawari like tambura or sitar
    . solkattu for metal percussion thing
    . can I hand damp metal percussion?
